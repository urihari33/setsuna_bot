#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³å£°ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
å¸¸æ™‚ãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°ç›£è¦– + ãƒ›ãƒƒãƒˆã‚­ãƒ¼ãƒˆãƒªã‚¬ãƒ¼éŸ³å£°èªè­˜
"""

import pyaudio
import wave
import threading
import time
import tempfile
import os
import queue
import speech_recognition as sr
import numpy as np
from pynput import keyboard
from typing import Callable, Optional
import asyncio


class VoiceMonitorSystem:
    """å¸¸æ™‚éŸ³å£°ç›£è¦–ï¼‹ãƒ›ãƒƒãƒˆã‚­ãƒ¼ãƒˆãƒªã‚¬ãƒ¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, bot_instance, voice_callback: Optional[Callable] = None):
        self.bot = bot_instance
        self.voice_callback = voice_callback
        
        # ç›£è¦–çŠ¶æ…‹
        self.is_monitoring = False
        self.is_hotkey_pressed = False
        self.is_recording_mode = False
        
        # éŸ³å£°è¨­å®š
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.record_seconds_buffer = 10  # æœ€å¤§éŒ²éŸ³æ™‚é–“
        
        # éŸ³å£°å‡¦ç†
        self.audio_queue = queue.Queue()
        self.recording_buffer = []
        self.silence_threshold = 500  # éŸ³é‡é–¾å€¤
        self.min_speech_duration = 0.5  # æœ€å°ç™ºè©±æ™‚é–“ï¼ˆç§’ï¼‰
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ç®¡ç†
        self.monitor_thread = None
        self.keyboard_thread = None
        
        # ãƒ›ãƒƒãƒˆã‚­ãƒ¼è¨­å®š
        self.pressed_keys = set()
        self.target_keys = {
            keyboard.Key.ctrl,
            keyboard.Key.shift,
            keyboard.Key.alt
        }
        
        # éŸ³å£°èªè­˜
        self.recognizer = sr.Recognizer()
        self.recognizer.energy_threshold = 300
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.pause_threshold = 0.8
        
        print("ğŸ¤ éŸ³å£°ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def start_monitoring(self) -> bool:
        """éŸ³å£°ç›£è¦–é–‹å§‹"""
        if self.is_monitoring:
            print("âš ï¸ æ—¢ã«éŸ³å£°ç›£è¦–ä¸­ã§ã™")
            return False
        
        try:
            self.is_monitoring = True
            
            # éŸ³å£°ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
            self.monitor_thread = threading.Thread(
                target=self._audio_monitor_worker,
                daemon=True
            )
            self.monitor_thread.start()
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
            self.keyboard_thread = threading.Thread(
                target=self._keyboard_monitor_worker,
                daemon=True
            )
            self.keyboard_thread.start()
            
            print("ğŸ¤ éŸ³å£°ç›£è¦–é–‹å§‹ - Ctrl+Shift+Alt ã§ãƒˆãƒªã‚¬ãƒ¼")
            return True
            
        except Exception as e:
            print(f"âŒ éŸ³å£°ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            self.is_monitoring = False
            return False
    
    def stop_monitoring(self):
        """éŸ³å£°ç›£è¦–åœæ­¢"""
        if not self.is_monitoring:
            return
        
        print("ğŸ›‘ éŸ³å£°ç›£è¦–åœæ­¢ä¸­...")
        self.is_monitoring = False
        self.is_hotkey_pressed = False
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†å¾…æ©Ÿ
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=2)
        
        if self.keyboard_thread and self.keyboard_thread.is_alive():
            self.keyboard_thread.join(timeout=2)
        
        print("âœ… éŸ³å£°ç›£è¦–åœæ­¢å®Œäº†")
    
    def _audio_monitor_worker(self):
        """éŸ³å£°ç›£è¦–ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"""
        try:
            # PyAudioåˆæœŸåŒ–
            p = pyaudio.PyAudio()
            
            # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
            stream = p.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )
            
            print("ğŸ§ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹")
            
            # ç›£è¦–ãƒ«ãƒ¼ãƒ—
            while self.is_monitoring:
                try:
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
                    audio_data = stream.read(self.chunk, exception_on_overflow=False)
                    
                    # éŸ³å£°ãƒ¬ãƒ™ãƒ«è¨ˆç®—
                    audio_level = self._calculate_audio_level(audio_data)
                    
                    # ãƒ›ãƒƒãƒˆã‚­ãƒ¼æŠ¼ä¸‹æ™‚ã®ã¿éŒ²éŸ³ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                    if self.is_hotkey_pressed:
                        if not self.is_recording_mode:
                            print("ğŸ”´ éŒ²éŸ³é–‹å§‹")
                            self.is_recording_mode = True
                            self.recording_buffer = []
                        
                        self.recording_buffer.append(audio_data)
                        
                        # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºåˆ¶é™
                        max_frames = int(self.rate / self.chunk * self.record_seconds_buffer)
                        if len(self.recording_buffer) > max_frames:
                            self.recording_buffer.pop(0)
                    
                    elif self.is_recording_mode:
                        # ãƒ›ãƒƒãƒˆã‚­ãƒ¼é›¢ä¸Šæ™‚ã®å‡¦ç†
                        print("â¹ï¸ éŒ²éŸ³çµ‚äº† - éŸ³å£°èªè­˜å‡¦ç†ä¸­...")
                        self.is_recording_mode = False
                        
                        # éŸ³å£°èªè­˜å‡¦ç†ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
                        if self.recording_buffer:
                            threading.Thread(
                                target=self._process_recorded_audio,
                                args=(self.recording_buffer.copy(),),
                                daemon=True
                            ).start()
                        
                        self.recording_buffer = []
                    
                    # çŸ­æ™‚é–“å¾…æ©Ÿ
                    time.sleep(0.01)
                
                except Exception as e:
                    print(f"âš ï¸ éŸ³å£°ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                    time.sleep(0.1)
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†
            stream.stop_stream()
            stream.close()
            p.terminate()
            
        except Exception as e:
            print(f"âŒ éŸ³å£°ç›£è¦–ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            print("ğŸ§ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†")
    
    def _keyboard_monitor_worker(self):
        """ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç›£è¦–ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            with keyboard.Listener(
                on_press=self._on_key_press,
                on_release=self._on_key_release
            ) as listener:
                print("âŒ¨ï¸ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç›£è¦–é–‹å§‹")
                
                while self.is_monitoring:
                    time.sleep(0.1)
                
                listener.stop()
                
        except Exception as e:
            print(f"âŒ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            print("âŒ¨ï¸ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç›£è¦–çµ‚äº†")
    
    def _on_key_press(self, key):
        """ã‚­ãƒ¼æŠ¼ä¸‹ã‚¤ãƒ™ãƒ³ãƒˆ"""
        try:
            self.pressed_keys.add(key)
            
            # Ctrl+Shift+AltåŒæ™‚æŠ¼ã—æ¤œå‡º
            if self.target_keys.issubset(self.pressed_keys):
                if not self.is_hotkey_pressed:
                    self.is_hotkey_pressed = True
                    # print("ğŸ® ãƒ›ãƒƒãƒˆã‚­ãƒ¼æŠ¼ä¸‹æ¤œå‡º")
        
        except Exception as e:
            print(f"âŒ ã‚­ãƒ¼æŠ¼ä¸‹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _on_key_release(self, key):
        """ã‚­ãƒ¼é›¢ä¸Šã‚¤ãƒ™ãƒ³ãƒˆ"""
        try:
            if key in self.pressed_keys:
                self.pressed_keys.remove(key)
            
            # ã„ãšã‚Œã‹ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚­ãƒ¼ãŒé›¢ã•ã‚ŒãŸå ´åˆ
            if self.is_hotkey_pressed and not self.target_keys.issubset(self.pressed_keys):
                self.is_hotkey_pressed = False
                # print("ğŸ® ãƒ›ãƒƒãƒˆã‚­ãƒ¼é›¢ä¸Šæ¤œå‡º")
        
        except Exception as e:
            print(f"âŒ ã‚­ãƒ¼é›¢ä¸Šå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _calculate_audio_level(self, audio_data):
        """éŸ³å£°ãƒ¬ãƒ™ãƒ«è¨ˆç®—ï¼ˆRMSï¼‰"""
        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16)
            rms = np.sqrt(np.mean(audio_np**2))
            return rms
        except:
            return 0
    
    def _is_speech_detected(self, audio_buffer):
        """ç™ºè©±æ¤œå‡ºï¼ˆVAD: Voice Activity Detectionï¼‰"""
        if not audio_buffer:
            return False
        
        # å…¨ä½“ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        combined_audio = b''.join(audio_buffer)
        audio_level = self._calculate_audio_level(combined_audio)
        
        # éŸ³é‡é–¾å€¤ãƒã‚§ãƒƒã‚¯
        if audio_level < self.silence_threshold:
            return False
        
        # æœ€å°ç™ºè©±æ™‚é–“ãƒã‚§ãƒƒã‚¯
        duration = len(audio_buffer) * self.chunk / self.rate
        if duration < self.min_speech_duration:
            return False
        
        return True
    
    def _process_recorded_audio(self, audio_buffer):
        """éŒ²éŸ³éŸ³å£°ã®å‡¦ç†"""
        try:
            if not self._is_speech_detected(audio_buffer):
                print("âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆç„¡éŸ³ã¾ãŸã¯ãƒã‚¤ã‚ºï¼‰")
                return
            
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            combined_audio = b''.join(audio_buffer)
            
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                with wave.open(temp_file.name, 'wb') as wav_file:
                    wav_file.setnchannels(self.channels)
                    wav_file.setsampwidth(2)  # 16-bit
                    wav_file.setframerate(self.rate)
                    wav_file.writeframes(combined_audio)
                
                # éŸ³å£°èªè­˜å®Ÿè¡Œ
                recognized_text = self._recognize_audio_file(temp_file.name)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                try:
                    os.unlink(temp_file.name)
                except:
                    pass
                
                if recognized_text:
                    print(f"âœ… éŸ³å£°èªè­˜æˆåŠŸ: '{recognized_text}'")
                    
                    # ç‹¬ã‚Šè¨€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if self._is_valid_command(recognized_text):
                        # Botã«éŸ³å£°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
                        if self.bot and hasattr(self.bot, 'loop'):
                            asyncio.run_coroutine_threadsafe(
                                self.bot.handle_voice_input(recognized_text),
                                self.bot.loop
                            )
                        
                        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
                        if self.voice_callback:
                            self.voice_callback(recognized_text)
                    else:
                        print(f"ğŸ”‡ ç‹¬ã‚Šè¨€ã¨ã—ã¦ç„¡è¦–: '{recognized_text}'")
                else:
                    print("âŒ éŸ³å£°èªè­˜å¤±æ•—")
        
        except Exception as e:
            print(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _recognize_audio_file(self, wav_file_path):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èªè­˜"""
        try:
            with sr.AudioFile(wav_file_path) as source:
                # ãƒã‚¤ã‚ºèª¿æ•´
                self.recognizer.adjust_for_ambient_noise(source, duration=0.3)
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
                audio = self.recognizer.record(source)
            
            # GoogleéŸ³å£°èªè­˜
            text = self.recognizer.recognize_google(audio, language="ja-JP")
            return text.strip() if text else ""
            
        except sr.UnknownValueError:
            return ""
        except sr.RequestError as e:
            print(f"âŒ éŸ³å£°èªè­˜APIã‚¨ãƒ©ãƒ¼: {e}")
            return ""
        except Exception as e:
            print(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _is_valid_command(self, text):
        """æœ‰åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹åˆ¤å®šï¼ˆç‹¬ã‚Šè¨€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰"""
        if not text or len(text.strip()) < 2:
            return False
        
        # ã›ã¤ãªã¸ã®å‘¼ã³ã‹ã‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        valid_triggers = [
            "ã›ã¤ãª", "ã‚»ãƒ„ãƒŠ", "ã“ã‚“ã«ã¡ã¯", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯",
            "ã‚ã‚ŠãŒã¨ã†", "æ•™ãˆã¦", "ã©ã†æ€ã†", "èã„ã¦", "è©±ãã†"
        ]
        
        text_lower = text.lower()
        for trigger in valid_triggers:
            if trigger in text_lower:
                return True
        
        # ç–‘å•ç¬¦ã‚„æ„Ÿå˜†ç¬¦ã‚’å«ã‚€å ´åˆ
        if "?" in text or "ï¼Ÿ" in text or "!" in text or "ï¼" in text:
            return True
        
        # ä¸€å®šä»¥ä¸Šã®é•·ã•ã®ç™ºè©±
        if len(text) >= 8:
            return True
        
        return False
    
    def get_status(self):
        """ç›£è¦–çŠ¶æ…‹å–å¾—"""
        return {
            'is_monitoring': self.is_monitoring,
            'is_hotkey_pressed': self.is_hotkey_pressed,
            'is_recording_mode': self.is_recording_mode,
            'buffer_size': len(self.recording_buffer) if hasattr(self, 'recording_buffer') else 0
        }


# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_voice_callback(recognized_text):
    """ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    print(f"ğŸ—£ï¸ éŸ³å£°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯: {recognized_text}")


if __name__ == "__main__":
    print("ğŸ¤ éŸ³å£°ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    
    # ãƒ¢ãƒƒã‚¯Bot
    class MockBot:
        def __init__(self):
            self.loop = asyncio.get_event_loop()
        
        async def handle_voice_input(self, text):
            print(f"MockBot: éŸ³å£°å…¥åŠ›å—ä¿¡ - {text}")
    
    mock_bot = MockBot()
    monitor = VoiceMonitorSystem(mock_bot, test_voice_callback)
    
    try:
        print("éŸ³å£°ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™...")
        print("Ctrl+Shift+Alt ã‚’æŠ¼ã—ãªãŒã‚‰è©±ã—ã¦ãã ã•ã„")
        print("Ctrl+C ã§çµ‚äº†")
        
        monitor.start_monitoring()
        
        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        while True:
            time.sleep(1)
            status = monitor.get_status()
            if status['is_recording_mode']:
                print(f"ğŸ”´ éŒ²éŸ³ä¸­... ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {status['buffer_size']}")
            
    except KeyboardInterrupt:
        print("\nçµ‚äº†ä¸­...")
        monitor.stop_monitoring()
        print("âœ… çµ‚äº†å®Œäº†")