# ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼è¨ˆç”» - äººé–“è©•ä¾¡å‹SAå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“‹ æ¦‚è¦

**ãƒ†ã‚¹ãƒˆæˆ¦ç•¥**: æ®µéšçš„æ¤œè¨¼ãƒ»ç¶™ç¶šçš„å“è³ªä¿è¨¼ãƒ»å®Ÿç”¨æ€§ç¢ºèª  
**æ¤œè¨¼å¯¾è±¡**: æ©Ÿèƒ½æ­£ç¢ºæ€§ãƒ»æ€§èƒ½åŠ¹ç‡ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£  
**å“è³ªåŸºæº–**: 90%æ©Ÿèƒ½å®Œæˆåº¦ãƒ»80%ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ»95%æ€§èƒ½é”æˆ

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆä½“ç³»

### ãƒ†ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«éšå±¤
```
L1: å˜ä½“ãƒ†ã‚¹ãƒˆ (Unit Tests)
â”œâ”€ å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ©Ÿèƒ½æ¤œè¨¼
â”œâ”€ APIå…¥å‡ºåŠ›æ¤œè¨¼
â””â”€ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ¤œè¨¼

L2: çµ±åˆãƒ†ã‚¹ãƒˆ (Integration Tests)  
â”œâ”€ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“é€£æºæ¤œè¨¼
â”œâ”€ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ¤œè¨¼
â””â”€ å¤–éƒ¨APIçµ±åˆæ¤œè¨¼

L3: ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ (System Tests)
â”œâ”€ å…¨ä½“ãƒ•ãƒ­ãƒ¼æ¤œè¨¼
â”œâ”€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼
â””â”€ è² è·ãƒ»ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ

L4: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆ (User Acceptance Tests)
â”œâ”€ å®Ÿç”¨ã‚·ãƒŠãƒªã‚ªæ¤œè¨¼
â”œâ”€ ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£æ¤œè¨¼
â””â”€ å®Ÿé‹ç”¨æ¤œè¨¼
```

### ãƒ†ã‚¹ãƒˆç¨®åˆ¥
```
æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ:
â”œâ”€ æ­£å¸¸ç³»ãƒ†ã‚¹ãƒˆ (Happy Path)
â”œâ”€ ç•°å¸¸ç³»ãƒ†ã‚¹ãƒˆ (Error Cases)
â”œâ”€ å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ (Boundary Conditions)
â””â”€ å›å¸°ãƒ†ã‚¹ãƒˆ (Regression Tests)

éæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ:
â”œâ”€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ (Performance)
â”œâ”€ è² è·ãƒ†ã‚¹ãƒˆ (Load Testing)
â”œâ”€ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ (Scalability)
â””â”€ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ (Security)

ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ:
â”œâ”€ ä½¿ã„ã‚„ã™ã•æ¤œè¨¼ (Usability)
â”œâ”€ ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£æ¤œè¨¼ (Accessibility)
â”œâ”€ å­¦ç¿’åŠ¹æœæ¤œè¨¼ (Learning Effectiveness)
â””â”€ æº€è¶³åº¦æ¤œè¨¼ (User Satisfaction)
```

---

## ğŸ”§ L1: å˜ä½“ãƒ†ã‚¹ãƒˆè¨ˆç”»

### ExplorationOrchestratorå˜ä½“ãƒ†ã‚¹ãƒˆ

#### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è¨­è¨ˆ
```python
class TestExplorationOrchestrator:
    """ExplorationOrchestratorå˜ä½“ãƒ†ã‚¹ãƒˆ"""
    
    def test_start_exploration_normal(self):
        """æ­£å¸¸ãªæ¢ç´¢é–‹å§‹ãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration(
            theme="AIéŸ³æ¥½ç”Ÿæˆ",
            budget=50.0,
            initial_temperature="high"
        )
        
        assert session.session_id is not None
        assert session.theme == "AIéŸ³æ¥½ç”Ÿæˆ"
        assert session.budget_limit == 50.0
        assert session.current_temperature == "high"
        assert session.status == "active"
    
    def test_start_exploration_invalid_budget(self):
        """ç„¡åŠ¹äºˆç®—ã§ã®æ¢ç´¢é–‹å§‹ãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        
        with pytest.raises(BudgetError):
            orchestrator.start_exploration(
                theme="AIéŸ³æ¥½ç”Ÿæˆ",
                budget=-10.0  # è² ã®äºˆç®—
            )
    
    def test_run_exploration_round_success(self):
        """æ¢ç´¢ãƒ©ã‚¦ãƒ³ãƒ‰æ­£å¸¸å®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration("AIéŸ³æ¥½ç”Ÿæˆ", 50.0)
        
        result = orchestrator.run_exploration_round(session.session_id)
        
        assert result.round_id is not None
        assert result.sessions_completed > 0
        assert result.total_cost > 0
        assert len(result.themes_discovered) > 0
    
    def test_process_user_feedback(self):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration("AIéŸ³æ¥½ç”Ÿæˆ", 50.0)
        
        feedback = UserFeedback(
            direction_choice="deeper",
            overall_quality=0.8,
            continuation_preference="continue"
        )
        
        result = orchestrator.process_user_feedback(session.session_id, feedback)
        
        assert result.feedback_processed == True
        assert result.temperature_adjusted == True
        assert result.next_strategy is not None
```

### TemperatureControllerå˜ä½“ãƒ†ã‚¹ãƒˆ

#### æ¸©åº¦åˆ¶å¾¡ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
```python
class TestTemperatureController:
    """TemperatureControllerå˜ä½“ãƒ†ã‚¹ãƒˆ"""
    
    def test_temperature_adjustment_deeper(self):
        """æ·±æ˜ã‚Šè¦æ±‚ã§ã®æ¸©åº¦èª¿æ•´ãƒ†ã‚¹ãƒˆ"""
        controller = TemperatureController()
        
        feedback = UserFeedback(direction_choice="deeper")
        quality_metrics = QualityMetrics(average_quality=0.8)
        
        adjustment = controller.adjust_temperature(
            session_id="test_session",
            feedback=feedback,
            quality_metrics=quality_metrics
        )
        
        assert adjustment.temperature_changed == True
        assert adjustment.new_temperature in ["medium", "low"]
        assert adjustment.reason == "high_quality_deep_request"
    
    def test_temperature_adjustment_broader(self):
        """ç¯„å›²æ‹¡å¤§è¦æ±‚ã§ã®æ¸©åº¦èª¿æ•´ãƒ†ã‚¹ãƒˆ"""
        controller = TemperatureController()
        
        feedback = UserFeedback(direction_choice="broader")
        quality_metrics = QualityMetrics(average_quality=0.4)
        
        adjustment = controller.adjust_temperature(
            session_id="test_session",
            feedback=feedback,
            quality_metrics=quality_metrics
        )
        
        assert adjustment.new_temperature == "high"
        assert adjustment.reason == "low_quality_broad_request"
    
    def test_temperature_config_retrieval(self):
        """æ¸©åº¦è¨­å®šå–å¾—ãƒ†ã‚¹ãƒˆ"""
        controller = TemperatureController()
        
        config = controller.get_temperature_config("high")
        
        assert config.temperature_level == "high"
        assert config.query_diversity > 0.8
        assert config.sessions_per_round > 20
        assert config.analysis_depth == "shallow"
```

### AdaptiveQueryGeneratorå˜ä½“ãƒ†ã‚¹ãƒˆ

#### ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
```python
class TestAdaptiveQueryGenerator:
    """AdaptiveQueryGeneratorå˜ä½“ãƒ†ã‚¹ãƒˆ"""
    
    def test_high_temperature_query_generation(self):
        """é«˜æ¸©æ™‚ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        generator = AdaptiveQueryGenerator()
        config = TemperatureConfig(
            temperature_level="high",
            query_diversity=0.9,
            sessions_per_round=25
        )
        
        queries = generator.generate_temperature_adapted_queries(
            theme="AIéŸ³æ¥½ç”Ÿæˆ",
            temperature_config=config
        )
        
        assert len(queries) >= 20
        assert len(queries) <= 30
        assert all(query.query_diversity_score > 0.7 for query in queries)
        assert any("AI" in query.query_text for query in queries)
        assert any("éŸ³æ¥½" in query.query_text for query in queries)
    
    def test_low_temperature_query_generation(self):
        """ä½æ¸©æ™‚ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        generator = AdaptiveQueryGenerator()
        config = TemperatureConfig(
            temperature_level="low",
            query_diversity=0.3,
            sessions_per_round=8
        )
        
        queries = generator.generate_temperature_adapted_queries(
            theme="TransformeréŸ³æ¥½ç”Ÿæˆ",
            temperature_config=config
        )
        
        assert len(queries) >= 6
        assert len(queries) <= 10
        assert all(query.specificity_score > 0.7 for query in queries)
        assert any("Transformer" in query.query_text for query in queries)
    
    def test_query_diversity_expansion(self):
        """ã‚¯ã‚¨ãƒªå¤šæ§˜æ€§æ‹¡å¼µãƒ†ã‚¹ãƒˆ"""
        generator = AdaptiveQueryGenerator()
        base_queries = ["AIéŸ³æ¥½ç”Ÿæˆ", "æ©Ÿæ¢°å­¦ç¿’ä½œæ›²"]
        
        expanded = generator.expand_query_diversity(
            base_queries=base_queries,
            diversity_level=0.8
        )
        
        assert len(expanded) > len(base_queries)
        assert all(base in expanded for base in base_queries)
        unique_concepts = set(query.split() for query in expanded)
        assert len(unique_concepts) > len(base_queries) * 2
```

---

## ğŸ”— L2: çµ±åˆãƒ†ã‚¹ãƒˆè¨ˆç”»

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆãƒ†ã‚¹ãƒˆ

#### Orchestrator â†” TemperatureControllerçµ±åˆ
```python
class TestOrchestratorTemperatureIntegration:
    """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ»æ¸©åº¦åˆ¶å¾¡çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def test_temperature_feedback_loop(self):
        """æ¸©åº¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration("AIéŸ³æ¥½ç”Ÿæˆ", 50.0)
        
        # ç¬¬1ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
        round1 = orchestrator.run_exploration_round(session.session_id)
        initial_temp = round1.temperature_used
        
        # æ·±æ˜ã‚Šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        feedback = UserFeedback(
            direction_choice="deeper",
            overall_quality=0.8
        )
        orchestrator.process_user_feedback(session.session_id, feedback)
        
        # ç¬¬2ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
        round2 = orchestrator.run_exploration_round(session.session_id)
        adjusted_temp = round2.temperature_used
        
        # æ¸©åº¦ãŒä¸‹ãŒã‚‹ã“ã¨ã‚’ç¢ºèª
        temp_order = ["high", "medium", "low"]
        assert temp_order.index(adjusted_temp) >= temp_order.index(initial_temp)
    
    def test_multi_round_temperature_evolution(self):
        """è¤‡æ•°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®æ¸©åº¦å¤‰åŒ–ãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration("AIéŸ³æ¥½ç”Ÿæˆ", 100.0)
        
        temperatures = []
        for round_num in range(5):
            result = orchestrator.run_exploration_round(session.session_id)
            temperatures.append(result.temperature_used)
            
            # æ·±æ˜ã‚Šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç¶™ç¶š
            feedback = UserFeedback(direction_choice="deeper", overall_quality=0.7)
            orchestrator.process_user_feedback(session.session_id, feedback)
        
        # æ¸©åº¦ãŒæ®µéšçš„ã«ä¸‹ãŒã‚‹ã“ã¨ã‚’ç¢ºèª
        assert temperatures[0] == "high"
        assert temperatures[-1] in ["medium", "low"]
```

#### BatchSessionManager â†” CostOptimizerçµ±åˆ
```python
class TestBatchCostIntegration:
    """ãƒãƒƒãƒå‡¦ç†ãƒ»ã‚³ã‚¹ãƒˆæœ€é©åŒ–çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def test_budget_constrained_execution(self):
        """äºˆç®—åˆ¶ç´„ä¸‹ã§ã®ãƒãƒƒãƒå®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
        batch_manager = BatchSessionManager()
        cost_optimizer = CostOptimizer()
        
        queries = self.generate_test_queries(30)
        budget_limit = 15.0  # å³ã—ã„äºˆç®—åˆ¶é™
        
        # ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã•ã‚ŒãŸãƒãƒƒãƒå®Ÿè¡Œ
        result = batch_manager.execute_session_batch(
            queries=queries,
            temperature_config=TemperatureConfig(temperature_level="high"),
            cost_limit=budget_limit
        )
        
        assert result.total_cost <= budget_limit
        assert result.sessions_completed > 0
        assert result.cost_optimization_applied == True
    
    def test_parallel_execution_cost_efficiency(self):
        """ä¸¦åˆ—å®Ÿè¡Œã‚³ã‚¹ãƒˆåŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""
        batch_manager = BatchSessionManager()
        
        queries = self.generate_test_queries(20)
        
        # é€æ¬¡å®Ÿè¡Œ
        sequential_result = batch_manager.execute_session_batch(
            queries=queries[:10],
            max_concurrent=1
        )
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        parallel_result = batch_manager.execute_session_batch(
            queries=queries[10:],
            max_concurrent=5
        )
        
        # ä¸¦åˆ—å®Ÿè¡ŒãŒåŠ¹ç‡çš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert parallel_result.execution_time < sequential_result.execution_time * 0.7
        assert parallel_result.cost_per_session <= sequential_result.cost_per_session * 1.1
```

### å¤–éƒ¨APIçµ±åˆãƒ†ã‚¹ãƒˆ

#### OpenAI APIçµ±åˆãƒ†ã‚¹ãƒˆ
```python
class TestOpenAIIntegration:
    """OpenAI APIçµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.integration
    def test_gpt4_query_generation(self):
        """GPT-4ã‚¯ã‚¨ãƒªç”Ÿæˆçµ±åˆãƒ†ã‚¹ãƒˆ"""
        generator = AdaptiveQueryGenerator()
        
        queries = generator.generate_temperature_adapted_queries(
            theme="é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°",
            temperature_config=TemperatureConfig(temperature_level="medium")
        )
        
        assert len(queries) > 0
        assert all(query.query_text for query in queries)
        assert all(query.predicted_relevance > 0 for query in queries)
    
    @pytest.mark.integration  
    def test_preprocessing_analysis(self):
        """å‰å‡¦ç†åˆ†æçµ±åˆãƒ†ã‚¹ãƒˆ"""
        analyzer = ResultsAnalyzer()
        
        test_sessions = self.create_test_sessions()
        analysis = analyzer.analyze_exploration_results(
            sessions=test_sessions,
            analysis_depth="medium"
        )
        
        assert len(analysis.major_themes) > 0
        assert analysis.quality_distribution is not None
        assert len(analysis.identified_gaps) >= 0
```

---

## ğŸ—ï¸ L3: ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆè¨ˆç”»

### å…¨ä½“ãƒ•ãƒ­ãƒ¼æ¤œè¨¼

#### ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ
```python
class TestEndToEndScenarios:
    """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
    
    def test_complete_exploration_workflow(self):
        """å®Œå…¨æ¢ç´¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # 1. æ¢ç´¢é–‹å§‹
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration(
            theme="æŒç¶šå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼æŠ€è¡“",
            budget=30.0,
            initial_temperature="high"
        )
        
        total_cost = 0
        round_count = 0
        
        while session.status == "active" and total_cost < 25.0:
            # 2. æ¢ç´¢ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
            round_result = orchestrator.run_exploration_round(session.session_id)
            total_cost += round_result.total_cost
            round_count += 1
            
            # 3. çµæœåˆ†æ
            analyzer = ResultsAnalyzer()
            analysis = analyzer.analyze_exploration_results(
                sessions=round_result.sessions_executed
            )
            
            # 4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            feedback = self.simulate_user_feedback(analysis)
            orchestrator.process_user_feedback(session.session_id, feedback)
            
            # ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢
            if round_count > 10:
                break
        
        # 5. æ¢ç´¢å®Œäº†
        summary = orchestrator.finalize_exploration(session.session_id)
        
        # æ¤œè¨¼
        assert round_count > 1
        assert total_cost > 0
        assert len(summary.major_themes) > 0
        assert summary.total_sessions > 0
    
    def test_simulated_annealing_behavior(self):
        """Simulated Annealingå‹•ä½œãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration("ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³æŠ€è¡“", 40.0)
        
        temperatures = []
        quality_scores = []
        
        # ä¸€è²«ã—ã¦æ·±æ˜ã‚Šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡
        for _ in range(6):
            result = orchestrator.run_exploration_round(session.session_id)
            temperatures.append(result.temperature_used)
            quality_scores.append(result.average_quality)
            
            feedback = UserFeedback(direction_choice="deeper", overall_quality=0.8)
            orchestrator.process_user_feedback(session.session_id, feedback)
        
        # SAç‰¹æ€§ã®ç¢ºèª
        assert temperatures[0] == "high"                    # é«˜æ¸©é–‹å§‹
        assert temperatures[-1] in ["medium", "low"]       # æ¸©åº¦ä½ä¸‹
        assert quality_scores[-1] > quality_scores[0]      # å“è³ªå‘ä¸Š
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

#### å‡¦ç†æ€§èƒ½åŸºæº–ãƒ†ã‚¹ãƒˆ
```python
class TestPerformanceRequirements:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ãƒ†ã‚¹ãƒˆ"""
    
    def test_session_execution_speed(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Ÿè¡Œé€Ÿåº¦ãƒ†ã‚¹ãƒˆ"""
        batch_manager = BatchSessionManager()
        
        queries = self.generate_test_queries(25)
        start_time = time.time()
        
        result = batch_manager.execute_session_batch(
            queries=queries,
            temperature_config=TemperatureConfig(temperature_level="high"),
            max_concurrent=5
        )
        
        execution_time = time.time() - start_time
        
        # è¦ä»¶: 25ã‚»ãƒƒã‚·ãƒ§ãƒ³/æ™‚é–“ = 144ç§’/ã‚»ãƒƒã‚·ãƒ§ãƒ³
        sessions_per_hour = result.sessions_completed / (execution_time / 3600)
        assert sessions_per_hour >= 20  # æœ€ä½20ã‚»ãƒƒã‚·ãƒ§ãƒ³/æ™‚é–“
    
    def test_large_scale_analysis_performance(self):
        """å¤§è¦æ¨¡åˆ†æãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        analyzer = ResultsAnalyzer()
        
        # 100ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†ã®åˆ†æ
        large_session_set = self.generate_test_sessions(100)
        start_time = time.time()
        
        analysis = analyzer.analyze_exploration_results(
            sessions=large_session_set,
            analysis_depth="medium"
        )
        
        analysis_time = time.time() - start_time
        
        # è¦ä»¶: 100ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†æ < 5åˆ†
        assert analysis_time < 300
        assert len(analysis.major_themes) > 0
    
    def test_memory_efficiency(self):
        """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""
        import psutil
        import gc
        
        orchestrator = ExplorationOrchestrator()
        
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # å¤§é‡ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        for i in range(50):
            session = orchestrator.start_exploration(f"ãƒ†ãƒ¼ãƒ{i}", 10.0)
            result = orchestrator.run_exploration_round(session.session_id)
            orchestrator.finalize_exploration(session.session_id)
            
            if i % 10 == 0:
                gc.collect()  # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        
        final_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        # ãƒ¡ãƒ¢ãƒªå¢—åŠ ãŒ500MBä»¥ä¸‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert memory_increase < 500
```

### è² è·ãƒ»ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ

#### åŒæ™‚å®Ÿè¡Œè² è·ãƒ†ã‚¹ãƒˆ
```python
class TestLoadStress:
    """è² è·ãƒ»ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    def test_concurrent_exploration_sessions(self):
        """åŒæ™‚æ¢ç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³è² è·ãƒ†ã‚¹ãƒˆ"""
        import threading
        import queue
        
        results = queue.Queue()
        
        def run_exploration_session(session_id):
            try:
                orchestrator = ExplorationOrchestrator()
                session = orchestrator.start_exploration(f"ãƒ†ãƒ¼ãƒ{session_id}", 20.0)
                
                for _ in range(3):
                    result = orchestrator.run_exploration_round(session.session_id)
                    feedback = UserFeedback(direction_choice="deeper")
                    orchestrator.process_user_feedback(session.session_id, feedback)
                
                summary = orchestrator.finalize_exploration(session.session_id)
                results.put(("success", session_id, summary))
                
            except Exception as e:
                results.put(("error", session_id, str(e)))
        
        # 10å€‹ã®åŒæ™‚ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        threads = []
        for i in range(10):
            thread = threading.Thread(target=run_exploration_session, args=(i,))
            threads.append(thread)
            thread.start()
        
        for thread in threads:
            thread.join(timeout=300)  # 5åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        
        # çµæœç¢ºèª
        successes = 0
        errors = 0
        
        while not results.empty():
            status, session_id, data = results.get()
            if status == "success":
                successes += 1
            else:
                errors += 1
                print(f"Session {session_id} error: {data}")
        
        # 80%ä»¥ä¸Šã®æˆåŠŸç‡ã‚’è¦æ±‚
        success_rate = successes / (successes + errors)
        assert success_rate >= 0.8
    
    def test_api_rate_limiting_resilience(self):
        """APIãƒ¬ãƒ¼ãƒˆåˆ¶é™è€æ€§ãƒ†ã‚¹ãƒˆ"""
        batch_manager = BatchSessionManager()
        
        # å¤§é‡ã‚¯ã‚¨ãƒªã‚’çŸ­æ™‚é–“ã§å®Ÿè¡Œï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’èª˜ç™ºï¼‰
        large_query_set = self.generate_test_queries(100)
        
        start_time = time.time()
        result = batch_manager.execute_session_batch(
            queries=large_query_set,
            temperature_config=TemperatureConfig(temperature_level="medium"),
            max_concurrent=8  # é«˜ã„åŒæ™‚å®Ÿè¡Œæ•°
        )
        execution_time = time.time() - start_time
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é­é‡ã—ã¦ã‚‚å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert result.sessions_completed > 50  # åŠåˆ†ä»¥ä¸Šã¯å®Œäº†
        assert len(result.errors) < result.sessions_completed  # ã‚¨ãƒ©ãƒ¼ã‚ˆã‚ŠæˆåŠŸãŒå¤šã„
        assert execution_time < 7200  # 2æ™‚é–“ä»¥å†…ã§å®Œäº†
```

---

## ğŸ‘¥ L4: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆè¨ˆç”»

### ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ

#### ä½¿ã„ã‚„ã™ã•æ¤œè¨¼ã‚·ãƒŠãƒªã‚ª
```python
class UserUsabilityTest:
    """ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª"""
    
    def test_first_time_user_experience(self):
        """åˆå›åˆ©ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        scenarios = [
            {
                "user_profile": "æŠ€è¡“è€…",
                "goal": "AIæŠ€è¡“ã®æœ€æ–°å‹•å‘ã‚’æŠŠæ¡",
                "expected_completion_time": 30,  # åˆ†
                "success_criteria": {
                    "task_completion": True,
                    "user_satisfaction": 4.0,  # 5æ®µéšè©•ä¾¡
                    "learning_effectiveness": 0.8
                }
            },
            {
                "user_profile": "çµŒå–¶è€…",
                "goal": "æ–°äº‹æ¥­åˆ†é‡ã®å¸‚å ´èª¿æŸ»",
                "expected_completion_time": 45,
                "success_criteria": {
                    "task_completion": True,
                    "user_satisfaction": 3.5,
                    "learning_effectiveness": 0.7
                }
            },
            {
                "user_profile": "ç ”ç©¶è€…",
                "goal": "å°‚é–€åˆ†é‡ã®æ·±ã„èª¿æŸ»",
                "expected_completion_time": 60,
                "success_criteria": {
                    "task_completion": True,
                    "user_satisfaction": 4.5,
                    "learning_effectiveness": 0.9
                }
            }
        ]
        
        for scenario in scenarios:
            result = self.execute_user_scenario(scenario)
            self.validate_success_criteria(result, scenario["success_criteria"])
    
    def test_interface_intuitiveness(self):
        """ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç›´æ„Ÿæ€§ãƒ†ã‚¹ãƒˆ"""
        ui_elements = [
            "exploration_start_dialog",
            "temperature_indicator",
            "progress_dashboard", 
            "feedback_interface",
            "results_presentation"
        ]
        
        for element in ui_elements:
            usability_score = self.measure_element_usability(element)
            assert usability_score >= 3.5  # 5æ®µéšè©•ä¾¡ã§3.5ä»¥ä¸Š
```

### å®Ÿç”¨æ€§æ¤œè¨¼

#### å®Ÿéš›å­¦ç¿’ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ
```python
class RealWorldLearningTest:
    """å®Ÿä¸–ç•Œå­¦ç¿’ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
    
    def test_market_research_scenario(self):
        """å¸‚å ´èª¿æŸ»ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        orchestrator = ExplorationOrchestrator()
        
        # å®Ÿéš›ã®å¸‚å ´èª¿æŸ»ã‚¿ã‚¹ã‚¯
        session = orchestrator.start_exploration(
            theme="é›»æ°—è‡ªå‹•è»Šãƒãƒƒãƒ†ãƒªãƒ¼å¸‚å ´",
            budget=80.0,
            initial_temperature="high"
        )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰ã•ã‚ŒãŸæ¢ç´¢ãƒ—ãƒ­ã‚»ã‚¹
        exploration_phases = [
            {"focus": "broader", "rounds": 2},    # å¸‚å ´æ¦‚è¦æŠŠæ¡
            {"focus": "focus", "rounds": 2},      # æŠ€è¡“å‹•å‘é›†ä¸­
            {"focus": "deeper", "rounds": 2}      # ç«¶åˆåˆ†ææ·±æ˜ã‚Š
        ]
        
        insights_collected = []
        
        for phase in exploration_phases:
            for _ in range(phase["rounds"]):
                result = orchestrator.run_exploration_round(session.session_id)
                insights_collected.extend(result.themes_discovered)
                
                feedback = UserFeedback(direction_choice=phase["focus"])
                orchestrator.process_user_feedback(session.session_id, feedback)
        
        summary = orchestrator.finalize_exploration(session.session_id)
        
        # å®Ÿç”¨æ€§æ¤œè¨¼
        assert len(summary.major_themes) >= 5  # ä¸»è¦ãƒ†ãƒ¼ãƒ5ã¤ä»¥ä¸Š
        assert summary.knowledge_coverage["market"] > 0.6  # å¸‚å ´ã‚«ãƒãƒ¬ãƒƒã‚¸60%ä»¥ä¸Š
        assert summary.knowledge_coverage["technology"] > 0.6  # æŠ€è¡“ã‚«ãƒãƒ¬ãƒƒã‚¸60%ä»¥ä¸Š
        assert len(summary.actionable_insights) >= 3  # å®Ÿç”¨çš„æ´å¯Ÿ3ã¤ä»¥ä¸Š
    
    def test_learning_effectiveness_measurement(self):
        """å­¦ç¿’åŠ¹æœæ¸¬å®šãƒ†ã‚¹ãƒˆ"""
        pre_knowledge = self.assess_user_knowledge("äººå·¥çŸ¥èƒ½")
        
        # å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        orchestrator = ExplorationOrchestrator()
        session = orchestrator.start_exploration("äººå·¥çŸ¥èƒ½æŠ€è¡“å‹•å‘", 50.0)
        
        for _ in range(4):
            result = orchestrator.run_exploration_round(session.session_id)
            feedback = UserFeedback(direction_choice="deeper", overall_quality=0.7)
            orchestrator.process_user_feedback(session.session_id, feedback)
        
        summary = orchestrator.finalize_exploration(session.session_id)
        post_knowledge = self.assess_user_knowledge("äººå·¥çŸ¥èƒ½")
        
        # å­¦ç¿’åŠ¹æœæ¸¬å®š
        knowledge_gain = post_knowledge - pre_knowledge
        assert knowledge_gain >= 0.3  # 30%ä»¥ä¸Šã®çŸ¥è­˜å‘ä¸Š
        
        cost_effectiveness = knowledge_gain / summary.total_cost
        assert cost_effectiveness >= 0.006  # 1ãƒ‰ãƒ«ã‚ãŸã‚Š0.6%ä»¥ä¸Šã®å‘ä¸Š
```

---

## ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»KPI

### æ©Ÿèƒ½å“è³ªæŒ‡æ¨™
```python
class QualityMetrics:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©"""
    
    def functional_quality_kpis(self):
        return {
            "feature_completeness": {
                "target": 0.90,
                "measurement": "implemented_features / planned_features",
                "critical_threshold": 0.85
            },
            "api_correctness": {
                "target": 0.95,
                "measurement": "correct_responses / total_requests",
                "critical_threshold": 0.90
            },
            "error_handling_coverage": {
                "target": 0.95,
                "measurement": "handled_error_cases / total_error_cases",
                "critical_threshold": 0.90
            },
            "temperature_control_accuracy": {
                "target": 0.90,
                "measurement": "correct_adjustments / total_adjustments",
                "critical_threshold": 0.85
            }
        }
    
    def performance_quality_kpis(self):
        return {
            "session_execution_speed": {
                "target": 25,  # sessions/hour
                "measurement": "sessions_completed / elapsed_hours",
                "critical_threshold": 20
            },
            "analysis_processing_time": {
                "target": 300,  # seconds for 100 sessions
                "measurement": "analysis_time_seconds",
                "critical_threshold": 600
            },
            "memory_efficiency": {
                "target": 500,  # MB max increase
                "measurement": "peak_memory - initial_memory",
                "critical_threshold": 1000
            },
            "cost_per_session": {
                "target": 1.00,  # USD
                "measurement": "total_cost / sessions_completed",
                "critical_threshold": 1.50
            }
        }
    
    def user_experience_kpis(self):
        return {
            "user_satisfaction": {
                "target": 4.0,  # 5-point scale
                "measurement": "average_satisfaction_rating",
                "critical_threshold": 3.0
            },
            "task_completion_rate": {
                "target": 0.85,
                "measurement": "completed_tasks / attempted_tasks",
                "critical_threshold": 0.70
            },
            "learning_effectiveness": {
                "target": 0.80,
                "measurement": "knowledge_gain_percentage",
                "critical_threshold": 0.60
            },
            "interface_intuitiveness": {
                "target": 4.0,  # 5-point scale
                "measurement": "average_usability_score",
                "critical_threshold": 3.0
            }
        }
```

### ç¶™ç¶šçš„å“è³ªç›£è¦–

#### è‡ªå‹•å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
```python
class ContinuousQualityMonitoring:
    """ç¶™ç¶šçš„å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def setup_monitoring_pipeline(self):
        """å“è³ªç›£è¦–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š"""
        return {
            "automated_tests": {
                "unit_tests": "every_commit",
                "integration_tests": "daily",
                "performance_tests": "weekly",
                "user_acceptance_tests": "release_candidate"
            },
            "quality_gates": {
                "code_coverage": 0.80,
                "test_pass_rate": 0.95,
                "performance_regression": 0.10,
                "user_satisfaction": 3.5
            },
            "alerts": {
                "quality_degradation": "immediate",
                "performance_regression": "within_1_hour",
                "user_complaint": "within_4_hours",
                "system_error": "immediate"
            }
        }
    
    def quality_trend_analysis(self):
        """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        return {
            "metric_tracking": [
                "test_pass_rate_over_time",
                "performance_metrics_trend",
                "user_satisfaction_evolution",
                "defect_discovery_rate"
            ],
            "predictive_analytics": [
                "quality_degradation_prediction",
                "performance_bottleneck_forecast",
                "user_churn_risk_assessment"
            ],
            "improvement_recommendations": [
                "priority_testing_areas",
                "performance_optimization_targets",
                "user_experience_enhancements"
            ]
        }
```

---

*ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼è¨ˆç”»ä½œæˆæ—¥: 2025å¹´7æœˆ11æ—¥*  
*ä½œæˆè€…: Claude Code (Sonnet 4)*  
*å“è³ªåŸºæº–: æ©Ÿèƒ½90%ãƒ»ãƒ†ã‚¹ãƒˆ80%ãƒ»æ€§èƒ½95%ãƒ»æº€è¶³åº¦80%*