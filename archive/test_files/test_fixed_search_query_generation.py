#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®æ­£å¾Œæ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ãé©åˆ‡ãªã‚¯ã‚¨ãƒªç”Ÿæˆã®æ¤œè¨¼
"""

import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

def test_search_query_generation():
    """ä¿®æ­£å¾Œã®æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ”§ ä¿®æ­£å¾Œæ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    try:
        # KnowledgeAnalysisEngineã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from core.knowledge_analysis.knowledge_analysis_engine import KnowledgeAnalysisEngine
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆã®ã¿ãªã®ã§ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸è¦ï¼‰
        print("ğŸš€ KnowledgeAnalysisEngineåˆæœŸåŒ–ä¸­...")
        engine = KnowledgeAnalysisEngine()
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©
        test_cases = [
            {
                "prompt": "ã›ã¤ãªã®éŸ³æ¥½æ´»å‹•ã«ã¤ã„ã¦è©³ã—ãçŸ¥ã‚ŠãŸã„",
                "expected_context": "person",
                "expected_keywords": ["ã›ã¤ãª", "éŸ³æ¥½", "æ´»å‹•", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "æ¥½æ›²"]
            },
            {
                "prompt": "ç‰‡ç„¡ã›ã¤ãªã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«",
                "expected_context": "person",
                "expected_keywords": ["ç‰‡ç„¡ã›ã¤ãª", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "çµŒæ­´", "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ"]
            },
            {
                "prompt": "AIæŠ€è¡“ã®æœ€æ–°å‹•å‘ã«ã¤ã„ã¦",
                "expected_context": "technology",
                "expected_keywords": ["AIæŠ€è¡“", "æœ€æ–°å‹•å‘", "å®Ÿè£…", "äº‹ä¾‹"]
            },
            {
                "prompt": "æ©Ÿæ¢°å­¦ç¿’ã®å®Ÿè£…æ–¹æ³•",
                "expected_context": "technology", 
                "expected_keywords": ["æ©Ÿæ¢°å­¦ç¿’", "å®Ÿè£…", "æŠ€è¡“", "å°å…¥"]
            },
            {
                "prompt": "Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®åŸºç¤",
                "expected_context": "general",
                "expected_keywords": ["Python", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", "åŸºç¤", "è©³ç´°"]
            }
        ]
        
        print(f"ğŸ“ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°: {len(test_cases)}")
        print()
        
        success_count = 0
        total_tests = len(test_cases)
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"{'=' * 60}")
            print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: {test_case['prompt']}")
            print("-" * 60)
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¤åˆ¥ãƒ†ã‚¹ãƒˆ
            detected_context = engine._detect_prompt_context(test_case['prompt'])
            print(f"ğŸ¯ æ¤œå‡ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {detected_context}")
            print(f"ğŸ¯ æœŸå¾…ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {test_case['expected_context']}")
            
            context_match = detected_context == test_case['expected_context']
            print(f"âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¤åˆ¥: {'æˆåŠŸ' if context_match else 'å¤±æ•—'}")
            
            # æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ†ã‚¹ãƒˆ
            generated_queries = engine._generate_search_queries(test_case['prompt'])
            print(f"ğŸ” ç”Ÿæˆã‚¯ã‚¨ãƒªæ•°: {len(generated_queries)}")
            
            # ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªã®è¡¨ç¤ºï¼ˆæœ€åˆã®10å€‹ï¼‰
            print("ğŸ“‹ ç”Ÿæˆã‚¯ã‚¨ãƒªï¼ˆä¸Šä½10å€‹ï¼‰:")
            for j, query in enumerate(generated_queries[:10], 1):
                print(f"  {j:2d}. {query}")
            
            if len(generated_queries) > 10:
                print(f"     ... ä»–{len(generated_queries) - 10}å€‹")
            
            # æœŸå¾…ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®åŒ…å«ãƒã‚§ãƒƒã‚¯
            all_queries_text = " ".join(generated_queries).lower()
            keyword_matches = []
            
            for keyword in test_case['expected_keywords']:
                is_present = keyword.lower() in all_queries_text
                keyword_matches.append(is_present)
                status = "âœ…" if is_present else "âŒ"
                print(f"ğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}': {status}")
            
            # ãƒ†ã‚¹ãƒˆçµæœåˆ¤å®š
            keyword_success_rate = sum(keyword_matches) / len(keyword_matches) if keyword_matches else 0
            overall_success = context_match and keyword_success_rate >= 0.6  # 60%ä»¥ä¸Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹
            
            if overall_success:
                success_count += 1
                print("ğŸ‰ ãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ")
            else:
                print("âŒ ãƒ†ã‚¹ãƒˆçµæœ: å¤±æ•—")
            
            print(f"ğŸ“Š ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åŒ…å«ç‡: {keyword_success_rate:.1%}")
            print()
        
        # å…¨ä½“çµæœ
        print("=" * 60)
        print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"   æˆåŠŸ: {success_count}/{total_tests} ({success_count/total_tests:.1%})")
        print(f"   å¤±æ•—: {total_tests - success_count}/{total_tests}")
        
        if success_count == total_tests:
            print("ğŸŠ å…¨ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
            print("âœ… æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
            return True
        elif success_count >= total_tests * 0.8:  # 80%ä»¥ä¸ŠæˆåŠŸ
            print("â­ ã»ã¼å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ")
            print("âœ… æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã¯ãŠãŠã‚€ã­æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
            return True
        else:
            print("âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
            print("ğŸ”§ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®èª¿æ•´ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“")
            return False
            
    except ImportError as e:
        print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_specific_setsuna_query():
    """ã›ã¤ãªç‰¹åŒ–ã®è¿½åŠ ãƒ†ã‚¹ãƒˆ"""
    
    print("\n" + "=" * 60)
    print("ğŸµ ã›ã¤ãªç‰¹åŒ–ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    try:
        from core.knowledge_analysis.knowledge_analysis_engine import KnowledgeAnalysisEngine
        engine = KnowledgeAnalysisEngine()
        
        setsuna_prompts = [
            "ã›ã¤ãªã®éŸ³æ¥½æ´»å‹•",
            "ã›ã¤ãªã«ã¤ã„ã¦æ•™ãˆã¦",
            "ç‰‡ç„¡ã›ã¤ãªã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«",
            "ã›ã¤ãªã®æ¥½æ›²ã«ã¤ã„ã¦"
        ]
        
        print("ğŸ­ ã›ã¤ãªé–¢é€£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
        
        for prompt in setsuna_prompts:
            print(f"\nğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: '{prompt}'")
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¤åˆ¥
            context = engine._detect_prompt_context(prompt)
            print(f"ğŸ¯ åˆ¤åˆ¥ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}")
            
            # äººç‰©åæŠ½å‡º
            person_name = engine._extract_person_name(prompt)
            print(f"ğŸ‘¤ æŠ½å‡ºäººç‰©å: '{person_name}'")
            
            # ã‚¯ã‚¨ãƒªç”Ÿæˆ
            queries = engine._generate_search_queries(prompt)
            print(f"ğŸ” ç”Ÿæˆã‚¯ã‚¨ãƒª ({len(queries)}å€‹):")
            
            for i, query in enumerate(queries[:8], 1):  # ä¸Šä½8å€‹è¡¨ç¤º
                print(f"  {i}. {query}")
            
            # AIæŠ€è¡“é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„ã“ã¨ã‚’ç¢ºèª
            ai_tech_keywords = ["æœ€æ–°å‹•å‘", "æŠ€è¡“é©æ–°", "ROI", "åŠ¹æœæ¸¬å®š", "å¸‚å ´å‹•å‘"]
            ai_keywords_found = [kw for kw in ai_tech_keywords if any(kw in q for q in queries)]
            
            if ai_keywords_found:
                print(f"âš ï¸ ä¸é©åˆ‡ãªAIæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {ai_keywords_found}")
            else:
                print("âœ… AIæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã›ã¤ãªç‰¹åŒ–ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ”§ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ä¿®æ­£ãƒ†ã‚¹ãƒˆ")
    print(f"{'=' * 60}")
    
    # ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    main_test_result = test_search_query_generation()
    
    # ã›ã¤ãªç‰¹åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    setsuna_test_result = test_specific_setsuna_query()
    
    print(f"\n{'=' * 60}")
    print("ğŸ æœ€çµ‚çµæœ:")
    
    if main_test_result and setsuna_test_result:
        print("ğŸŠ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("âœ… æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®ä¿®æ­£ãŒå®Œäº†ã—ã¦ã„ã¾ã™")
        print("ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé©åˆ‡ã«åæ˜ ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸ")
        exit(0)
    elif main_test_result or setsuna_test_result:
        print("â­ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ")
        print("ğŸ”§ ä¸€éƒ¨èª¿æ•´ãŒå¿…è¦ã§ã™ãŒã€å¤§å¹…ãªæ”¹å–„ãŒç¢ºèªã§ãã¾ã—ãŸ")
        exit(0)
    else:
        print("âŒ ãƒ†ã‚¹ãƒˆã«é‡å¤§ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")
        print("ğŸ”§ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å†ç¢ºèªãŒå¿…è¦ã§ã™")
        exit(1)