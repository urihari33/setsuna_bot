#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPT-4çµ±åˆéŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ 
ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ãƒãƒ£ãƒƒãƒˆ + OpenAI GPT-4 + VOICEVOX
"""

import speech_recognition as sr
import threading
import time
import pyaudio
from pynput import keyboard
from voice_synthesizer import VoiceVoxSynthesizer
from core.setsuna_chat import SetsunaChat

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹
listening = False
recording = False
current_keys = set()
required_keys = {keyboard.Key.ctrl_l, keyboard.Key.shift_l, keyboard.Key.alt_l}
fast_mode_keys = {keyboard.Key.ctrl_l, keyboard.Key.shift_l}  # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ç”¨ã‚­ãƒ¼
audio_frames = []
audio_stream = None
pyaudio_instance = None
current_mode = "full_search"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯é€šå¸¸ãƒ¢ãƒ¼ãƒ‰

# ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
voice_synthesizer = None
setsuna_chat = None
voice_recognizer = None
microphone = None

def start_recording():
    """ãƒ›ãƒƒãƒˆã‚­ãƒ¼åˆ¶å¾¡ã§ã®éŒ²éŸ³é–‹å§‹"""
    global recording, audio_frames, audio_stream, pyaudio_instance
    
    if recording:
        return
    
    try:
        print("ğŸ¤ éŒ²éŸ³é–‹å§‹...")
        print("ğŸ¤ è©±ã—ã¦ãã ã•ã„ï¼ˆãƒ›ãƒƒãƒˆã‚­ãƒ¼ã‚’é›¢ã™ã¾ã§éŒ²éŸ³ç¶™ç¶šï¼‰...")
        
        # PyAudioè¨­å®š
        chunk = 1024
        sample_format = pyaudio.paInt16
        channels = 1
        fs = 44100
        
        # PyAudioã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        pyaudio_instance = pyaudio.PyAudio()
        
        # éŒ²éŸ³ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
        audio_stream = pyaudio_instance.open(
            format=sample_format,
            channels=channels,
            rate=fs,
            frames_per_buffer=chunk,
            input=True
        )
        
        recording = True
        audio_frames = []
        
        # éŒ²éŸ³ãƒ«ãƒ¼ãƒ—ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰
        threading.Thread(target=record_audio_loop, args=(chunk,), daemon=True).start()
        
    except Exception as e:
        print(f"âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
        recording = False

def record_audio_loop(chunk):
    """éŒ²éŸ³ãƒ«ãƒ¼ãƒ—ï¼ˆãƒ›ãƒƒãƒˆã‚­ãƒ¼ãŒé›¢ã•ã‚Œã‚‹ã¾ã§ç¶™ç¶šï¼‰"""
    global recording, audio_frames, audio_stream
    
    while recording and audio_stream:
        try:
            data = audio_stream.read(chunk, exception_on_overflow=False)
            audio_frames.append(data)
        except Exception as e:
            print(f"âš ï¸ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")
            break

def stop_recording_and_recognize():
    """éŒ²éŸ³åœæ­¢ãƒ»éŸ³å£°èªè­˜å®Ÿè¡Œ"""
    global recording, audio_frames, audio_stream, pyaudio_instance, voice_recognizer
    
    if not recording:
        return "éŒ²éŸ³ã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        # éŒ²éŸ³åœæ­¢
        recording = False
        print("âœ… éŒ²éŸ³å®Œäº†")
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if audio_stream:
            audio_stream.stop_stream()
            audio_stream.close()
        if pyaudio_instance:
            pyaudio_instance.terminate()
        
        if not audio_frames:
            print("âŒ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãªã—")
            return "éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        total_frames = len(audio_frames)
        data_size = sum(len(frame) for frame in audio_frames)
        print(f"ğŸ” éŸ³å£°ãƒ‡ãƒ¼ã‚¿: {data_size} bytes ({total_frames} frames)")
        
        # AudioDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥ä½œæˆï¼ˆä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦ï¼‰
        sample_format = pyaudio.paInt16
        channels = 1
        fs = 44100
        
        print("ğŸŒ éŸ³å£°èªè­˜ä¸­...")
        recognition_result = None
        
        try:
            # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
            audio_data = b''.join(audio_frames)
            
            # speech_recognitionã®AudioDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥ä½œæˆ
            audio = sr.AudioData(audio_data, fs, pyaudio.PyAudio().get_sample_size(sample_format))
            
            # GoogleéŸ³å£°èªè­˜APIå‘¼ã³å‡ºã—
            text = voice_recognizer.recognize_google(audio, language="ja-JP")
            print(f"âœ… èªè­˜æˆåŠŸ: '{text}'")
            recognition_result = text
                
        except sr.UnknownValueError:
            print("âŒ éŸ³å£°èªè­˜å¤±æ•—ï¼ˆéŸ³å£°ä¸æ˜ç­ï¼‰")
            recognition_result = "éŸ³å£°ãŒèãå–ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
        except sr.RequestError as e:
            print(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            recognition_result = "éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼"
        except Exception as e:
            print(f"âŒ éŸ³å£°èªè­˜å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            recognition_result = "éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        return recognition_result
                
    except Exception as e:
        print(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return "éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"

def on_key_press(key):
    """ã‚­ãƒ¼æŠ¼ä¸‹å‡¦ç†"""
    global listening, recording, current_mode
    current_keys.add(key)
    
    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆCtrl+Shift+Altï¼‰
    if required_keys.issubset(current_keys) and not listening and not recording:
        listening = True
        current_mode = "full_search"
        print("ğŸ® [é€šå¸¸ãƒ¢ãƒ¼ãƒ‰] ãƒ›ãƒƒãƒˆã‚­ãƒ¼æ¤œå‡º: Ctrl+Shift+Alt - YouTubeæ¤œç´¢å®Ÿè¡Œ")
        start_recording()
    
    # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆShift+Ctrlï¼‰
    elif fast_mode_keys.issubset(current_keys) and keyboard.Key.alt_l not in current_keys and not listening and not recording:
        listening = True
        current_mode = "fast_response"
        print("âš¡ [é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰] ãƒ›ãƒƒãƒˆã‚­ãƒ¼æ¤œå‡º: Shift+Ctrl - æ—¢å­˜çŸ¥è­˜ã§å¿œç­”")
        start_recording()

def on_key_release(key):
    """ã‚­ãƒ¼é›¢ä¸Šå‡¦ç†"""
    global listening, recording
    if key in current_keys:
        current_keys.remove(key)
    
    # ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãŒé›¢ã•ã‚ŒãŸã‚‰éŒ²éŸ³åœæ­¢ãƒ»èªè­˜é–‹å§‹
    if (key in required_keys or key in fast_mode_keys) and recording:
        listening = False
        # éŒ²éŸ³åœæ­¢ã¨éŸ³å£°èªè­˜ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
        threading.Thread(target=handle_voice_recognition, daemon=True).start()

def handle_voice_recognition():
    """éŸ³å£°èªè­˜ãƒ»å¯¾è©±å‡¦ç†"""
    global current_mode
    print(f"ğŸ—£ï¸ éŸ³å£°å¯¾è©±é–‹å§‹ - {current_mode}ãƒ¢ãƒ¼ãƒ‰")
    
    # éŸ³å£°èªè­˜å®Ÿè¡Œ
    user_input = stop_recording_and_recognize()
    
    if user_input and user_input not in ["éŸ³å£°ãŒèãå–ã‚Œã¾ã›ã‚“ã§ã—ãŸ", "éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼", "éŒ²éŸ³ã«å¤±æ•—ã—ã¾ã—ãŸ", "éŒ²éŸ³ã•ã‚Œã¦ã„ã¾ã›ã‚“", "éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", "éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"]:
        print(f"ğŸ‘¤ ã‚ãªãŸ: {user_input}")
        
        # GPT-4å¿œç­”ç”Ÿæˆï¼ˆãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã‚’æ¸¡ã™ï¼‰
        if setsuna_chat:
            if current_mode == "fast_response":
                print("âš¡ ã›ã¤ãªæ€è€ƒä¸­ï¼ˆé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰...")
            else:
                print("ğŸ¤– ã›ã¤ãªæ€è€ƒä¸­ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼‰...")
            response = setsuna_chat.get_response(user_input, mode=current_mode)
            print(f"ğŸ¤– ã›ã¤ãª: {response}")
            
            # Phase 1: URLè¡¨ç¤ºæ©Ÿèƒ½ - å‹•ç”»æ¨è–¦æ™‚ã®URLè¡¨ç¤ºï¼ˆå¿œç­”ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãï¼‰
            try:
                from url_display_manager import show_recommended_urls
                if setsuna_chat.context_builder and hasattr(setsuna_chat.context_builder, 'get_last_context'):
                    last_context = setsuna_chat.context_builder.get_last_context()
                    if last_context and last_context.get('videos'):
                        print(f"ğŸ”— [URLè¡¨ç¤º] æ¨è–¦å‹•ç”»ã‹ã‚‰å¿œç­”è¨€åŠåˆ†ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä¸­...")
                        # ã›ã¤ãªã®å¿œç­”æ–‡ã‚’æ¸¡ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        show_recommended_urls(last_context, response)
            except ImportError:
                # URLè¡¨ç¤ºæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                pass
            except Exception as e:
                print(f"âš ï¸ [URLè¡¨ç¤º] ã‚¨ãƒ©ãƒ¼: {e}")
            
            # éŸ³å£°åˆæˆå®Ÿè¡Œ
            if voice_synthesizer:
                print("ğŸµ éŸ³å£°åˆæˆä¸­...")
                wav_path = voice_synthesizer.synthesize_voice(response)
                if wav_path:
                    voice_synthesizer.play_voice(wav_path)
                    print("âœ… éŸ³å£°å‡ºåŠ›å®Œäº†")
                else:
                    print("âŒ éŸ³å£°åˆæˆå¤±æ•—")
            else:
                print("âš ï¸ éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        else:
            print("âš ï¸ GPT-4ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    else:
        print("ğŸ¤– ã›ã¤ãª: éŸ³å£°ãŒã‚ˆãèã“ãˆã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©±ã—ãã ã•ã„ã€‚")
    
    print("âœ… éŸ³å£°å¯¾è©±å®Œäº†\n")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    global voice_synthesizer, setsuna_chat, voice_recognizer, microphone
    
    print("ğŸ® GPT-4çµ±åˆéŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    print("="*60)
    
    # éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆãƒ›ãƒƒãƒˆã‚­ãƒ¼åˆ¶å¾¡ç”¨ï¼‰
    print("ğŸ¤ éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
    try:
        voice_recognizer = sr.Recognizer()
        print("âœ… éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        print(f"âŒ éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
        print("âš ï¸ SpeechRecognitionãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("   ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        print("   pip install SpeechRecognition")
        return
    
    # éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    print("ğŸ”Š éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
    try:
        voice_synthesizer = VoiceVoxSynthesizer()
        print("âœ… éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        print(f"âš ï¸ éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
        print("   éŸ³å£°èªè­˜ã®ã¿ã§ç¶šè¡Œã—ã¾ã™")
    
    # GPT-4ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    print("ğŸ¤– GPT-4ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
    try:
        setsuna_chat = SetsunaChat()
        print("âœ… GPT-4ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        print(f"âš ï¸ GPT-4ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
        print("   OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        print("   ã‚·ãƒ³ãƒ—ãƒ«å¿œç­”ãƒ¢ãƒ¼ãƒ‰ã§ç¶šè¡Œã—ã¾ã™")
    
    print("="*60)
    print("ğŸ® æ“ä½œæ–¹æ³•:")
    print("   - Ctrl+Shift+Alt ã‚’æŠ¼ã—ã¦ã„ã‚‹é–“éŒ²éŸ³")
    print("   - ã‚­ãƒ¼ã‚’é›¢ã™ã¨éŒ²éŸ³çµ‚äº†ãƒ»éŸ³å£°èªè­˜é–‹å§‹")
    print("   - Ctrl+C ã§çµ‚äº†")
    print("="*60)
    print("ğŸ¤– ã›ã¤ãª: æº–å‚™å®Œäº†ã§ã™ã€‚ãŠè©±ã—ãã ã•ã„ï¼")
    print("="*60)
    
    # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒªã‚¹ãƒŠãƒ¼ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§é–‹å§‹
    listener = keyboard.Listener(on_press=on_key_press, on_release=on_key_release)
    listener.start()
    
    try:
        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§Ctrl+Cã‚’å¾…æ©Ÿ
        while True:
            time.sleep(0.1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†ä¸­...")
        listener.stop()
        print("âœ… ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†å®Œäº†")

if __name__ == "__main__":
    main()