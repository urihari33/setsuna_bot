#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
å¿œç­”é€Ÿåº¦å‘ä¸Šã®ãŸã‚ã®é«˜é€Ÿã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½
"""

import json
import os
import hashlib
import time
from typing import Dict, Optional, List, Tuple
from datetime import datetime, timedelta

class ResponseCache:
    """å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, cache_dir: str = "response_cache"):
        self.cache_dir = cache_dir
        self.cache_file = os.path.join(cache_dir, "response_cache.json")
        self.stats_file = os.path.join(cache_dir, "cache_stats.json")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
        self.max_cache_size = 1000  # æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»¶æ•°
        self.cache_expire_days = 7  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆæ—¥ï¼‰
        self.similarity_threshold = 0.8  # é¡ä¼¼åº¦é–¾å€¤
        
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.memory_cache: Dict[str, Dict] = {}
        self.cache_stats = {
            "hits": 0,
            "misses": 0,
            "total_requests": 0,
            "cache_size": 0
        }
        
        self._initialize_cache()
        
        print(f"ğŸ—„ï¸ å¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        print(f"   - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.cache_dir}")
        print(f"   - æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ•°: {self.max_cache_size}")
        print(f"   - æœ‰åŠ¹æœŸé™: {self.cache_expire_days}æ—¥")
    
    def _initialize_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.memory_cache = json.load(f)
                print(f"âœ… æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿: {len(self.memory_cache)}ä»¶")
            except Exception as e:
                print(f"âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                self.memory_cache = {}
        
        # çµ±è¨ˆæƒ…å ±èª­ã¿è¾¼ã¿
        if os.path.exists(self.stats_file):
            try:
                with open(self.stats_file, 'r', encoding='utf-8') as f:
                    self.cache_stats.update(json.load(f))
            except Exception as e:
                print(f"âš ï¸ çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‰Šé™¤
        self._cleanup_expired_cache()
    
    def _generate_cache_key(self, user_input: str) -> str:
        """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        # æ­£è¦åŒ–ï¼ˆå°æ–‡å­—åŒ–ã€ç©ºç™½å‰Šé™¤ï¼‰
        normalized = user_input.lower().strip()
        
        # ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ
        return hashlib.md5(normalized.encode('utf-8')).hexdigest()
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®é¡ä¼¼åº¦ï¼ˆJaccardä¿‚æ•°ï¼‰
        set1 = set(text1.lower())
        set2 = set(text2.lower())
        
        if not set1 and not set2:
            return 1.0
        
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        
        return intersection / union if union > 0 else 0.0
    
    def get_cached_response(self, user_input: str) -> Optional[str]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å¿œç­”ã‚’å–å¾—"""
        self.cache_stats["total_requests"] += 1
        
        cache_key = self._generate_cache_key(user_input)
        
        # å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        if cache_key in self.memory_cache:
            cache_entry = self.memory_cache[cache_key]
            if self._is_cache_valid(cache_entry):
                self.cache_stats["hits"] += 1
                cache_entry["last_used"] = datetime.now().isoformat()
                cache_entry["use_count"] += 1
                print(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼ˆå®Œå…¨ä¸€è‡´ï¼‰")
                return cache_entry["response"]
        
        # é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢
        for key, cache_entry in self.memory_cache.items():
            if not self._is_cache_valid(cache_entry):
                continue
            
            similarity = self._calculate_similarity(user_input, cache_entry["original_input"])
            if similarity >= self.similarity_threshold:
                self.cache_stats["hits"] += 1
                cache_entry["last_used"] = datetime.now().isoformat()
                cache_entry["use_count"] += 1
                print(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼ˆé¡ä¼¼åº¦: {similarity:.2f}ï¼‰")
                return cache_entry["response"]
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹
        self.cache_stats["misses"] += 1
        print(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹")
        return None
    
    def cache_response(self, user_input: str, response: str):
        """å¿œç­”ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        cache_key = self._generate_cache_key(user_input)
        
        cache_entry = {
            "original_input": user_input,
            "response": response,
            "created_at": datetime.now().isoformat(),
            "last_used": datetime.now().isoformat(),
            "use_count": 1
        }
        
        self.memory_cache[cache_key] = cache_entry
        self.cache_stats["cache_size"] = len(self.memory_cache)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
        if len(self.memory_cache) > self.max_cache_size:
            self._cleanup_old_cache()
        
        print(f"ğŸ’¾ å¿œç­”ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜")
    
    def _is_cache_valid(self, cache_entry: Dict) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            created_at = datetime.fromisoformat(cache_entry["created_at"])
            expiry_date = created_at + timedelta(days=self.cache_expire_days)
            return datetime.now() < expiry_date
        except:
            return False
    
    def _cleanup_expired_cache(self):
        """æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‰Šé™¤"""
        expired_keys = []
        
        for key, cache_entry in self.memory_cache.items():
            if not self._is_cache_valid(cache_entry):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.memory_cache[key]
        
        if expired_keys:
            print(f"ğŸ—‘ï¸ æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤: {len(expired_keys)}ä»¶")
    
    def _cleanup_old_cache(self):
        """å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‰Šé™¤ï¼ˆLRUæ–¹å¼ï¼‰"""
        # ä½¿ç”¨é »åº¦ã¨æœ€çµ‚ä½¿ç”¨æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
        sorted_cache = sorted(
            self.memory_cache.items(),
            key=lambda x: (x[1]["use_count"], x[1]["last_used"])
        )
        
        # å¤ã„ã‚‚ã®ã‹ã‚‰å‰Šé™¤
        remove_count = len(self.memory_cache) - self.max_cache_size + 100
        for i in range(remove_count):
            if i < len(sorted_cache):
                key = sorted_cache[i][0]
                del self.memory_cache[key]
        
        print(f"ğŸ—‘ï¸ å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤: {remove_count}ä»¶")
    
    def save_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.memory_cache, f, ensure_ascii=False, indent=2)
            
            with open(self.stats_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache_stats, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†")
        except Exception as e:
            print(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_cache_stats(self) -> Dict:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆæƒ…å ±å–å¾—"""
        hit_rate = 0.0
        if self.cache_stats["total_requests"] > 0:
            hit_rate = self.cache_stats["hits"] / self.cache_stats["total_requests"]
        
        return {
            **self.cache_stats,
            "hit_rate": hit_rate,
            "cache_size_current": len(self.memory_cache)
        }
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        self.memory_cache.clear()
        self.cache_stats = {
            "hits": 0,
            "misses": 0,
            "total_requests": 0,
            "cache_size": 0
        }
        print("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†")

# ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":
    print("="*50)
    print("ğŸ§ª å¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    cache = ResponseCache()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_cases = [
        ("ã“ã‚“ã«ã¡ã¯", "ã“ã‚“ã«ã¡ã¯ï¼å…ƒæ°—ã§ã™ã‹ï¼Ÿ"),
        ("ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ", "ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚"),
        ("ã“ã‚“ã«ã¡ã‚", "ã“ã‚“ã«ã¡ã¯ï¼å…ƒæ°—ã§ã™ã‹ï¼Ÿ"),  # é¡ä¼¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    ]
    
    for user_input, expected_response in test_cases:
        print(f"\nğŸ‘¤ å…¥åŠ›: {user_input}")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
        cached = cache.get_cached_response(user_input)
        if cached:
            print(f"ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¿œç­”: {cached}")
        else:
            print(f"ğŸ¤– æ–°è¦å¿œç­”: {expected_response}")
            cache.cache_response(user_input, expected_response)
    
    # çµ±è¨ˆè¡¨ç¤º
    stats = cache.get_cache_stats()
    print(f"\nğŸ“Š ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ:")
    print(f"   - ãƒ’ãƒƒãƒˆç‡: {stats['hit_rate']:.1%}")
    print(f"   - ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {stats['total_requests']}")
    print(f"   - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: {stats['cache_size_current']}")
    
    cache.save_cache()