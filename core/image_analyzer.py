#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”»åƒåˆ†æã‚¨ãƒ³ã‚¸ãƒ³ - OpenAI Vision APIçµ±åˆ
å‹•ç”»é–¢é€£ç”»åƒã®è‡ªå‹•åˆ†æãƒ»ç†è§£ã‚·ã‚¹ãƒ†ãƒ 
"""

import base64
import json
import os
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
import requests
from PIL import Image
import openai
from openai import OpenAI
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()


class ImageAnalyzer:
    """OpenAI Vision APIã‚’ä½¿ç”¨ã—ãŸç”»åƒåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, model="gpt-4o"):
        """
        åˆæœŸåŒ–
        
        Args:
            model: ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ï¼ˆVisionå¯¾å¿œï¼‰
        """
        # OpenAI APIè¨­å®š
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        self.client = OpenAI(api_key=self.api_key)
        self.model = model
        
        # è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.max_image_size = (1024, 1024)  # ã‚³ã‚¹ãƒˆæœ€é©åŒ–ç”¨
        self.default_max_tokens = 500
        self.default_temperature = 0.7
        
        # åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.analysis_prompts = self._load_analysis_prompts()
        
        # çµ±è¨ˆæƒ…å ±
        self.analysis_stats = {
            'total_analyses': 0,
            'total_cost': 0.0,
            'total_tokens': 0,
            'last_analysis': None
        }
        
        print("[ç”»åƒåˆ†æ] âœ… ImageAnalyzeråˆæœŸåŒ–å®Œäº†")
    
    def _load_analysis_prompts(self) -> Dict[str, str]:
        """åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        return {
            "general_description": """ã“ã®ç”»åƒã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©³ã—ãåˆ†æã—ã¦ãã ã•ã„ï¼š

ã€åˆ†æé …ç›®ã€‘
1. å…¨ä½“çš„ãªå†…å®¹ãƒ»ã‚·ãƒ¼ãƒ³
2. ä¸»è¦ãªè¦ç´ ï¼ˆäººç‰©ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ†ã‚­ã‚¹ãƒˆãªã©ï¼‰
3. è‰²å½©ãƒ»é›°å›²æ°—ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«
4. æ³¨ç›®ã™ã¹ãè©³ç´°ãƒ»ç‰¹å¾´

ã€å‡ºåŠ›å½¢å¼ã€‘
è‡ªç„¶ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§ã€è©³ç´°ã‹ã¤ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚""",

            "general_with_context": """ã“ã®ç”»åƒã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©³ã—ãåˆ†æã—ã¦ãã ã•ã„ï¼š

ã€åˆ†æé …ç›®ã€‘
1. å…¨ä½“çš„ãªå†…å®¹ãƒ»ã‚·ãƒ¼ãƒ³
2. ä¸»è¦ãªè¦ç´ ï¼ˆäººç‰©ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ†ã‚­ã‚¹ãƒˆãªã©ï¼‰
3. è‰²å½©ãƒ»é›°å›²æ°—ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«
4. æ³¨ç›®ã™ã¹ãè©³ç´°ãƒ»ç‰¹å¾´

ã€å‹•ç”»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘
{video_context}

ã€å‡ºåŠ›å½¢å¼ã€‘
è‡ªç„¶ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§ã€è©³ç´°ã‹ã¤ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚""",

            "music_video_analysis": """ã“ã®éŸ³æ¥½å‹•ç”»ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

ã€åˆ†æé …ç›®ã€‘
1. æ˜ åƒã®ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»æ¼”å‡ºæŠ€æ³•
2. å‡ºæ¼”è€…ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å†…å®¹
3. ã‚»ãƒƒãƒˆãƒ»èƒŒæ™¯ãƒ»è¡£è£…ãƒ‡ã‚¶ã‚¤ãƒ³
4. ç”»é¢ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹æ­Œè©ã‚„ãƒ†ã‚­ã‚¹ãƒˆ
5. æ¥½æ›²ã®é›°å›²æ°—ã¨ã®é–¢é€£æ€§

ã€æ¥½æ›²æƒ…å ±ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {title}
ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ: {artist}
æ¦‚è¦: {description}

ã€å‡ºåŠ›å½¢å¼ã€‘
éŸ³æ¥½å‹•ç”»ã¨ã—ã¦é­…åŠ›çš„ãªç‚¹ã‚’ä¸­å¿ƒã«ã€æ—¥æœ¬èªã§è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚""",

            "scene_elements": """ç”»åƒå†…ã®è¦ç´ ã‚’ä»¥ä¸‹ã®å½¢å¼ã§æ§‹é€ åŒ–ã—ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

ã€æŠ½å‡ºé …ç›®ã€‘
- äººç‰©: [äººæ•°ã€æ€§åˆ¥ã€å¹´é½¢å±¤ã€è¡¨æƒ…ã€å‹•ä½œã€æœè£…]
- ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: [æ¥½å™¨ã€å°é“å…·ã€è£…é£¾ã€å®¶å…·ãªã©]
- ç’°å¢ƒ: [å ´æ‰€ã€æ™‚é–“å¸¯ã€å¤©å€™ã€ç…§æ˜ã€é›°å›²æ°—]
- ãƒ†ã‚­ã‚¹ãƒˆ: [æ­Œè©ã€å­—å¹•ã€çœ‹æ¿ã€ãƒ­ã‚´ãªã©]
- æŠ€è¡“çš„è¦ç´ : [ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«ã€æ§‹å›³ã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ]

å„é …ç›®ã«ã¤ã„ã¦ã€è¦‹ãˆã‚‹ã‚‚ã®ã‚’å…·ä½“çš„ã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚""",

            "text_extraction": """ã“ã®ç”»åƒã«å«ã¾ã‚Œã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’ã™ã¹ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

ã€æŠ½å‡ºå¯¾è±¡ã€‘
- æ­Œè©ãƒ»å­—å¹•
- ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ
- çœ‹æ¿ãƒ»ãƒ­ã‚´
- ãã®ä»–ã™ã¹ã¦ã®æ–‡å­—æƒ…å ±

ã€å‡ºåŠ›å½¢å¼ã€‘
æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å…ƒã®ä½ç½®ãƒ»æ–‡è„ˆã¨å…±ã«æ•´ç†ã—ã¦å ±å‘Šã—ã¦ãã ã•ã„ã€‚""",

            "mood_atmosphere": """ã“ã®ç”»åƒã®é›°å›²æ°—ãƒ»ãƒ ãƒ¼ãƒ‰ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

ã€åˆ†æé …ç›®ã€‘
1. è‰²å½©ã®å°è±¡ï¼ˆæš–è‰²ãƒ»å¯’è‰²ã€æ˜åº¦ã€å½©åº¦ï¼‰
2. æ§‹å›³ãƒ»ç©ºé–“ã®ä½¿ã„æ–¹
3. å…‰ã®ä½¿ã„æ–¹ãƒ»å½±ã®åŠ¹æœ
4. å…¨ä½“çš„ãªæ„Ÿæƒ…ãƒ»é›°å›²æ°—
5. è¦–è´è€…ã«ä¸ãˆã‚‹å°è±¡

ã€å‡ºåŠ›å½¢å¼ã€‘
æ„Ÿæ€§çš„ãªè¦ç´ ã‚‚å«ã‚ã¦ã€è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""
        }
    
    def _resize_image_for_api(self, image_path: str) -> str:
        """
        APIé€ä¿¡ç”¨ã«ç”»åƒã‚µã‚¤ã‚ºã‚’æœ€é©åŒ–
        
        Args:
            image_path: å…ƒç”»åƒã®ãƒ‘ã‚¹
            
        Returns:
            æœ€é©åŒ–ã•ã‚ŒãŸç”»åƒã®ãƒ‘ã‚¹
        """
        try:
            with Image.open(image_path) as img:
                # ã™ã§ã«é©åˆ‡ãªã‚µã‚¤ã‚ºã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                if img.size[0] <= self.max_image_size[0] and img.size[1] <= self.max_image_size[1]:
                    return image_path
                
                # ãƒªã‚µã‚¤ã‚ºãŒå¿…è¦ãªå ´åˆ
                import tempfile
                import uuid
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                temp_dir = Path(tempfile.gettempdir()) / "setsuna_bot_analysis"
                temp_dir.mkdir(exist_ok=True)
                
                unique_id = str(uuid.uuid4())[:8]
                temp_filename = f"resized_{unique_id}.jpg"
                temp_path = temp_dir / temp_filename
                
                # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ä¿æŒã—ã¦ãƒªã‚µã‚¤ã‚º
                img_copy = img.copy()
                img_copy.thumbnail(self.max_image_size, Image.LANCZOS)
                
                # RGBå½¢å¼ã«å¤‰æ›ï¼ˆJPEGä¿å­˜ã®ãŸã‚ï¼‰
                if img_copy.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img_copy.size, (255, 255, 255))
                    if img_copy.mode == 'P':
                        img_copy = img_copy.convert('RGBA')
                    background.paste(img_copy, mask=img_copy.split()[-1] if 'A' in img_copy.mode else None)
                    img_copy = background
                
                # JPEGå½¢å¼ã§ä¿å­˜
                img_copy.save(temp_path, 'JPEG', quality=85)
                
                print(f"[ç”»åƒåˆ†æ] ğŸ“ ç”»åƒãƒªã‚µã‚¤ã‚º: {img.size} â†’ {img_copy.size}")
                return str(temp_path)
                
        except Exception as e:
            print(f"[ç”»åƒåˆ†æ] âŒ ç”»åƒãƒªã‚µã‚¤ã‚ºã‚¨ãƒ©ãƒ¼: {e}")
            return image_path  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒç”»åƒã‚’è¿”ã™
    
    def _encode_image_to_base64(self, image_path: str) -> str:
        """
        ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
        """
        try:
            with open(image_path, 'rb') as image_file:
                encoded_image = base64.b64encode(image_file.read()).decode('utf-8')
                return encoded_image
        except Exception as e:
            print(f"[ç”»åƒåˆ†æ] âŒ Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _call_vision_api(self, prompt: str, image_path: str, max_tokens: int = None, temperature: float = None) -> Dict[str, Any]:
        """
        OpenAI Vision APIã‚’å‘¼ã³å‡ºã—
        
        Args:
            prompt: åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
        Returns:
            APIå¿œç­”ã¨çµ±è¨ˆæƒ…å ±
        """
        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
            max_tokens = max_tokens or self.default_max_tokens
            temperature = temperature or self.default_temperature
            
            # ç”»åƒã®æœ€é©åŒ–
            optimized_image_path = self._resize_image_for_api(image_path)
            
            # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            base64_image = self._encode_image_to_base64(optimized_image_path)
            
            # APIå‘¼ã³å‡ºã—
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                    "detail": "high"  # é«˜å“è³ªåˆ†æ
                                }
                            }
                        ]
                    }
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            end_time = time.time()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            content = response.choices[0].message.content
            tokens_used = response.usage.total_tokens
            
            # ã‚³ã‚¹ãƒˆæ¦‚ç®—è¨ˆç®—ï¼ˆGPT-4o Visionæ¦‚ç®—ï¼‰
            estimated_cost = self._estimate_cost(tokens_used, has_image=True)
            
            # çµ±è¨ˆæ›´æ–°
            self.analysis_stats['total_analyses'] += 1
            self.analysis_stats['total_cost'] += estimated_cost
            self.analysis_stats['total_tokens'] += tokens_used
            self.analysis_stats['last_analysis'] = datetime.now().isoformat()
            
            print(f"[ç”»åƒåˆ†æ] âœ… APIå‘¼ã³å‡ºã—æˆåŠŸ: {tokens_used}ãƒˆãƒ¼ã‚¯ãƒ³, ${estimated_cost:.4f}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if optimized_image_path != image_path:
                try:
                    os.unlink(optimized_image_path)
                except:
                    pass
            
            return {
                'content': content,
                'tokens_used': tokens_used,
                'estimated_cost': estimated_cost,
                'processing_time': end_time - start_time,
                'model': self.model,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"[ç”»åƒåˆ†æ] âŒ Vision APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _estimate_cost(self, tokens: int, has_image: bool = False) -> float:
        """
        APIä½¿ç”¨ã‚³ã‚¹ãƒˆã‚’æ¦‚ç®—
        
        Args:
            tokens: ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            has_image: ç”»åƒãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
            
        Returns:
            æ¨å®šã‚³ã‚¹ãƒˆï¼ˆUSDï¼‰
        """
        # GPT-4oæ–™é‡‘ï¼ˆ2024å¹´æ™‚ç‚¹ã®æ¦‚ç®—ï¼‰
        text_cost_per_1k_tokens = 0.005  # $0.005 per 1K tokens
        image_base_cost = 0.01  # ç”»åƒ1æšã‚ãŸã‚Šã®åŸºæœ¬ã‚³ã‚¹ãƒˆ
        
        text_cost = (tokens / 1000) * text_cost_per_1k_tokens
        image_cost = image_base_cost if has_image else 0
        
        return text_cost + image_cost
    
    def _safe_format_prompt(self, prompt_template: str, context: Dict[str, Any]) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å®‰å…¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        ä¸è¶³ã—ã¦ã„ã‚‹ã‚­ãƒ¼ã‚’è‡ªå‹•çš„ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è£œå®Œ
        
        Args:
            prompt_template: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾è±¡ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¾æ›¸
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        try:
            import string
            import re
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…ã®å…¨ã¦ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æŠ½å‡º
            formatter = string.Formatter()
            placeholders = set()
            
            try:
                for literal_text, field_name, format_spec, conversion in formatter.parse(prompt_template):
                    if field_name:
                        placeholders.add(field_name)
            except Exception as e:
                print(f"[ç”»åƒåˆ†æ] âš ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè§£æã‚¨ãƒ©ãƒ¼: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ­£è¦è¡¨ç¾ã§{key}å½¢å¼ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æŠ½å‡º
                placeholders = set(re.findall(r'\{([^}]+)\}', prompt_template))
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            default_values = {
                'video_context': 'æƒ…å ±ãªã—',
                'title': 'ä¸æ˜',
                'artist': 'ä¸æ˜',
                'description': 'æƒ…å ±ãªã—',
                'channel_title': 'ä¸æ˜',
                'published_at': 'ä¸æ˜',
                'view_count': 'ä¸æ˜'
            }
            
            # ä¸è¶³ã—ã¦ã„ã‚‹ã‚­ãƒ¼ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è£œå®Œ
            safe_context = context.copy()
            for placeholder in placeholders:
                if placeholder not in safe_context:
                    safe_context[placeholder] = default_values.get(placeholder, f'[{placeholder}]')
                    print(f"[ç”»åƒåˆ†æ] ğŸ”§ ä¸è¶³ã‚­ãƒ¼ã‚’è£œå®Œ: {placeholder} = {safe_context[placeholder]}")
            
            # å®‰å…¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            formatted_prompt = prompt_template.format(**safe_context)
            return formatted_prompt
            
        except Exception as e:
            print(f"[ç”»åƒåˆ†æ] âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã®åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™
            return f"ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ã—ãåˆ†æã—ã¦ãã ã•ã„ã€‚\n\næä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}"
    
    def _select_analysis_type(self, requested_type: str, context: Dict[str, Any]) -> str:
        """
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ã¦é©åˆ‡ãªåˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠ
        
        Args:
            requested_type: è¦æ±‚ã•ã‚ŒãŸåˆ†æã‚¿ã‚¤ãƒ—
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            
        Returns:
            åŠ¹æœçš„ãªåˆ†æã‚¿ã‚¤ãƒ—
        """
        # åˆ©ç”¨å¯èƒ½ãªåˆ†æã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
        available_types = list(self.analysis_prompts.keys())
        
        # è¦æ±‚ã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
        if requested_type in available_types:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æœ‰ç„¡ã§ã‚¿ã‚¤ãƒ—ã‚’èª¿æ•´
            if requested_type == "general_description" and context:
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãã®åˆ†æã‚’å„ªå…ˆ
                video_context = context.get('video_context')
                if video_context and "general_with_context" in available_types:
                    return "general_with_context"
            return requested_type
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠãƒ­ã‚¸ãƒƒã‚¯
        if context:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®é¸æŠ
            if any(key in context for key in ['title', 'artist', 'description']):
                return "music_video_analysis"
            elif 'video_context' in context:
                return "general_with_context"
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return "general_description"
    
    def analyze_image(self, image_path: str, analysis_type: str = "general_description", context: Dict = None) -> Dict[str, Any]:
        """
        ç”»åƒã®åŒ…æ‹¬çš„åˆ†æ
        
        Args:
            image_path: åˆ†æã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹
            analysis_type: åˆ†æã‚¿ã‚¤ãƒ—
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            
        Returns:
            åˆ†æçµæœè¾æ›¸
        """
        try:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
            context = context or {}
            
            # åˆ†æã‚¿ã‚¤ãƒ—ã®é©åˆ‡ãªé¸æŠ
            effective_analysis_type = self._select_analysis_type(analysis_type, context)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆå®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ï¼‰
            prompt_template = self.analysis_prompts.get(effective_analysis_type, self.analysis_prompts["general_description"])
            prompt = self._safe_format_prompt(prompt_template, context)
            
            print(f"[ç”»åƒåˆ†æ] ğŸ” åˆ†æé–‹å§‹: {effective_analysis_type}")
            
            # Vision APIå‘¼ã³å‡ºã—
            api_result = self._call_vision_api(prompt, image_path)
            
            # çµæœæ§‹é€ åŒ–
            analysis_result = {
                'analysis_type': effective_analysis_type,
                'image_path': image_path,
                'description': api_result['content'],
                'metadata': {
                    'tokens_used': api_result['tokens_used'],
                    'estimated_cost': api_result['estimated_cost'],
                    'processing_time': api_result['processing_time'],
                    'model': api_result['model'],
                    'timestamp': api_result['timestamp']
                },
                'context': context
            }
            
            return analysis_result
            
        except Exception as e:
            print(f"[ç”»åƒåˆ†æ] âŒ ç”»åƒåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'analysis_type': analysis_type,
                'image_path': image_path,
                'description': f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                'error': str(e),
                'metadata': {
                    'timestamp': datetime.now().isoformat()
                }
            }
    
    def analyze_with_video_context(self, image_path: str, video_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‹•ç”»æƒ…å ±ã¨çµ„ã¿åˆã‚ã›ãŸæ–‡è„ˆåˆ†æ
        
        Args:
            image_path: åˆ†æã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹
            video_info: å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            æ–‡è„ˆåˆ†æçµæœ
        """
        try:
            # å‹•ç”»æƒ…å ±ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
            video_context = f"""
ã‚¿ã‚¤ãƒˆãƒ«: {video_info.get('title', 'ä¸æ˜')}
ãƒãƒ£ãƒ³ãƒãƒ«: {video_info.get('channel_title', 'ä¸æ˜')}
æ¦‚è¦: {video_info.get('description', 'æƒ…å ±ãªã—')[:200]}...
å…¬é–‹æ—¥: {video_info.get('published_at', 'ä¸æ˜')}
å†ç”Ÿå›æ•°: {video_info.get('view_count', 'ä¸æ˜')}
"""
            
            # éŸ³æ¥½å‹•ç”»ã¨ã—ã¦åˆ†æ
            context = {
                'video_context': video_context,
                'title': video_info.get('title', 'ä¸æ˜'),
                'artist': video_info.get('channel_title', 'ä¸æ˜'),
                'description': video_info.get('description', 'æƒ…å ±ãªã—')[:300]
            }
            
            return self.analyze_image(image_path, "music_video_analysis", context)
            
        except Exception as e:
            print(f"[ç”»åƒåˆ†æ] âŒ å‹•ç”»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self.analyze_image(image_path, "general_description")
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """åˆ†æçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return self.analysis_stats.copy()
    
    def reset_stats(self):
        """çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.analysis_stats = {
            'total_analyses': 0,
            'total_cost': 0.0,
            'total_tokens': 0,
            'last_analysis': None
        }
        print("[ç”»åƒåˆ†æ] ğŸ“Š çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")


def test_image_analyzer():
    """ImageAnalyzerã®åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ"""
    print("=== ImageAnalyzer ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # åˆæœŸåŒ–
        analyzer = ImageAnalyzer()
        
        # çµ±è¨ˆæƒ…å ±ç¢ºèª
        stats = analyzer.get_analysis_stats()
        print(f"âœ… åˆæœŸçµ±è¨ˆ: {stats}")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç¢ºèª
        prompts = analyzer.analysis_prompts
        print(f"âœ… åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°: {len(prompts)}")
        
        print("âœ… ImageAnalyzeråŸºæœ¬æ©Ÿèƒ½æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ ImageAnalyzerãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
    
    print("=== ImageAnalyzer ãƒ†ã‚¹ãƒˆå®Œäº† ===")


if __name__ == "__main__":
    test_image_analyzer()