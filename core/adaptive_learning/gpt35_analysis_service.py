#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPT35AnalysisService - GPT-3.5-turboã‚’ä½¿ç”¨ã—ãŸåˆ†æã‚µãƒ¼ãƒ“ã‚¹
ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã•ã‚ŒãŸæ¤œç´¢æ–¹å‘åˆ†æã¨çµæœè§£æã‚·ã‚¹ãƒ†ãƒ 
"""

from openai import OpenAI
import json
import os
import sys
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ç¢ºå®Ÿã«ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from core.adaptive_learning.accurate_cost_calculator import AccurateCostCalculator
except ImportError:
    try:
        from .accurate_cost_calculator import AccurateCostCalculator
    except ImportError:
        from accurate_cost_calculator import AccurateCostCalculator

class GPT35AnalysisService:
    """GPT-3.5-turboåˆ†æã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # .envãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆpython-dotenvãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å„ªå…ˆä½¿ç”¨ï¼‰
        try:
            from dotenv import load_dotenv
            env_path = Path(__file__).parent.parent.parent / ".env"
            load_dotenv(env_path)
        except ImportError:
            # python-dotenvãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯æ‰‹å‹•èª­ã¿è¾¼ã¿
            env_path = Path(__file__).parent.parent.parent / ".env"
            if env_path.exists():
                try:
                    with open(env_path, 'r', encoding='utf-8') as f:
                        for line in f:
                            if line.startswith('OPENAI_API_KEY='):
                                os.environ['OPENAI_API_KEY'] = line.split('=', 1)[1].strip()
                except UnicodeDecodeError:
                    # Windowsç’°å¢ƒã§cp932ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®å¯¾å‡¦
                    try:
                        with open(env_path, 'r', encoding='cp932') as f:
                            for line in f:
                                if line.startswith('OPENAI_API_KEY='):
                                    os.environ['OPENAI_API_KEY'] = line.split('=', 1)[1].strip()
                    except UnicodeDecodeError:
                        # æœ€å¾Œã®æ‰‹æ®µ: latin-1ã§èª­ã¿è¾¼ã¿
                        with open(env_path, 'r', encoding='latin-1') as f:
                            for line in f:
                                if line.startswith('OPENAI_API_KEY='):
                                    os.environ['OPENAI_API_KEY'] = line.split('=', 1)[1].strip()
                except Exception as e:
                    print(f"âš ï¸ .envãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    print("ç’°å¢ƒå¤‰æ•°OPENAI_API_KEYã‚’ç›´æ¥è¨­å®šã—ã¦ãã ã•ã„")
        
        # OpenAI APIè¨­å®š
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.client = OpenAI(api_key=api_key)
        self.model = "gpt-3.5-turbo"
        self.cost_calculator = AccurateCostCalculator()
        self.analysis_history = []
        
    def analyze_search_direction(self, user_prompt: str) -> Dict:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰æ¤œç´¢æ–¹å‘ã‚’åˆ†æ"""
        
        system_prompt = """ã‚ãªãŸã¯æƒ…å ±æ¢ç´¢ã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†æã—ã€åŠ¹æœçš„ãªæ¤œç´¢æ–¹å‘ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
1. ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: [3-5å€‹ã®é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰]
2. æ¤œç´¢æ–¹å‘: [3ã¤ã®å…·ä½“çš„ãªæ¤œç´¢æ–¹å‘]
3. æ¢ç´¢æˆ¦ç•¥: [åŠ¹æœçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ–¹æ³•]

ç°¡æ½”ã§å®Ÿç”¨çš„ãªææ¡ˆã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"""

        user_message = f"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {user_prompt}

ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦ã€DuckDuckGoæ¤œç´¢ã§åŠ¹æœçš„ãªæƒ…å ±åé›†ã‚’è¡Œã†ãŸã‚ã®æ¤œç´¢æ–¹å‘ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=300,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content.strip()
            
            # ã‚³ã‚¹ãƒˆè¨ˆç®—
            cost = self.cost_calculator.calculate_gpt_cost(
                input_text=system_prompt + user_message,
                output_text=analysis_result
            )
            
            # å±¥æ­´è¨˜éŒ²
            analysis_record = {
                "timestamp": datetime.now().isoformat(),
                "type": "search_direction_analysis",
                "user_prompt": user_prompt,
                "analysis_result": analysis_result,
                "cost": cost,
                "tokens": {
                    "input": len(self.cost_calculator.tokenizer.encode(system_prompt + user_message)),
                    "output": len(self.cost_calculator.tokenizer.encode(analysis_result))
                }
            }
            self.analysis_history.append(analysis_record)
            
            return {
                "analysis": analysis_result,
                "cost": cost,
                "search_queries": self._extract_search_queries(analysis_result),
                "metadata": analysis_record
            }
            
        except Exception as e:
            print(f"âŒ GPT-3.5åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_fallback_analysis(user_prompt)
    
    def analyze_search_results(self, search_results: List[Dict], original_prompt: str) -> Dict:
        """æ¤œç´¢çµæœã‚’åˆ†æã—ã¦è¦ç´„ãƒ»æ¬¡ã®æ–¹å‘æ€§ã‚’æç¤º"""
        
        # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«æ•´ç†
        results_text = ""
        for i, result in enumerate(search_results, 1):
            results_text += f"{i}. {result['title']}\n   {result['snippet']}\n   å‡ºå…¸: {result['source']}\n\n"
        
        system_prompt = """ã‚ãªãŸã¯æƒ…å ±åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
æ¤œç´¢çµæœã‚’åˆ†æã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:

1. ä¸»è¦ãªç™ºè¦‹: [é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ2-3å€‹]
2. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ: [ç¾åœ¨ã®å‹•å‘]
3. æ¬¡ã®æ¢ç´¢æ–¹å‘: [3ã¤ã®å…·ä½“çš„ãªææ¡ˆ]

å®Ÿç”¨çš„ã§å…·ä½“çš„ãªåˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"""

        user_message = f"""
å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {original_prompt}

æ¤œç´¢çµæœ:
{results_text}

ã“ã‚Œã‚‰ã®æ¤œç´¢çµæœã‚’åˆ†æã—ã€ä¸»è¦ãªç™ºè¦‹ã‚’ã¾ã¨ã‚ã€ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã¹ãæ–¹å‘æ€§ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=400,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content.strip()
            
            # ã‚³ã‚¹ãƒˆè¨ˆç®—
            cost = self.cost_calculator.calculate_gpt_cost(
                input_text=system_prompt + user_message,
                output_text=analysis_result
            )
            
            # å±¥æ­´è¨˜éŒ²
            analysis_record = {
                "timestamp": datetime.now().isoformat(),
                "type": "search_results_analysis",
                "original_prompt": original_prompt,
                "results_count": len(search_results),
                "analysis_result": analysis_result,
                "cost": cost
            }
            self.analysis_history.append(analysis_record)
            
            return {
                "analysis": analysis_result,
                "cost": cost,
                "next_directions": self._extract_next_directions(analysis_result),
                "metadata": analysis_record
            }
            
        except Exception as e:
            print(f"âŒ GPT-3.5çµæœåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_fallback_results_analysis(search_results, original_prompt)
    
    def generate_next_exploration_options(self, current_analysis: str, user_feedback: str = "") -> Dict:
        """æ¬¡ã®æ¢ç´¢é¸æŠè‚¢ã‚’ç”Ÿæˆ"""
        
        system_prompt = """ã‚ãªãŸã¯æ¢ç´¢æˆ¦ç•¥ã®å°‚é–€å®¶ã§ã™ã€‚
ç¾åœ¨ã®åˆ†æçµæœã‚’åŸºã«ã€æ¬¡ã®æ¢ç´¢ã‚¹ãƒ†ãƒƒãƒ—ã®é¸æŠè‚¢ã‚’3ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚

å„é¸æŠè‚¢ã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„:
- æ¢ç´¢æ–¹å‘ã®èª¬æ˜
- æœŸå¾…ã•ã‚Œã‚‹ç™ºè¦‹
- å…·ä½“çš„ãªæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"""

        user_message = f"""
ç¾åœ¨ã®åˆ†æçµæœ:
{current_analysis}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {user_feedback}

æ¬¡ã®æ¢ç´¢ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€3ã¤ã®ç•°ãªã‚‹æ–¹å‘æ€§ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=350,
                temperature=0.8
            )
            
            options_result = response.choices[0].message.content.strip()
            
            # ã‚³ã‚¹ãƒˆè¨ˆç®—
            cost = self.cost_calculator.calculate_gpt_cost(
                input_text=system_prompt + user_message,
                output_text=options_result
            )
            
            # å±¥æ­´è¨˜éŒ²
            analysis_record = {
                "timestamp": datetime.now().isoformat(),
                "type": "next_exploration_options",
                "current_analysis": current_analysis,
                "user_feedback": user_feedback,
                "options_result": options_result,
                "cost": cost
            }
            self.analysis_history.append(analysis_record)
            
            return {
                "options": options_result,
                "cost": cost,
                "parsed_options": self._parse_exploration_options(options_result),
                "metadata": analysis_record
            }
            
        except Exception as e:
            print(f"âŒ GPT-3.5é¸æŠè‚¢ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_fallback_options(current_analysis)
    
    def _extract_search_queries(self, analysis_text: str) -> List[str]:
        """åˆ†æçµæœã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡º"""
        queries = []
        lines = analysis_text.split('\n')
        
        for line in lines:
            if 'æ¤œç´¢æ–¹å‘' in line or 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰' in line:
                # ç°¡å˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã§æ¤œç´¢èªã‚’æŠ½å‡º
                if ':' in line:
                    query_part = line.split(':', 1)[1].strip()
                    if query_part and len(query_part) > 3:
                        queries.append(query_part)
        
        # åŸºæœ¬çš„ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not queries:
            queries = ["æŠ€è¡“å‹•å‘", "å®Ÿè£…äº‹ä¾‹", "ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹"]
        
        return queries[:3]
    
    def _extract_next_directions(self, analysis_text: str) -> List[str]:
        """åˆ†æçµæœã‹ã‚‰æ¬¡ã®æ–¹å‘æ€§ã‚’æŠ½å‡º"""
        directions = []
        lines = analysis_text.split('\n')
        
        for line in lines:
            if 'æ¬¡ã®' in line or 'æ–¹å‘' in line or 'ææ¡ˆ' in line:
                if ':' in line:
                    direction = line.split(':', 1)[1].strip()
                    if direction and len(direction) > 5:
                        directions.append(direction)
        
        if not directions:
            directions = ["è©³ç´°èª¿æŸ»", "é–¢é€£åˆ†é‡å±•é–‹", "å®Ÿè·µå¿œç”¨"]
        
        return directions[:3]
    
    def _parse_exploration_options(self, options_text: str) -> List[Dict]:
        """æ¢ç´¢é¸æŠè‚¢ã‚’ãƒ‘ãƒ¼ã‚¹"""
        options = []
        current_option = {}
        
        lines = options_text.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith(('1.', '2.', '3.', 'â—', 'ãƒ»')):
                if current_option:
                    options.append(current_option)
                current_option = {"title": line, "description": "", "keywords": []}
            elif line and current_option:
                if 'æœŸå¾…' in line or 'ç™ºè¦‹' in line:
                    current_option["expected"] = line
                elif 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰' in line:
                    current_option["keywords"] = line.split(':')[-1].strip().split(',')
                else:
                    current_option["description"] += line + " "
        
        if current_option:
            options.append(current_option)
        
        return options
    
    def _generate_fallback_analysis(self, user_prompt: str) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æï¼ˆAPIå¤±æ•—æ™‚ï¼‰"""
        return {
            "analysis": f"{user_prompt}ã«é–¢ã™ã‚‹åŸºæœ¬çš„ãªæ¤œç´¢æ–¹å‘ã‚’ææ¡ˆã—ã¾ã™ã€‚ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€å®Ÿè£…äº‹ä¾‹ã€æœ€æ–°å‹•å‘ã®3ã¤ã®è»¸ã§æƒ…å ±åé›†ã‚’è¡Œã†ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
            "cost": 0.0,
            "search_queries": [f"{user_prompt} åŸºæœ¬", f"{user_prompt} äº‹ä¾‹", f"{user_prompt} å‹•å‘"],
            "metadata": {"fallback": True, "timestamp": datetime.now().isoformat()}
        }
    
    def _generate_fallback_results_analysis(self, search_results: List[Dict], original_prompt: str) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœåˆ†æ"""
        return {
            "analysis": f"{len(search_results)}ä»¶ã®æ¤œç´¢çµæœã‹ã‚‰ã€{original_prompt}ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚è©³ç´°ãªæŠ€è¡“æƒ…å ±ã€å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã€æœ€æ–°å‹•å‘ã«ã¤ã„ã¦è¿½åŠ èª¿æŸ»ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
            "cost": 0.0,
            "next_directions": ["æŠ€è¡“è©³ç´°", "å®Ÿè£…æ–¹æ³•", "å¿œç”¨äº‹ä¾‹"],
            "metadata": {"fallback": True, "timestamp": datetime.now().isoformat()}
        }
    
    def _generate_fallback_options(self, current_analysis: str) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é¸æŠè‚¢ç”Ÿæˆ"""
        return {
            "options": "1. ã‚ˆã‚Šæ·±ã„æŠ€è¡“è©³ç´°ã®èª¿æŸ»\n2. é–¢é€£æŠ€è¡“é ˜åŸŸã¸ã®å±•é–‹\n3. å®Ÿè·µçš„ãªå¿œç”¨æ–¹æ³•ã®æ¢ç´¢",
            "cost": 0.0,
            "parsed_options": [
                {"title": "æŠ€è¡“è©³ç´°èª¿æŸ»", "description": "è©³ç´°ãªæŠ€è¡“ä»•æ§˜ã¨å®Ÿè£…æ–¹æ³•"},
                {"title": "é–¢é€£æŠ€è¡“å±•é–‹", "description": "é–¢é€£ã™ã‚‹æŠ€è¡“åˆ†é‡ã¸ã®å±•é–‹"},
                {"title": "å®Ÿè·µå¿œç”¨", "description": "å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®å¿œç”¨æ–¹æ³•"}
            ],
            "metadata": {"fallback": True, "timestamp": datetime.now().isoformat()}
        }
    
    def get_total_cost(self) -> float:
        """ç·ã‚³ã‚¹ãƒˆå–å¾—"""
        return sum(record["cost"] for record in self.analysis_history)
    
    def get_analysis_summary(self) -> Dict:
        """åˆ†æå±¥æ­´ã®è¦ç´„"""
        if not self.analysis_history:
            return {"total_analyses": 0, "total_cost": 0.0}
        
        total_cost = self.get_total_cost()
        total_analyses = len(self.analysis_history)
        avg_cost = total_cost / total_analyses if total_analyses > 0 else 0
        
        return {
            "total_analyses": total_analyses,
            "total_cost": total_cost,
            "average_cost_per_analysis": avg_cost,
            "recent_analyses": self.analysis_history[-3:] if len(self.analysis_history) >= 3 else self.analysis_history
        }
    
    def save_analysis_history(self, filepath: str):
        """åˆ†æå±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        history_data = {
            "analysis_history": self.analysis_history,
            "summary": self.get_analysis_summary(),
            "cost_calculator_summary": self.cost_calculator.get_cost_summary(),
            "saved_at": datetime.now().isoformat()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    try:
        service = GPT35AnalysisService()
        
        print("ğŸ¤– GPT-3.5åˆ†æã‚µãƒ¼ãƒ“ã‚¹ - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        test_prompt = "AIæŠ€è¡“ã®æœ€æ–°å‹•å‘ã«ã¤ã„ã¦è©³ã—ãèª¿ã¹ãŸã„"
        
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: '{test_prompt}'")
        
        # æ¤œç´¢æ–¹å‘åˆ†æ
        direction_analysis = service.analyze_search_direction(test_prompt)
        print(f"âœ… æ–¹å‘åˆ†æå®Œäº† (ã‚³ã‚¹ãƒˆ: ${direction_analysis['cost']:.6f})")
        print(f"ææ¡ˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª: {direction_analysis['search_queries']}")
        
        # ãƒ¢ãƒƒã‚¯æ¤œç´¢çµæœã§ã®çµæœåˆ†æãƒ†ã‚¹ãƒˆ
        mock_results = [
            {"title": "AIæŠ€è¡“æœ€æ–°å‹•å‘", "snippet": "2025å¹´ã®AIæŠ€è¡“é€²å±•", "source": "Tech News"},
            {"title": "GPT-4æ´»ç”¨äº‹ä¾‹", "snippet": "ä¼æ¥­ã§ã®GPT-4å°å…¥ä¾‹", "source": "Business AI"}
        ]
        
        results_analysis = service.analyze_search_results(mock_results, test_prompt)
        print(f"âœ… çµæœåˆ†æå®Œäº† (ã‚³ã‚¹ãƒˆ: ${results_analysis['cost']:.6f})")
        
        # æ¬¡ã®é¸æŠè‚¢ç”Ÿæˆ
        options = service.generate_next_exploration_options(results_analysis['analysis'])
        print(f"âœ… é¸æŠè‚¢ç”Ÿæˆå®Œäº† (ã‚³ã‚¹ãƒˆ: ${options['cost']:.6f})")
        
        # ç·ã‚³ã‚¹ãƒˆè¡¨ç¤º
        total_cost = service.get_total_cost()
        print(f"\nğŸ’° ç·ã‚³ã‚¹ãƒˆ: ${total_cost:.6f}")
        
        # çµæœä¿å­˜
        output_path = Path("D:/setsuna_bot/data/adaptive_learning/gpt35_analysis_test.json")
        output_path.parent.mkdir(parents=True, exist_ok=True)
        service.save_analysis_history(str(output_path))
        print(f"ğŸ’¾ ãƒ†ã‚¹ãƒˆçµæœä¿å­˜: {output_path}")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print("æ³¨æ„: OpenAI API ã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")