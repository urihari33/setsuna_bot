#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¥½ã¿é€²åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ - Phase 2Då®Ÿè£…
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿å¤‰åŒ–äºˆæ¸¬ãƒ»æ–°èˆˆå‘³é ˜åŸŸç™ºè¦‹ãƒ»å€‹äººåŒ–ãƒ¬ãƒ™ãƒ«ç¶™ç¶šå‘ä¸Š
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
from datetime import datetime, timedelta
import numpy as np
from statistics import mean, median, stdev
import hashlib

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# é–¢é€£ã‚·ã‚¹ãƒ†ãƒ 
try:
    from core.user_interest_tracker import UserInterestTracker
    from core.conversation_history_analyzer import ConversationHistoryAnalyzer
    DEPENDENCIES_AVAILABLE = True
except ImportError:
    DEPENDENCIES_AVAILABLE = False

# Windowsãƒ‘ã‚¹è¨­å®š
if os.name == 'nt':
    DATA_DIR = Path("D:/setsuna_bot/data")
    EVOLUTION_CACHE_DIR = Path("D:/setsuna_bot/preference_evolution_cache")
else:
    DATA_DIR = Path("/mnt/d/setsuna_bot/data")
    EVOLUTION_CACHE_DIR = Path("/mnt/d/setsuna_bot/preference_evolution_cache")

EVOLUTION_CACHE_DIR.mkdir(parents=True, exist_ok=True)

@dataclass
class PreferenceEvolution:
    """å¥½ã¿é€²åŒ–ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    evolution_id: str
    topic: str
    evolution_type: str          # "emerging", "strengthening", "weakening", "shifting"
    confidence: float
    timeline: List[Dict[str, Any]]  # é€²åŒ–ã®æ™‚ç³»åˆ—
    trigger_events: List[str]    # é€²åŒ–ã®ãã£ã‹ã‘ã‚¤ãƒ™ãƒ³ãƒˆ
    prediction_accuracy: float  # äºˆæ¸¬ç²¾åº¦
    last_updated: str

@dataclass
class EmergingInterest:
    """æ–°èˆˆèˆˆå‘³ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    interest_id: str
    topic: str
    emergence_strength: float   # å‡ºç¾å¼·åº¦
    discovery_context: Dict[str, Any]  # ç™ºè¦‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    growth_trajectory: List[float]     # æˆé•·è»Œè·¡
    related_existing_interests: List[str]  # é–¢é€£ã™ã‚‹æ—¢å­˜èˆˆå‘³
    emergence_triggers: List[str]      # å‡ºç¾ãƒˆãƒªã‚¬ãƒ¼
    predicted_potential: float         # å°†æ¥æ€§äºˆæ¸¬
    discovered_at: str

@dataclass
class PersonalizationInsight:
    """å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    insight_id: str
    insight_type: str           # "pattern", "preference", "behavior", "recommendation"
    description: str
    confidence: float
    actionable_suggestions: List[str]  # å®Ÿè¡Œå¯èƒ½ãªææ¡ˆ
    impact_prediction: float    # ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆäºˆæ¸¬
    validation_status: str      # "pending", "confirmed", "rejected"
    created_at: str

class PreferenceEvolutionEngine:
    """å¥½ã¿é€²åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
        self.preference_evolutions_path = EVOLUTION_CACHE_DIR / "preference_evolutions.json"
        self.emerging_interests_path = EVOLUTION_CACHE_DIR / "emerging_interests.json"
        self.personalization_insights_path = EVOLUTION_CACHE_DIR / "personalization_insights.json"
        self.evolution_models_path = EVOLUTION_CACHE_DIR / "evolution_models.json"
        
        # ä¾å­˜ã‚·ã‚¹ãƒ†ãƒ 
        if DEPENDENCIES_AVAILABLE:
            self.interest_tracker = UserInterestTracker()
            self.history_analyzer = ConversationHistoryAnalyzer()
        else:
            self.interest_tracker = None
            self.history_analyzer = None
            print("[å¥½ã¿é€²åŒ–] âš ï¸ ä¾å­˜ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # ãƒ‡ãƒ¼ã‚¿
        self.preference_evolutions = {}
        self.emerging_interests = {}
        self.personalization_insights = {}
        self.evolution_models = {}
        
        # é€²åŒ–æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.evolution_threshold = 0.2      # é€²åŒ–æ¤œå‡ºé–¾å€¤
        self.emergence_threshold = 0.15     # æ–°èˆˆæ¤œå‡ºé–¾å€¤
        self.confidence_threshold = 0.6     # ä¿¡é ¼åº¦é–¾å€¤
        self.prediction_window = 30         # äºˆæ¸¬ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆæ—¥ï¼‰
        
        # é€²åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
        self.evolution_patterns = self._build_evolution_patterns()
        self.emergence_indicators = self._build_emergence_indicators()
        self.personalization_factors = self._build_personalization_factors()
        
        # çµ±è¨ˆæƒ…å ±
        self.evolution_statistics = {
            "total_evolutions_tracked": 0,
            "emerging_interests_discovered": 0,
            "insights_generated": 0,
            "prediction_accuracy": 0.0,
            "last_analysis": None
        }
        
        self._load_existing_data()
        print("[å¥½ã¿é€²åŒ–] âœ… å¥½ã¿é€²åŒ–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def _build_evolution_patterns(self) -> Dict[str, Dict[str, Any]]:
        """é€²åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰"""
        return {
            "strengthening": {
                "indicators": [
                    "èˆˆå‘³ãƒ¬ãƒ™ãƒ«ç¶™ç¶šä¸Šæ˜‡",
                    "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé »åº¦å¢—åŠ ",
                    "æ·±æ˜ã‚Šè³ªå•å¢—åŠ ",
                    "é–¢é€£ãƒˆãƒ”ãƒƒã‚¯æ‹¡å¼µ"
                ],
                "threshold": 0.3,
                "duration_days": 7
            },
            "weakening": {
                "indicators": [
                    "è¨€åŠé »åº¦æ¸›å°‘",
                    "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆä½ä¸‹",
                    "é–¢å¿ƒè¡¨ç¾ã®æ¶ˆå¤±",
                    "ä»–ãƒˆãƒ”ãƒƒã‚¯ã¸ã®ç§»è¡Œ"
                ],
                "threshold": -0.2,
                "duration_days": 14
            },
            "shifting": {
                "indicators": [
                    "é–¢é€£é ˜åŸŸã¸ã®ç§»å‹•",
                    "æ–°ã—ã„åˆ‡ã‚Šå£ã§ã®è¨€åŠ",
                    "è¦–ç‚¹ã®å¤‰åŒ–",
                    "ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¤‰æ›´"
                ],
                "threshold": 0.25,
                "duration_days": 10
            },
            "emerging": {
                "indicators": [
                    "æ–°è¦ãƒˆãƒ”ãƒƒã‚¯åˆå›è¨€åŠ",
                    "æ€¥æ¿€ãªèˆˆå‘³ãƒ¬ãƒ™ãƒ«ä¸Šæ˜‡",
                    "é›†ä¸­çš„ãªè³ªå•",
                    "é–¢é€£æ¤œç´¢è¡Œå‹•"
                ],
                "threshold": 0.4,
                "duration_days": 3
            }
        }
    
    def _build_emergence_indicators(self) -> Dict[str, List[str]]:
        """æ–°èˆˆæŒ‡æ¨™æ§‹ç¯‰"""
        return {
            "discovery_signals": [
                "åˆã‚ã¦çŸ¥ã£ãŸ", "æ–°ã—ã„ç™ºè¦‹", "ã“ã‚“ãªã®ãŒã‚ã‚‹ã‚“ã ", "èˆˆå‘³æ·±ã„",
                "é¢ç™½ãã†", "ã‚„ã£ã¦ã¿ãŸã„", "å­¦ã‚“ã§ã¿ãŸã„", "æŒ‘æˆ¦ã—ãŸã„"
            ],
            "exploration_signals": [
                "ã‚‚ã£ã¨è©³ã—ã", "ä»–ã«ã‚‚ã‚ã‚‹?", "ä¼¼ãŸã‚ˆã†ãªã®", "é–¢é€£ã™ã‚‹",
                "ã©ã‚“ãªç¨®é¡", "ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³", "å¿œç”¨", "ç™ºå±•"
            ],
            "commitment_signals": [
                "ç¶šã‘ãŸã„", "æ·±ãå­¦ã³ãŸã„", "æ¥µã‚ãŸã„", "å°‚é–€çš„ã«",
                "æœ¬æ ¼çš„ã«", "çœŸå‰£ã«", "é›†ä¸­ã—ã¦", "æ™‚é–“ã‚’ã‹ã‘ã¦"
            ]
        }
    
    def _build_personalization_factors(self) -> Dict[str, Dict[str, Any]]:
        """å€‹äººåŒ–è¦å› æ§‹ç¯‰"""
        return {
            "temporal_patterns": {
                "description": "æ™‚é–“çš„æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³",
                "weight": 0.2,
                "indicators": ["activity_hours", "session_frequency", "duration_preferences"]
            },
            "content_preferences": {
                "description": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å¥½ã¿å‚¾å‘",
                "weight": 0.3,
                "indicators": ["topic_preferences", "complexity_level", "format_preferences"]
            },
            "interaction_style": {
                "description": "å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«",
                "weight": 0.25,
                "indicators": ["question_patterns", "engagement_depth", "exploration_tendency"]
            },
            "learning_patterns": {
                "description": "å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³",
                "weight": 0.25,
                "indicators": ["knowledge_acquisition", "skill_progression", "interest_evolution"]
            }
        }
    
    def _load_existing_data(self):
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰"""
        # å¥½ã¿é€²åŒ–
        try:
            if self.preference_evolutions_path.exists():
                with open(self.preference_evolutions_path, 'r', encoding='utf-8') as f:
                    evolutions_data = json.load(f)
                    self.preference_evolutions = {
                        eid: PreferenceEvolution(**evolution) 
                        for eid, evolution in evolutions_data.get("evolutions", {}).items()
                    }
                print(f"[å¥½ã¿é€²åŒ–] ğŸ“Š {len(self.preference_evolutions)}å€‹ã®å¥½ã¿é€²åŒ–ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[å¥½ã¿é€²åŒ–] âš ï¸ å¥½ã¿é€²åŒ–ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ–°èˆˆèˆˆå‘³
        try:
            if self.emerging_interests_path.exists():
                with open(self.emerging_interests_path, 'r', encoding='utf-8') as f:
                    interests_data = json.load(f)
                    self.emerging_interests = {
                        iid: EmergingInterest(**interest) 
                        for iid, interest in interests_data.get("interests", {}).items()
                    }
                print(f"[å¥½ã¿é€²åŒ–] ğŸ“Š {len(self.emerging_interests)}å€‹ã®æ–°èˆˆèˆˆå‘³ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[å¥½ã¿é€²åŒ–] âš ï¸ æ–°èˆˆèˆˆå‘³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        # å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        try:
            if self.personalization_insights_path.exists():
                with open(self.personalization_insights_path, 'r', encoding='utf-8') as f:
                    insights_data = json.load(f)
                    self.personalization_insights = {
                        iid: PersonalizationInsight(**insight) 
                        for iid, insight in insights_data.get("insights", {}).items()
                    }
                print(f"[å¥½ã¿é€²åŒ–] ğŸ“Š {len(self.personalization_insights)}å€‹ã®å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[å¥½ã¿é€²åŒ–] âš ï¸ å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    def analyze_preference_evolution(self) -> Dict[str, PreferenceEvolution]:
        """å¥½ã¿é€²åŒ–åˆ†æ"""
        print("[å¥½ã¿é€²åŒ–] ğŸ“ˆ å¥½ã¿é€²åŒ–ã‚’åˆ†æä¸­...")
        
        if not self.interest_tracker:
            print("[å¥½ã¿é€²åŒ–] âš ï¸ èˆˆå‘³è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return {}
        
        evolutions = {}
        
        # å„ãƒˆãƒ”ãƒƒã‚¯ã®é€²åŒ–åˆ†æ
        for topic, metrics in self.interest_tracker.interest_metrics.items():
            evolution = self._analyze_topic_evolution(topic, metrics)
            if evolution:
                evolutions[evolution.evolution_id] = evolution
        
        self.preference_evolutions = evolutions
        self._save_preference_evolutions()
        
        print(f"[å¥½ã¿é€²åŒ–] âœ… {len(evolutions)}å€‹ã®å¥½ã¿é€²åŒ–ã‚’æ¤œå‡º")
        return evolutions
    
    def _analyze_topic_evolution(self, topic: str, metrics) -> Optional[PreferenceEvolution]:
        """ãƒˆãƒ”ãƒƒã‚¯é€²åŒ–åˆ†æ"""
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—
        timeline_data = self._get_topic_timeline(topic)
        
        if len(timeline_data) < 3:  # æœ€å°ãƒ‡ãƒ¼ã‚¿é‡
            return None
        
        # é€²åŒ–ã‚¿ã‚¤ãƒ—æ¤œå‡º
        evolution_type = self._detect_evolution_type(timeline_data, metrics)
        
        if evolution_type == "stable":  # é€²åŒ–ãªã—
            return None
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_evolution_confidence(timeline_data, evolution_type)
        
        if confidence < self.confidence_threshold:
            return None
        
        # ãƒˆãƒªã‚¬ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º
        trigger_events = self._extract_trigger_events(topic, timeline_data)
        
        # äºˆæ¸¬ç²¾åº¦è©•ä¾¡
        prediction_accuracy = self._evaluate_prediction_accuracy(timeline_data, evolution_type)
        
        evolution_id = f"evolution_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        return PreferenceEvolution(
            evolution_id=evolution_id,
            topic=topic,
            evolution_type=evolution_type,
            confidence=confidence,
            timeline=timeline_data,
            trigger_events=trigger_events,
            prediction_accuracy=prediction_accuracy,
            last_updated=datetime.now().isoformat()
        )
    
    def _get_topic_timeline(self, topic: str) -> List[Dict[str, Any]]:
        """ãƒˆãƒ”ãƒƒã‚¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        timeline = []
        
        if not self.interest_tracker:
            return timeline
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰æ™‚ç³»åˆ—æ§‹ç¯‰
        topic_events = [
            event for event in self.interest_tracker.engagement_events 
            if event.topic == topic
        ]
        
        # æ—¥æ¬¡é›†è¨ˆ
        daily_data = defaultdict(list)
        for event in topic_events:
            date_key = event.timestamp[:10]  # YYYY-MM-DD
            daily_data[date_key].append(event)
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        for date, events in sorted(daily_data.items()):
            daily_intensity = mean([event.intensity for event in events])
            daily_frequency = len(events)
            
            timeline.append({
                "date": date,
                "intensity": daily_intensity,
                "frequency": daily_frequency,
                "event_types": list(set(event.event_type for event in events))
            })
        
        return timeline
    
    def _detect_evolution_type(self, timeline_data: List[Dict], metrics) -> str:
        """é€²åŒ–ã‚¿ã‚¤ãƒ—æ¤œå‡º"""
        if len(timeline_data) < 3:
            return "stable"
        
        # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ
        recent_data = timeline_data[-3:]
        early_data = timeline_data[:3]
        
        recent_avg_intensity = mean([data["intensity"] for data in recent_data])
        early_avg_intensity = mean([data["intensity"] for data in early_data])
        
        intensity_change = recent_avg_intensity - early_avg_intensity
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for pattern_type, pattern_config in self.evolution_patterns.items():
            threshold = pattern_config["threshold"]
            
            if pattern_type == "strengthening" and intensity_change > threshold:
                return "strengthening"
            elif pattern_type == "weakening" and intensity_change < threshold:
                return "weakening"
            elif pattern_type == "emerging" and self._is_emerging_pattern(timeline_data):
                return "emerging"
            elif pattern_type == "shifting" and self._is_shifting_pattern(timeline_data):
                return "shifting"
        
        return "stable"
    
    def _is_emerging_pattern(self, timeline_data: List[Dict]) -> bool:
        """æ–°èˆˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š"""
        if len(timeline_data) < 2:
            return False
        
        # æœ€åˆã®æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãŒä½ãã€å¾ŒåŠã§æ€¥ä¸Šæ˜‡
        first_half = timeline_data[:len(timeline_data)//2]
        second_half = timeline_data[len(timeline_data)//2:]
        
        first_avg = mean([data["intensity"] for data in first_half])
        second_avg = mean([data["intensity"] for data in second_half])
        
        return first_avg < 0.3 and second_avg > 0.6
    
    def _is_shifting_pattern(self, timeline_data: List[Dict]) -> bool:
        """å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š"""
        if len(timeline_data) < 3:
            return False
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®å¤‰åŒ–ã‚’æ¤œæŸ»
        early_types = set()
        late_types = set()
        
        for data in timeline_data[:len(timeline_data)//2]:
            early_types.update(data["event_types"])
        
        for data in timeline_data[len(timeline_data)//2:]:
            late_types.update(data["event_types"])
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®å¤‰åŒ–åº¦
        overlap = len(early_types.intersection(late_types))
        total_unique = len(early_types.union(late_types))
        
        change_ratio = 1 - (overlap / total_unique if total_unique > 0 else 1)
        
        return change_ratio > 0.5
    
    def _calculate_evolution_confidence(self, timeline_data: List[Dict], evolution_type: str) -> float:
        """é€²åŒ–ä¿¡é ¼åº¦è¨ˆç®—"""
        confidence = 0.0
        
        # ãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        data_confidence = min(0.3, len(timeline_data) / 10)
        confidence += data_confidence
        
        # ä¸€è²«æ€§ã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        intensities = [data["intensity"] for data in timeline_data]
        if len(intensities) > 1:
            consistency = 1 - (stdev(intensities) if len(intensities) > 1 else 0)
            consistency_confidence = consistency * 0.3
            confidence += consistency_confidence
        
        # é€²åŒ–ã‚¿ã‚¤ãƒ—ç‰¹æœ‰ã®ä¿¡é ¼åº¦
        type_specific_confidence = self._calculate_type_specific_confidence(
            timeline_data, evolution_type
        )
        confidence += type_specific_confidence
        
        return min(1.0, confidence)
    
    def _calculate_type_specific_confidence(self, timeline_data: List[Dict], evolution_type: str) -> float:
        """ã‚¿ã‚¤ãƒ—ç‰¹æœ‰ä¿¡é ¼åº¦è¨ˆç®—"""
        if evolution_type == "strengthening":
            # å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰ã®ä¸€è²«æ€§
            intensities = [data["intensity"] for data in timeline_data]
            increasing_count = sum(
                1 for i in range(1, len(intensities)) 
                if intensities[i] > intensities[i-1]
            )
            return (increasing_count / max(1, len(intensities) - 1)) * 0.4
        
        elif evolution_type == "emerging":
            # æ€¥æ¿€ãªä¸Šæ˜‡ã®æ˜ç¢ºã•
            if len(timeline_data) >= 2:
                start_intensity = timeline_data[0]["intensity"]
                end_intensity = timeline_data[-1]["intensity"]
                emergence_strength = end_intensity - start_intensity
                return min(0.4, emergence_strength)
        
        elif evolution_type == "weakening":
            # æ¸›å°‘ãƒˆãƒ¬ãƒ³ãƒ‰ã®ä¸€è²«æ€§
            intensities = [data["intensity"] for data in timeline_data]
            decreasing_count = sum(
                1 for i in range(1, len(intensities)) 
                if intensities[i] < intensities[i-1]
            )
            return (decreasing_count / max(1, len(intensities) - 1)) * 0.4
        
        return 0.2  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _extract_trigger_events(self, topic: str, timeline_data: List[Dict]) -> List[str]:
        """ãƒˆãƒªã‚¬ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º"""
        triggers = []
        
        # æ€¥æ¿€ãªå¤‰åŒ–ç‚¹ã‚’æ¤œå‡º
        for i in range(1, len(timeline_data)):
            prev_data = timeline_data[i-1]
            curr_data = timeline_data[i]
            
            intensity_change = curr_data["intensity"] - prev_data["intensity"]
            
            if abs(intensity_change) > 0.3:  # å¤§ããªå¤‰åŒ–
                trigger_description = f"å¼·åº¦å¤‰åŒ–: {intensity_change:.2f} ({prev_data['date']} -> {curr_data['date']})"
                triggers.append(trigger_description)
        
        # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®å‡ºç¾
        seen_types = set()
        for data in timeline_data:
            current_types = set(data["event_types"])
            new_types = current_types - seen_types
            
            if new_types:
                triggers.append(f"æ–°ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—: {', '.join(new_types)} ({data['date']})")
            
            seen_types.update(current_types)
        
        return triggers[:5]  # æœ€å¤§5ã¤
    
    def _evaluate_prediction_accuracy(self, timeline_data: List[Dict], evolution_type: str) -> float:
        """äºˆæ¸¬ç²¾åº¦è©•ä¾¡"""
        # ç°¡æ˜“å®Ÿè£…ï¼šé€²åŒ–ã‚¿ã‚¤ãƒ—ã®ä¸€è²«æ€§ã«åŸºã¥ã
        if len(timeline_data) < 3:
            return 0.5
        
        # å‰åŠãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã—å¾ŒåŠãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼
        split_point = len(timeline_data) // 2
        prediction_data = timeline_data[:split_point]
        validation_data = timeline_data[split_point:]
        
        # äºˆæ¸¬ãƒˆãƒ¬ãƒ³ãƒ‰
        pred_trend = self._detect_evolution_type(prediction_data, None)
        
        # æ¤œè¨¼ãƒˆãƒ¬ãƒ³ãƒ‰
        val_trend = self._detect_evolution_type(validation_data, None)
        
        # ä¸€è‡´åº¦
        if pred_trend == val_trend:
            return 0.9
        elif pred_trend in ["strengthening", "emerging"] and val_trend in ["strengthening", "emerging"]:
            return 0.7
        elif pred_trend in ["weakening"] and val_trend in ["weakening"]:
            return 0.7
        else:
            return 0.3
    
    def discover_emerging_interests(self) -> Dict[str, EmergingInterest]:
        """æ–°èˆˆèˆˆå‘³ç™ºè¦‹"""
        print("[å¥½ã¿é€²åŒ–] ğŸ” æ–°èˆˆèˆˆå‘³ã‚’ç™ºè¦‹ä¸­...")
        
        if not self.interest_tracker:
            print("[å¥½ã¿é€²åŒ–] âš ï¸ èˆˆå‘³è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return {}
        
        emerging = {}
        
        # æœ€è¿‘ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆåˆ†æ
        recent_cutoff = datetime.now() - timedelta(days=7)
        recent_events = [
            event for event in self.interest_tracker.engagement_events
            if datetime.fromisoformat(event.timestamp) > recent_cutoff
        ]
        
        # ãƒˆãƒ”ãƒƒã‚¯åˆ¥æ–°èˆˆåº¦è©•ä¾¡
        topic_emergence = defaultdict(list)
        for event in recent_events:
            topic_emergence[event.topic].append(event)
        
        for topic, events in topic_emergence.items():
            emergence = self._evaluate_topic_emergence(topic, events)
            if emergence:
                emerging[emergence.interest_id] = emergence
        
        self.emerging_interests = emerging
        self._save_emerging_interests()
        
        print(f"[å¥½ã¿é€²åŒ–] âœ… {len(emerging)}å€‹ã®æ–°èˆˆèˆˆå‘³ã‚’ç™ºè¦‹")
        return emerging
    
    def _evaluate_topic_emergence(self, topic: str, events: List) -> Optional[EmergingInterest]:
        """ãƒˆãƒ”ãƒƒã‚¯æ–°èˆˆåº¦è©•ä¾¡"""
        if len(events) < 2:
            return None
        
        # æ–°èˆˆå¼·åº¦è¨ˆç®—
        emergence_strength = self._calculate_emergence_strength(topic, events)
        
        if emergence_strength < self.emergence_threshold:
            return None
        
        # ç™ºè¦‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        discovery_context = self._build_discovery_context(events)
        
        # æˆé•·è»Œè·¡
        growth_trajectory = self._calculate_growth_trajectory(events)
        
        # é–¢é€£æ—¢å­˜èˆˆå‘³
        related_interests = self._find_related_existing_interests(topic)
        
        # å‡ºç¾ãƒˆãƒªã‚¬ãƒ¼
        emergence_triggers = self._identify_emergence_triggers(events)
        
        # å°†æ¥æ€§äºˆæ¸¬
        predicted_potential = self._predict_interest_potential(topic, events)
        
        interest_id = f"emerging_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        return EmergingInterest(
            interest_id=interest_id,
            topic=topic,
            emergence_strength=emergence_strength,
            discovery_context=discovery_context,
            growth_trajectory=growth_trajectory,
            related_existing_interests=related_interests,
            emergence_triggers=emergence_triggers,
            predicted_potential=predicted_potential,
            discovered_at=datetime.now().isoformat()
        )
    
    def _calculate_emergence_strength(self, topic: str, events: List) -> float:
        """æ–°èˆˆå¼·åº¦è¨ˆç®—"""
        # çŸ­æœŸé–“ã§ã®æ€¥æ¿€ãªå¢—åŠ 
        time_span = (
            datetime.fromisoformat(events[-1].timestamp) - 
            datetime.fromisoformat(events[0].timestamp)
        ).total_seconds() / 86400  # æ—¥æ•°
        
        if time_span == 0:
            time_span = 1
        
        # ã‚¤ãƒ™ãƒ³ãƒˆå¯†åº¦
        event_density = len(events) / time_span
        
        # å¹³å‡å¼·åº¦
        avg_intensity = mean([event.intensity for event in events])
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—å¤šæ§˜æ€§
        unique_types = len(set(event.event_type for event in events))
        type_diversity = min(1.0, unique_types / 3)  # æœ€å¤§3ã‚¿ã‚¤ãƒ—
        
        # ç·åˆæ–°èˆˆå¼·åº¦
        emergence_strength = (
            min(1.0, event_density / 2) * 0.4 +  # å¯†åº¦ï¼ˆ1æ—¥2å›ã§æœ€å¤§ï¼‰
            avg_intensity * 0.4 +                 # å¼·åº¦
            type_diversity * 0.2                  # å¤šæ§˜æ€§
        )
        
        return emergence_strength
    
    def _build_discovery_context(self, events: List) -> Dict[str, Any]:
        """ç™ºè¦‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰"""
        return {
            "first_mention": events[0].timestamp,
            "trigger_context": events[0].context[:100],
            "initial_event_type": events[0].event_type,
            "discovery_intensity": events[0].intensity,
            "total_events": len(events),
            "event_types": list(set(event.event_type for event in events))
        }
    
    def _calculate_growth_trajectory(self, events: List) -> List[float]:
        """æˆé•·è»Œè·¡è¨ˆç®—"""
        # æ™‚ç³»åˆ—ã§ã®å¼·åº¦å¤‰åŒ–
        trajectory = []
        
        # æ™‚é–“é †ã‚½ãƒ¼ãƒˆ
        sorted_events = sorted(events, key=lambda e: e.timestamp)
        
        # ç´¯ç©å¼·åº¦
        cumulative_intensity = 0
        for event in sorted_events:
            cumulative_intensity += event.intensity
            trajectory.append(cumulative_intensity / len(trajectory) if trajectory else event.intensity)
        
        return trajectory
    
    def _find_related_existing_interests(self, topic: str) -> List[str]:
        """é–¢é€£æ—¢å­˜èˆˆå‘³æ¤œç´¢"""
        if not self.interest_tracker:
            return []
        
        related = []
        
        # å…±èµ·åˆ†æ
        for existing_topic in self.interest_tracker.interest_metrics.keys():
            if existing_topic != topic:
                correlation = self._calculate_topic_correlation(topic, existing_topic)
                if correlation > 0.3:
                    related.append(existing_topic)
        
        return related[:3]  # ä¸Šä½3ã¤
    
    def _calculate_topic_correlation(self, topic1: str, topic2: str) -> float:
        """ãƒˆãƒ”ãƒƒã‚¯ç›¸é–¢è¨ˆç®—"""
        if not self.interest_tracker:
            return 0.0
        
        # åŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…å…±èµ·ç‡
        session_with_topic1 = set()
        session_with_topic2 = set()
        
        for event in self.interest_tracker.engagement_events:
            session_key = event.timestamp[:13]  # æ™‚é–“ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
            if event.topic == topic1:
                session_with_topic1.add(session_key)
            elif event.topic == topic2:
                session_with_topic2.add(session_key)
        
        if not session_with_topic1 or not session_with_topic2:
            return 0.0
        
        intersection = len(session_with_topic1.intersection(session_with_topic2))
        union = len(session_with_topic1.union(session_with_topic2))
        
        return intersection / union if union > 0 else 0.0
    
    def _identify_emergence_triggers(self, events: List) -> List[str]:
        """å‡ºç¾ãƒˆãƒªã‚¬ãƒ¼è­˜åˆ¥"""
        triggers = []
        
        # åˆå›ã‚¤ãƒ™ãƒ³ãƒˆåˆ†æ
        first_event = events[0]
        trigger_context = first_event.context.lower()
        
        # ç™ºè¦‹ã‚·ã‚°ãƒŠãƒ«æ¤œå‡º
        for signal_type, signals in self.emergence_indicators.items():
            for signal in signals:
                if signal in trigger_context:
                    triggers.append(f"{signal_type}: {signal}")
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—é·ç§»
        if len(events) > 1:
            type_sequence = [event.event_type for event in events]
            triggers.append(f"ã‚¤ãƒ™ãƒ³ãƒˆé·ç§»: {' -> '.join(type_sequence[:3])}")
        
        return triggers[:3]
    
    def _predict_interest_potential(self, topic: str, events: List) -> float:
        """èˆˆå‘³å°†æ¥æ€§äºˆæ¸¬"""
        # æˆé•·é€Ÿåº¦
        if len(events) >= 2:
            time_span = (
                datetime.fromisoformat(events[-1].timestamp) - 
                datetime.fromisoformat(events[0].timestamp)
            ).total_seconds() / 86400
            
            growth_rate = len(events) / max(1, time_span)
        else:
            growth_rate = 1.0
        
        # å¼·åº¦ãƒˆãƒ¬ãƒ³ãƒ‰
        intensities = [event.intensity for event in events]
        intensity_trend = (intensities[-1] - intensities[0]) if len(intensities) > 1 else 0
        
        # å¤šæ§˜æ€§
        type_diversity = len(set(event.event_type for event in events)) / 4  # æ­£è¦åŒ–
        
        # ç·åˆå°†æ¥æ€§
        potential = (
            min(1.0, growth_rate / 3) * 0.4 +  # æˆé•·ç‡
            max(0, intensity_trend) * 0.4 +    # å¼·åº¦å‘ä¸Š
            type_diversity * 0.2                # å¤šæ§˜æ€§
        )
        
        return min(1.0, potential)
    
    def generate_personalization_insights(self) -> Dict[str, PersonalizationInsight]:
        """å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ"""
        print("[å¥½ã¿é€²åŒ–] ğŸ’¡ å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆä¸­...")
        
        insights = {}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        pattern_insights = self._generate_pattern_insights()
        insights.update(pattern_insights)
        
        # å¥½ã¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        preference_insights = self._generate_preference_insights()
        insights.update(preference_insights)
        
        # è¡Œå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        behavior_insights = self._generate_behavior_insights()
        insights.update(behavior_insights)
        
        # æ¨è–¦ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        recommendation_insights = self._generate_recommendation_insights()
        insights.update(recommendation_insights)
        
        self.personalization_insights = insights
        self._save_personalization_insights()
        
        print(f"[å¥½ã¿é€²åŒ–] âœ… {len(insights)}å€‹ã®å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆ")
        return insights
    
    def _generate_pattern_insights(self) -> Dict[str, PersonalizationInsight]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ"""
        insights = {}
        
        # æ´»å‹•æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³
        if self.interest_tracker and self.interest_tracker.engagement_events:
            hour_activity = defaultdict(int)
            
            for event in self.interest_tracker.engagement_events:
                try:
                    hour = datetime.fromisoformat(event.timestamp).hour
                    hour_activity[hour] += 1
                except:
                    continue
            
            if hour_activity:
                peak_hour = max(hour_activity.items(), key=lambda x: x[1])[0]
                
                insight_id = f"pattern_temporal_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                insights[insight_id] = PersonalizationInsight(
                    insight_id=insight_id,
                    insight_type="pattern",
                    description=f"æœ€ã‚‚æ´»ç™ºãªæ™‚é–“å¸¯ã¯{peak_hour}æ™‚é ƒã§ã™",
                    confidence=0.8,
                    actionable_suggestions=[
                        f"{peak_hour}æ™‚é ƒã«æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ææ¡ˆ",
                        "é›†ä¸­çš„ãªå­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åŒæ™‚é–“å¸¯ã«è¨­å®š",
                        "é‡è¦ãªæƒ…å ±ã¯æ´»å‹•ãƒ”ãƒ¼ã‚¯æ™‚ã«æä¾›"
                    ],
                    impact_prediction=0.7,
                    validation_status="pending",
                    created_at=datetime.now().isoformat()
                )
        
        return insights
    
    def _generate_preference_insights(self) -> Dict[str, PersonalizationInsight]:
        """å¥½ã¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ"""
        insights = {}
        
        if self.interest_tracker:
            # èˆˆå‘³ãƒ¬ãƒ™ãƒ«ä¸Šä½ãƒˆãƒ”ãƒƒã‚¯
            top_interests = sorted(
                self.interest_tracker.interest_metrics.items(),
                key=lambda x: x[1].current_level,
                reverse=True
            )[:3]
            
            if top_interests:
                top_topics = [topic for topic, _ in top_interests]
                
                insight_id = f"preference_top_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                insights[insight_id] = PersonalizationInsight(
                    insight_id=insight_id,
                    insight_type="preference",
                    description=f"ä¸»è¦èˆˆå‘³åˆ†é‡: {', '.join(top_topics)}",
                    confidence=0.9,
                    actionable_suggestions=[
                        f"{top_topics[0]}ã«é–¢é€£ã™ã‚‹æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆè¡¨ç¤º",
                        "èˆˆå‘³åˆ†é‡ã‚’çµ„ã¿åˆã‚ã›ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ææ¡ˆ",
                        "å°‚é–€æ€§ã‚’æ·±ã‚ã‚‹å­¦ç¿’ãƒ‘ã‚¹ã‚’æä¾›"
                    ],
                    impact_prediction=0.8,
                    validation_status="pending",
                    created_at=datetime.now().isoformat()
                )
        
        return insights
    
    def _generate_behavior_insights(self) -> Dict[str, PersonalizationInsight]:
        """è¡Œå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ"""
        insights = {}
        
        if self.history_analyzer and self.history_analyzer.user_behavior_profile:
            profile = self.history_analyzer.user_behavior_profile
            
            # å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æ
            dominant_style = max(profile.conversation_style.items(), key=lambda x: x[1])
            
            insight_id = f"behavior_style_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            insights[insight_id] = PersonalizationInsight(
                insight_id=insight_id,
                insight_type="behavior",
                description=f"ä¸»è¦ãªå¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«: {dominant_style[0]}",
                confidence=0.75,
                actionable_suggestions=[
                    f"{dominant_style[0]}ã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ãŸæƒ…å ±æç¤º",
                    "å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å€‹äººåŒ–",
                    "è³ªå•å½¢å¼ã®æœ€é©åŒ–"
                ],
                impact_prediction=0.6,
                validation_status="pending",
                created_at=datetime.now().isoformat()
            )
        
        return insights
    
    def _generate_recommendation_insights(self) -> Dict[str, PersonalizationInsight]:
        """æ¨è–¦ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ"""
        insights = {}
        
        # æ–°èˆˆèˆˆå‘³ã«åŸºã¥ãæ¨è–¦
        for interest in self.emerging_interests.values():
            if interest.predicted_potential > 0.7:
                insight_id = f"recommendation_emerging_{interest.topic}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                insights[insight_id] = PersonalizationInsight(
                    insight_id=insight_id,
                    insight_type="recommendation",
                    description=f"æ–°èˆˆèˆˆå‘³ã€Œ{interest.topic}ã€ã®æˆé•·æ”¯æ´",
                    confidence=interest.predicted_potential,
                    actionable_suggestions=[
                        f"{interest.topic}ã®åŸºç¤çŸ¥è­˜ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æä¾›",
                        "é–¢é€£ã™ã‚‹æ—¢å­˜èˆˆå‘³ã¨ã®æ¥ç¶šç‚¹æç¤º",
                        "æ®µéšçš„ãªå­¦ç¿’ãƒ‘ã‚¹è¨­è¨ˆ"
                    ],
                    impact_prediction=interest.predicted_potential,
                    validation_status="pending",
                    created_at=datetime.now().isoformat()
                )
        
        return insights
    
    def predict_future_preferences(self, prediction_days: int = 30) -> Dict[str, Any]:
        """å°†æ¥å¥½ã¿äºˆæ¸¬"""
        print(f"[å¥½ã¿é€²åŒ–] ğŸ”® {prediction_days}æ—¥å¾Œã®å¥½ã¿ã‚’äºˆæ¸¬ä¸­...")
        
        predictions = {
            "timeframe_days": prediction_days,
            "predicted_interests": {},
            "emerging_candidates": [],
            "declining_candidates": [],
            "stable_interests": [],
            "confidence": 0.0
        }
        
        if not self.interest_tracker:
            return predictions
        
        # å„èˆˆå‘³ã®å°†æ¥äºˆæ¸¬
        for topic, metrics in self.interest_tracker.interest_metrics.items():
            future_level = self._predict_topic_future_level(topic, metrics, prediction_days)
            
            predictions["predicted_interests"][topic] = {
                "current_level": metrics.current_level,
                "predicted_level": future_level,
                "change": future_level - metrics.current_level,
                "trend": metrics.trend_direction
            }
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
            change = future_level - metrics.current_level
            if change > 0.2:
                predictions["emerging_candidates"].append(topic)
            elif change < -0.2:
                predictions["declining_candidates"].append(topic)
            else:
                predictions["stable_interests"].append(topic)
        
        # å…¨ä½“ä¿¡é ¼åº¦
        predictions["confidence"] = self._calculate_prediction_confidence()
        
        print(f"[å¥½ã¿é€²åŒ–] âœ… äºˆæ¸¬å®Œäº† (ä¿¡é ¼åº¦: {predictions['confidence']:.2f})")
        return predictions
    
    def _predict_topic_future_level(self, topic: str, metrics, prediction_days: int) -> float:
        """ãƒˆãƒ”ãƒƒã‚¯å°†æ¥ãƒ¬ãƒ™ãƒ«äºˆæ¸¬"""
        current_level = metrics.current_level
        trend = metrics.trend_direction
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¹äºˆæ¸¬
        if trend == "increasing":
            growth_rate = 0.01 * prediction_days  # 1æ—¥1%æˆé•·
            future_level = min(1.0, current_level + growth_rate)
        elif trend == "decreasing":
            decay_rate = 0.005 * prediction_days  # 1æ—¥0.5%æ¸›è¡°
            future_level = max(0.0, current_level - decay_rate)
        else:  # stable
            # è‡ªç„¶æ¸›è¡°
            decay_factor = 0.98 ** prediction_days
            future_level = current_level * decay_factor
        
        return future_level
    
    def _calculate_prediction_confidence(self) -> float:
        """äºˆæ¸¬ä¿¡é ¼åº¦è¨ˆç®—"""
        # ãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        data_confidence = 0.0
        if self.interest_tracker:
            event_count = len(self.interest_tracker.engagement_events)
            data_confidence = min(0.4, event_count / 100)
        
        # é€²åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        pattern_confidence = min(0.3, len(self.preference_evolutions) / 10)
        
        # ä¸€è²«æ€§ã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        consistency_confidence = 0.3  # åŸºæœ¬å€¤
        
        return data_confidence + pattern_confidence + consistency_confidence
    
    def _save_preference_evolutions(self):
        """å¥½ã¿é€²åŒ–ä¿å­˜"""
        try:
            evolutions_data = {
                "evolutions": {eid: asdict(evolution) for eid, evolution in self.preference_evolutions.items()},
                "metadata": {
                    "total_evolutions": len(self.preference_evolutions),
                    "last_updated": datetime.now().isoformat()
                }
            }
            
            with open(self.preference_evolutions_path, 'w', encoding='utf-8') as f:
                json.dump(evolutions_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[å¥½ã¿é€²åŒ–] âš ï¸ å¥½ã¿é€²åŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_emerging_interests(self):
        """æ–°èˆˆèˆˆå‘³ä¿å­˜"""
        try:
            interests_data = {
                "interests": {iid: asdict(interest) for iid, interest in self.emerging_interests.items()},
                "metadata": {
                    "total_interests": len(self.emerging_interests),
                    "last_updated": datetime.now().isoformat()
                }
            }
            
            with open(self.emerging_interests_path, 'w', encoding='utf-8') as f:
                json.dump(interests_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[å¥½ã¿é€²åŒ–] âš ï¸ æ–°èˆˆèˆˆå‘³ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_personalization_insights(self):
        """å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆä¿å­˜"""
        try:
            insights_data = {
                "insights": {iid: asdict(insight) for iid, insight in self.personalization_insights.items()},
                "metadata": {
                    "total_insights": len(self.personalization_insights),
                    "last_updated": datetime.now().isoformat()
                }
            }
            
            with open(self.personalization_insights_path, 'w', encoding='utf-8') as f:
                json.dump(insights_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[å¥½ã¿é€²åŒ–] âš ï¸ å€‹äººåŒ–ã‚¤ãƒ³ã‚µã‚¤ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def perform_comprehensive_evolution_analysis(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„é€²åŒ–åˆ†æå®Ÿè¡Œ"""
        print("[å¥½ã¿é€²åŒ–] ğŸ”¬ åŒ…æ‹¬çš„é€²åŒ–åˆ†æã‚’å®Ÿè¡Œä¸­...")
        
        # å„ç¨®åˆ†æå®Ÿè¡Œ
        evolutions = self.analyze_preference_evolution()
        emerging = self.discover_emerging_interests()
        insights = self.generate_personalization_insights()
        predictions = self.predict_future_preferences()
        
        # çµ±è¨ˆæ›´æ–°
        self.evolution_statistics.update({
            "total_evolutions_tracked": len(evolutions),
            "emerging_interests_discovered": len(emerging),
            "insights_generated": len(insights),
            "prediction_accuracy": predictions.get("confidence", 0.0),
            "last_analysis": datetime.now().isoformat()
        })
        
        analysis_result = {
            "evolutions": evolutions,
            "emerging_interests": emerging,
            "insights": insights,
            "predictions": predictions,
            "statistics": self.evolution_statistics
        }
        
        print("[å¥½ã¿é€²åŒ–] âœ… åŒ…æ‹¬çš„é€²åŒ–åˆ†æå®Œäº†")
        return analysis_result
    
    def get_evolution_summary(self) -> Dict[str, Any]:
        """é€²åŒ–ã‚µãƒãƒªãƒ¼å–å¾—"""
        return {
            "current_evolutions": len(self.preference_evolutions),
            "emerging_interests": len(self.emerging_interests),
            "active_insights": len([
                i for i in self.personalization_insights.values() 
                if i.validation_status != "rejected"
            ]),
            "statistics": self.evolution_statistics,
            "top_emerging": [
                {
                    "topic": interest.topic,
                    "strength": interest.emergence_strength,
                    "potential": interest.predicted_potential
                }
                for interest in sorted(
                    self.emerging_interests.values(),
                    key=lambda x: x.predicted_potential,
                    reverse=True
                )[:3]
            ]
        }