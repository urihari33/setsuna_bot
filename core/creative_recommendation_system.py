#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‰µé€ çš„æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  - Phase 3-A
æ„å¤–æ€§ã®ã‚ã‚‹ç‹¬å‰µçš„ãªæ¨è–¦ç†ç”±ã¨æ¥½æ›²é–“ã®éš ã‚ŒãŸé–¢é€£æ€§ç™ºè¦‹
"""

import random
import re
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from collections import defaultdict, Counter
import math

class CreativeRecommendationSystem:
    """å‰µé€ çš„ã§ç‹¬å‰µçš„ãªæ¨è–¦ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # Windowsç’°å¢ƒã¨WSL2ç’°å¢ƒä¸¡æ–¹ã«å¯¾å¿œ
        if os.name == 'nt':  # Windows
            self.recommendation_file = Path("D:/setsuna_bot/data/creative_recommendations.json")
        else:  # Linux/WSL2
            self.recommendation_file = Path("/mnt/d/setsuna_bot/data/creative_recommendations.json")
        
        # å‰µé€ çš„é–¢é€£æ€§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.creative_patterns = self._build_creative_patterns()
        self.narrative_templates = self._build_narrative_templates()
        self.connection_types = self._build_connection_types()
        self.surprise_factors = self._build_surprise_factors()
        
        # æ¨è–¦å±¥æ­´ï¼ˆå¤šæ§˜æ€§ç¢ºä¿ã®ãŸã‚ï¼‰
        self.recommendation_history = []
        
        self._ensure_data_dir()
        self._load_recommendation_data()
        
        print("[å‰µé€ æ¨è–¦] âœ… å‰µé€ çš„æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def _ensure_data_dir(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºä¿"""
        self.recommendation_file.parent.mkdir(parents=True, exist_ok=True)
    
    def _build_creative_patterns(self) -> Dict[str, Dict[str, Any]]:
        """å‰µé€ çš„é–¢é€£æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ§‹ç¯‰"""
        return {
            # æ„Ÿæƒ…çš„å…±é€šç‚¹ã«ã‚ˆã‚‹é–¢é€£æ€§
            "emotional_resonance": {
                "description": "æ„Ÿæƒ…çš„ãªå…±é³´ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "weight": 1.2,
                "narrative_hooks": [
                    "åŒã˜å¿ƒã®ç´ç·šã«è§¦ã‚Œã‚‹",
                    "å…±é€šã™ã‚‹æ„Ÿæƒ…ã®æ³¢é•·",
                    "ä¼¼ãŸæ„Ÿæƒ…ã®æ·±å±¤ã§ç¹‹ãŒã‚‹",
                    "åŒã˜æ„Ÿæƒ…ã®ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ä¸Šã«ã‚ã‚‹"
                ]
            },
            
            # å¯¾ç…§çš„é­…åŠ›ã«ã‚ˆã‚‹é–¢é€£æ€§
            "contrasting_appeal": {
                "description": "å¯¾ç…§çš„ãªé­…åŠ›ã«ã‚ˆã‚‹è£œå®Œé–¢ä¿‚",
                "weight": 1.0,
                "narrative_hooks": [
                    "æ­£åå¯¾ã ã‹ã‚‰ã“ãæƒ¹ã‹ã‚Œåˆã†",
                    "é™°ã¨é™½ã®ã‚ˆã†ãªè£œå®Œé–¢ä¿‚",
                    "ç•°ãªã‚‹è§’åº¦ã‹ã‚‰åŒã˜ç¾ã—ã•",
                    "å¯¾æ¯”ãŒç”Ÿã¿å‡ºã™æ–°ãŸãªç™ºè¦‹"
                ]
            },
            
            # æ™‚ä»£ãƒ»æ–‡è„ˆçš„é–¢é€£æ€§
            "temporal_connection": {
                "description": "æ™‚ä»£ã‚„æ–‡è„ˆçš„èƒŒæ™¯ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "weight": 0.8,
                "narrative_hooks": [
                    "æ™‚ã‚’è¶…ãˆãŸå…±é€šã®ãƒ†ãƒ¼ãƒ",
                    "ç•°ãªã‚‹æ™‚ä»£ã®åŒã˜æƒ³ã„",
                    "ä¸–ä»£ã‚’è¶Šãˆã¦å—ã‘ç¶™ãŒã‚Œã‚‹æ„Ÿæƒ…",
                    "æ™‚ä»£ã‚’æ˜ ã™é¡ã¨ã—ã¦ã®æ¥½æ›²"
                ]
            },
            
            # å‰µä½œæŠ€æ³•ã«ã‚ˆã‚‹é–¢é€£æ€§
            "artistic_technique": {
                "description": "å‰µä½œæŠ€æ³•ã‚„è¡¨ç¾æ–¹æ³•ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "weight": 0.9,
                "narrative_hooks": [
                    "å‰µä½œè€…ã®æŠ€å·§çš„ãªé¡ä¼¼æ€§",
                    "è¡¨ç¾æ‰‹æ³•ã®é©æ–°æ€§",
                    "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªæ¢æ±‚ã®å…±é€šç‚¹",
                    "å‰µé€ æ€§ã®ç™ºéœ²ã«ãŠã‘ã‚‹ç›¸ä¼¼æ€§"
                ]
            },
            
            # è±¡å¾´çš„ãƒ»æ¯”å–©çš„é–¢é€£æ€§
            "symbolic_connection": {
                "description": "è±¡å¾´ã‚„æ¯”å–©ã«ã‚ˆã‚‹æ·±å±¤çš„é–¢é€£æ€§",
                "weight": 1.1,
                "narrative_hooks": [
                    "è±¡å¾´çš„ãªæ„å‘³ã§ã®ç¹‹ãŒã‚Š",
                    "æ¯”å–©ã®ä¸–ç•Œã§äº¤ã‚ã‚‹",
                    "æš—å–©çš„ãªé–¢é€£æ€§",
                    "æ·±å±¤æ„è­˜ã§ã®å…±é³´"
                ]
            },
            
            # éŸ³æ¥½ç†è«–çš„é–¢é€£æ€§
            "musical_theory": {
                "description": "éŸ³æ¥½ç†è«–çš„ãªæ§‹é€ ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "weight": 0.7,
                "narrative_hooks": [
                    "éŸ³æ¥½çš„æ§‹é€ ã®ç¾ã—ã„é¡ä¼¼",
                    "ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ã®ç†è«–çš„é–¢é€£",
                    "æ¥½ç†çš„ãªè¦ªå’Œæ€§",
                    "éŸ³æ¥½çš„DNAçš„ã®å…±é€šç‚¹"
                ]
            },
            
            # å“²å­¦çš„ãƒ»æ€æƒ³çš„é–¢é€£æ€§
            "philosophical_link": {
                "description": "å“²å­¦çš„æ€æƒ³ã‚„äººç”Ÿè¦³ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "weight": 1.3,
                "narrative_hooks": [
                    "äººç”Ÿã¸ã®å“²å­¦çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                    "å­˜åœ¨è«–çš„ãªå…±é€šãƒ†ãƒ¼ãƒ",
                    "æ€æƒ³çš„ãªæ·±ã„ç¹‹ãŒã‚Š",
                    "ç”Ÿãã‚‹ã“ã¨ã¸ã®åŒã˜å•ã„ã‹ã‘"
                ]
            }
        }
    
    def _build_narrative_templates(self) -> Dict[str, List[str]]:
        """ç‰©èªæ€§ã®ã‚ã‚‹ãƒŠãƒ©ãƒ†ã‚£ãƒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ§‹ç¯‰"""
        return {
            "journey_narrative": [
                "{source_song}ã‹ã‚‰å§‹ã¾ã£ãŸæ„Ÿæƒ…ã®æ—…ã¯ã€{target_song}ã§æ–°ãŸãªåœ°å¹³ã‚’è¦‹ã¤ã‘ã‚‹ã§ã—ã‚‡ã†",
                "{source_song}ã®ä¸–ç•Œã‚’æ­©ã„ãŸå¾Œã«ã€{target_song}ã®æ‰‰ã‚’é–‹ã‘ã°ã€{connection_reason}",
                "{source_song}ã§èŠ½ç”ŸãˆãŸ{emotion}ã¯ã€{target_song}ã§{evolution}ã¸ã¨è‚²ã¤ã¯ãš"
            ],
            
            "discovery_narrative": [
                "{source_song}ã‚’æ„›ã™ã‚‹ã‚ãªãŸãªã‚‰ã€{target_song}ã®{hidden_quality}ã«é©šã‹ã•ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“",
                "{source_song}ã®å‘ã“ã†å´ã«éš ã‚Œã¦ã„ãŸ{target_song}ã¯ã€{unexpected_element}ã§æº€ã¡ã¦ã„ã¾ã™",
                "{source_song}ã¨ã„ã†æ‰‰ã®éµã§é–‹ã{target_song}ã®ä¸–ç•Œã«ã¯ã€{surprise_element}ãŒå¾…ã£ã¦ã„ã¾ã™"
            ],
            
            "relationship_narrative": [
                "{source_song}ã¨{target_song}ã¯ã€{relationship_type}ã¨ã—ã¦ã€{shared_quality}ã‚’åˆ†ã‹ã¡åˆã£ã¦ã„ã¾ã™",
                "{source_song}ãŒã‚‚ã—{personification}ãªã‚‰ã€{target_song}ã¯{complementary_character}ã¨ã—ã¦å¯„ã‚Šæ·»ã†ã§ã—ã‚‡ã†",
                "{source_song}ã¨{target_song}ã®é–“ã«ã¯ã€{connection_metaphor}ã®ã‚ˆã†ãªçµ†ãŒã‚ã‚Šã¾ã™"
            ],
            
            "transformation_narrative": [
                "{source_song}ã®{initial_state}ãŒã€{target_song}ã§ã¯{transformed_state}ã¨ã—ã¦æ˜‡è¯ã•ã‚Œã¦ã„ã¾ã™",
                "{source_song}ã§æ„Ÿã˜ãŸ{emotion}ã‚’ã€{target_song}ã¯{transformation_type}ã¨ã—ã¦å†è©±èªã—ã¦ã„ã¾ã™",
                "{source_song}ã‹ã‚‰{target_song}ã¸ã®é“ã®ã‚Šã¯ã€{transformation_journey}ã®ç‰©èªã§ã™"
            ],
            
            "synergy_narrative": [
                "{source_song}ã¨{target_song}ã‚’ä¸¦ã¹ã‚‹ã¨ã€{synergy_effect}ãŒç”Ÿã¾ã‚Œã¾ã™",
                "{source_song}ã®{quality1}ã¨{target_song}ã®{quality2}ãŒçµ„ã¿åˆã‚ã•ã‚‹ã¨ã€{combined_effect}ã«ãªã‚Šã¾ã™",
                "{source_song}ã¨{target_song}ã®å…±å­˜ã¯ã€{harmony_metaphor}ã®ã‚ˆã†ãªèª¿å’Œã‚’å¥ã§ã¾ã™"
            ]
        }
    
    def _build_connection_types(self) -> Dict[str, Dict[str, Any]]:
        """æ¥½æ›²é–“ã®é–¢é€£æ€§ã‚¿ã‚¤ãƒ—ã‚’æ§‹ç¯‰"""
        return {
            "emotional_mirror": {
                "description": "æ„Ÿæƒ…çš„ãªé¡åƒé–¢ä¿‚",
                "strength": 0.9,
                "explanation_templates": [
                    "åŒã˜æ„Ÿæƒ…ã®ç•°ãªã‚‹è¡¨ç¾",
                    "å¿ƒã®åŒã˜å ´æ‰€ã«éŸ¿ã",
                    "æ„Ÿæƒ…ã®åŒå­ã®ã‚ˆã†ãªé–¢ä¿‚"
                ]
            },
            
            "complementary_pair": {
                "description": "è£œå®Œé–¢ä¿‚",
                "strength": 0.8,
                "explanation_templates": [
                    "äº’ã„ã‚’è£œã„åˆã†å­˜åœ¨",
                    "ãƒ‘ã‚ºãƒ«ã®ãƒ”ãƒ¼ã‚¹ã®ã‚ˆã†ã«åˆã†",
                    "é™°é™½ã®ã‚ˆã†ãªç›¸äº’è£œå®Œ"
                ]
            },
            
            "evolutionary_chain": {
                "description": "é€²åŒ–çš„é–¢é€£æ€§",
                "strength": 0.7,
                "explanation_templates": [
                    "æ„Ÿæƒ…ã®é€²åŒ–å½¢",
                    "æ¬¡ã®æ®µéšã¸ã®æ‰‰",
                    "æˆé•·ã®ç‰©èªã®ç¶šã"
                ]
            },
            
            "hidden_bridge": {
                "description": "éš ã‚ŒãŸæ©‹æ¸¡ã—",
                "strength": 1.0,
                "explanation_templates": [
                    "è¦‹ãˆãªã„ç³¸ã§ç¹‹ãŒã‚‹",
                    "æ½œåœ¨çš„ãªå…±é³´",
                    "æ·±å±¤ã§éŸ¿ãåˆã†é–¢ä¿‚"
                ]
            },
            
            "paradigm_shift": {
                "description": "ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆé–¢ä¿‚",
                "strength": 1.1,
                "explanation_templates": [
                    "è¦–ç‚¹ã‚’å¤‰ãˆã‚‹ä½“é¨“",
                    "æ–°ã—ã„ä¸–ç•Œã¸ã®å…¥å£",
                    "èªè­˜ã‚’åºƒã’ã‚‹ç™ºè¦‹"
                ]
            }
        }
    
    def _build_surprise_factors(self) -> Dict[str, Dict[str, Any]]:
        """æ„å¤–æ€§è¦ç´ ã‚’æ§‹ç¯‰"""
        return {
            "genre_transcendence": {
                "description": "ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è¶…ãˆãŸé–¢é€£æ€§",
                "impact": 1.2,
                "triggers": ["ç•°ãªã‚‹ã‚¸ãƒ£ãƒ³ãƒ«", "äºˆæƒ³å¤–ã®çµ„ã¿åˆã‚ã›", "å¢ƒç•Œã‚’è¶ŠãˆãŸ"]
            },
            
            "temporal_gap": {
                "description": "æ™‚ä»£ã‚’è¶ŠãˆãŸé–¢é€£æ€§",
                "impact": 1.0,
                "triggers": ["æ™‚ä»£ã‚’è¶…ãˆã¦", "ä¸–ä»£ã‚’è·¨ã„ã§", "æ™‚ã‚’è¶ŠãˆãŸ"]
            },
            
            "mood_inversion": {
                "description": "ãƒ ãƒ¼ãƒ‰ã®åè»¢ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "impact": 1.1,
                "triggers": ["æ­£åå¯¾ãªã®ã«", "å¯¾ç…§çš„ã ã‘ã‚Œã©", "çœŸé€†ã§ã‚ã‚ŠãªãŒã‚‰"]
            },
            
            "deep_metaphor": {
                "description": "æ·±å±¤æ¯”å–©ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "impact": 1.3,
                "triggers": ["éš ã‚ŒãŸè±¡å¾´", "æ·±å±¤ã®æ¯”å–©", "æ½œåœ¨çš„ãªç¹‹ãŒã‚Š"]
            },
            
            "artistic_revolution": {
                "description": "èŠ¸è¡“çš„é©æ–°ã«ã‚ˆã‚‹é–¢é€£æ€§",
                "impact": 1.4,
                "triggers": ["é©æ–°çš„ãª", "å‰è¡›çš„ãª", "ãƒ‘ã‚¤ã‚ªãƒ‹ã‚¢çš„ãª"]
            }
        }
    
    def _load_recommendation_data(self):
        """æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        try:
            if self.recommendation_file.exists():
                with open(self.recommendation_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.recommendation_history = data.get('recommendation_history', [])
                print(f"[å‰µé€ æ¨è–¦] ğŸ“Š æ¨è–¦å±¥æ­´: {len(self.recommendation_history)}ä»¶ã‚’ãƒ­ãƒ¼ãƒ‰")
            else:
                print("[å‰µé€ æ¨è–¦] ğŸ“ æ–°è¦æ¨è–¦ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ")
        except Exception as e:
            print(f"[å‰µé€ æ¨è–¦] âš ï¸ æ¨è–¦ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            self.recommendation_history = []
    
    def _save_recommendation_data(self):
        """æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"""
        try:
            data = {
                'recommendation_history': self.recommendation_history[-200:],  # æœ€æ–°200ä»¶ã®ã¿ä¿æŒ
                'last_updated': datetime.now().isoformat()
            }
            with open(self.recommendation_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[å‰µé€ æ¨è–¦] âŒ æ¨è–¦ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¤±æ•—: {e}")
    
    def generate_creative_recommendation(self, 
                                       source_video: Dict[str, Any],
                                       candidate_videos: List[Dict[str, Any]],
                                       user_emotion_analysis: Optional[Dict[str, Any]] = None,
                                       context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        å‰µé€ çš„æ¨è–¦ã‚’ç”Ÿæˆ
        
        Args:
            source_video: æ¨è–¦ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹å‹•ç”»
            candidate_videos: å€™è£œå‹•ç”»ãƒªã‚¹ãƒˆ
            user_emotion_analysis: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…åˆ†æçµæœ
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            å‰µé€ çš„æ¨è–¦ãƒªã‚¹ãƒˆ
        """
        print(f"[å‰µé€ æ¨è–¦] ğŸ¨ å‰µé€ çš„æ¨è–¦ç”Ÿæˆé–‹å§‹")
        
        if not candidate_videos:
            return []
        
        creative_recommendations = []
        
        for candidate in candidate_videos:
            # å‰µé€ çš„é–¢é€£æ€§ã®åˆ†æ
            creative_connections = self._analyze_creative_connections(source_video, candidate)
            
            # æ„å¤–æ€§ã®è©•ä¾¡
            surprise_score = self._calculate_surprise_score(source_video, candidate, context)
            
            # ãƒŠãƒ©ãƒ†ã‚£ãƒ–ã®ç”Ÿæˆ
            narrative = self._generate_recommendation_narrative(
                source_video, candidate, creative_connections, user_emotion_analysis
            )
            
            # å‰µé€ æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
            creativity_score = self._calculate_creativity_score(
                creative_connections, surprise_score, narrative
            )
            
            creative_recommendation = {
                "video_id": candidate.get("video_id", ""),
                "video_data": candidate,
                "source_video_id": source_video.get("video_id", ""),
                "creative_connections": creative_connections,
                "surprise_score": surprise_score,
                "creativity_score": creativity_score,
                "narrative": narrative,
                "recommendation_type": "creative",
                "generated_at": datetime.now().isoformat()
            }
            
            creative_recommendations.append(creative_recommendation)
        
        # å‰µé€ æ€§ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        creative_recommendations.sort(key=lambda x: x["creativity_score"], reverse=True)
        
        # æ¨è–¦å±¥æ­´ã«è¨˜éŒ²
        self._record_recommendation_generation(source_video, creative_recommendations[:3])
        
        print(f"[å‰µé€ æ¨è–¦] âœ… å‰µé€ çš„æ¨è–¦ç”Ÿæˆå®Œäº†: {len(creative_recommendations)}ä»¶")
        
        return creative_recommendations
    
    def _analyze_creative_connections(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> Dict[str, Any]:
        """å‰µé€ çš„é–¢é€£æ€§ã‚’åˆ†æ"""
        connections = {
            "detected_patterns": [],
            "connection_strength": 0.0,
            "primary_connection_type": "",
            "surprise_elements": [],
            "narrative_potential": 0.0
        }
        
        # åŸºæœ¬æƒ…å ±ã®å–å¾—
        source_metadata = source_video.get("metadata", {})
        target_metadata = target_video.get("metadata", {})
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã§ã®é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯
        for pattern_name, pattern_data in self.creative_patterns.items():
            connection_score = self._evaluate_pattern_connection(
                pattern_name, source_video, target_video
            )
            
            if connection_score > 0.3:  # é–¾å€¤ä»¥ä¸Šã®é–¢é€£æ€§
                connections["detected_patterns"].append({
                    "pattern": pattern_name,
                    "score": connection_score,
                    "description": pattern_data["description"],
                    "weight": pattern_data["weight"]
                })
        
        # ä¸»è¦ãªé–¢é€£æ€§ã‚¿ã‚¤ãƒ—ã®æ±ºå®š
        if connections["detected_patterns"]:
            primary_pattern = max(connections["detected_patterns"], key=lambda x: x["score"] * x["weight"])
            connections["primary_connection_type"] = primary_pattern["pattern"]
            connections["connection_strength"] = primary_pattern["score"] * primary_pattern["weight"]
        
        # æ„å¤–æ€§è¦ç´ ã®æ¤œå‡º
        connections["surprise_elements"] = self._detect_surprise_elements(source_video, target_video)
        
        # ãƒŠãƒ©ãƒ†ã‚£ãƒ–æ½œåœ¨æ€§ã®è©•ä¾¡
        connections["narrative_potential"] = self._evaluate_narrative_potential(connections)
        
        return connections
    
    def _evaluate_pattern_connection(self, pattern_name: str, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®é–¢é€£æ€§ã‚’è©•ä¾¡"""
        
        # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã®è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
        if pattern_name == "emotional_resonance":
            return self._evaluate_emotional_resonance(source_video, target_video)
        
        elif pattern_name == "contrasting_appeal":
            return self._evaluate_contrasting_appeal(source_video, target_video)
        
        elif pattern_name == "temporal_connection":
            return self._evaluate_temporal_connection(source_video, target_video)
        
        elif pattern_name == "artistic_technique":
            return self._evaluate_artistic_technique(source_video, target_video)
        
        elif pattern_name == "symbolic_connection":
            return self._evaluate_symbolic_connection(source_video, target_video)
        
        elif pattern_name == "musical_theory":
            return self._evaluate_musical_theory(source_video, target_video)
        
        elif pattern_name == "philosophical_link":
            return self._evaluate_philosophical_link(source_video, target_video)
        
        return min(1.0, score)
    
    def _are_related_moods(self, mood1: str, mood2: str) -> bool:
        """ãƒ ãƒ¼ãƒ‰é–“ã®é–¢é€£æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        mood_relations = {
            "happy": ["energetic", "uplifting", "joyful", "cheerful"],
            "sad": ["melancholy", "nostalgic", "emotional", "somber"],
            "energetic": ["happy", "uplifting", "dynamic", "powerful"],
            "calm": ["peaceful", "relaxing", "gentle", "serene"],
            "nostalgic": ["sad", "emotional", "romantic", "wistful"],
            "romantic": ["gentle", "emotional", "soft", "tender"]
        }
        
        return mood2 in mood_relations.get(mood1, []) or mood1 in mood_relations.get(mood2, [])
    
    def _calculate_genre_emotional_similarity(self, genre1: str, genre2: str) -> float:
        """ã‚¸ãƒ£ãƒ³ãƒ«é–“ã®æ„Ÿæƒ…çš„é¡ä¼¼æ€§ã‚’è¨ˆç®—"""
        genre_emotion_map = {
            "pop": 0.7, "rock": 0.6, "ballad": 0.8, "jazz": 0.6,
            "classical": 0.7, "electronic": 0.5, "folk": 0.8,
            "r&b": 0.7, "country": 0.7, "indie": 0.6
        }
        
        emotion1 = genre_emotion_map.get(genre1, 0.5)
        emotion2 = genre_emotion_map.get(genre2, 0.5)
        
        return 1.0 - abs(emotion1 - emotion2)
    
    def _evaluate_contrasting_appeal(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """å¯¾ç…§çš„é­…åŠ›ã®è©•ä¾¡"""
        source_metadata = source_video.get("metadata", {})
        target_metadata = target_video.get("metadata", {})
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        score = 0.0
        
        # BPMã®å¯¾æ¯”
        source_music = source_insight.get("music_analysis", {})
        target_music = target_insight.get("music_analysis", {})
        
        source_bpm = source_music.get("bpm")
        target_bpm = target_music.get("bpm")
        
        if source_bpm and target_bpm:
            bpm_diff = abs(source_bpm - target_bpm)
            if bpm_diff > 40:  # å¤§ããªBPMå·®
                score += 0.6
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ã®å¯¾æ¯”
        source_genre = source_music.get("genre", "").lower()
        target_genre = target_music.get("genre", "").lower()
        
        if source_genre and target_genre and source_genre != target_genre:
            contrast_genres = {
                ("ballad", "rock"), ("classical", "electronic"), 
                ("folk", "hip-hop"), ("jazz", "pop")
            }
            if (source_genre, target_genre) in contrast_genres or (target_genre, source_genre) in contrast_genres:
                score += 0.7
        
        return min(1.0, score)
    
    def _evaluate_temporal_connection(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """æ™‚ä»£çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        source_metadata = source_video.get("metadata", {})
        target_metadata = target_video.get("metadata", {})
        
        score = 0.0
        
        # å…¬é–‹æ™‚æœŸã®é–¢é€£æ€§
        source_date = source_metadata.get("published_at", "")
        target_date = target_metadata.get("published_at", "")
        
        if source_date and target_date:
            try:
                from datetime import datetime
                source_dt = datetime.fromisoformat(source_date.replace('Z', '+00:00'))
                target_dt = datetime.fromisoformat(target_date.replace('Z', '+00:00'))
                
                # åŒã˜å¹´
                if source_dt.year == target_dt.year:
                    score += 0.8
                # è¿‘ã„å¹´ï¼ˆÂ±2å¹´ï¼‰
                elif abs(source_dt.year - target_dt.year) <= 2:
                    score += 0.6
                # åŒã˜å­£ç¯€
                elif source_dt.month // 3 == target_dt.month // 3:
                    score += 0.4
                    
            except:
                pass
        
        return min(1.0, score)
    
    def _evaluate_artistic_technique(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """å‰µä½œæŠ€æ³•ã®é–¢é€£æ€§è©•ä¾¡"""
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        score = 0.0
        
        # ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼æƒ…å ±ã®æ¯”è¼ƒ
        source_creators = source_insight.get("creators", [])
        target_creators = target_insight.get("creators", [])
        
        # å…±é€šã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®å­˜åœ¨
        source_names = {creator.get("name", "").lower() for creator in source_creators}
        target_names = {creator.get("name", "").lower() for creator in target_creators}
        
        common_creators = source_names & target_names
        if common_creators:
            score += 0.9  # åŒã˜ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼
        
        # å½¹å‰²ã®é¡ä¼¼æ€§
        source_roles = {creator.get("role", "") for creator in source_creators}
        target_roles = {creator.get("role", "") for creator in target_creators}
        
        common_roles = source_roles & target_roles
        role_similarity = len(common_roles) / max(len(source_roles | target_roles), 1)
        score += role_similarity * 0.5
        
        return min(1.0, score)
    
    def _evaluate_symbolic_connection(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """è±¡å¾´çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        score = 0.0
        
        # ãƒ†ãƒ¼ãƒã®å…±é€šæ€§
        source_themes = source_insight.get("themes", [])
        target_themes = target_insight.get("themes", [])
        
        if source_themes and target_themes:
            common_themes = set(source_themes) & set(target_themes)
            theme_similarity = len(common_themes) / max(len(set(source_themes) | set(target_themes)), 1)
            score += theme_similarity * 0.8
        
        # è¦–è¦šçš„è¦ç´ ã®å…±é€šæ€§
        source_visuals = source_insight.get("visual_elements", [])
        target_visuals = target_insight.get("visual_elements", [])
        
        if source_visuals and target_visuals:
            common_visuals = set(source_visuals) & set(target_visuals)
            visual_similarity = len(common_visuals) / max(len(set(source_visuals) | set(target_visuals)), 1)
            score += visual_similarity * 0.6
        
        return min(1.0, score)
    
    def _evaluate_musical_theory(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """éŸ³æ¥½ç†è«–çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        source_music = source_insight.get("music_analysis", {})
        target_music = target_insight.get("music_analysis", {})
        
        score = 0.0
        
        # ã‚­ãƒ¼ã®é–¢é€£æ€§
        source_key = source_music.get("key")
        target_key = target_music.get("key")
        
        if source_key and target_key:
            if source_key == target_key:
                score += 0.7
            elif self._are_related_keys(source_key, target_key):
                score += 0.5
        
        # BPMã®é–¢é€£æ€§
        source_bpm = source_music.get("bpm")
        target_bpm = target_music.get("bpm")
        
        if source_bpm and target_bpm:
            bpm_ratio = min(source_bpm, target_bpm) / max(source_bpm, target_bpm)
            if bpm_ratio > 0.9:  # éå¸¸ã«è¿‘ã„
                score += 0.6
            elif bpm_ratio > 0.7:  # ã‚„ã‚„è¿‘ã„
                score += 0.4
        
        return min(1.0, score)
    
    def _are_related_keys(self, key1: str, key2: str) -> bool:
        """ã‚­ãƒ¼ã®é–¢é€£æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        # ç°¡å˜ãªé–¢é€£ã‚­ãƒ¼åˆ¤å®šï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šè¤‡é›‘ãªéŸ³æ¥½ç†è«–çš„é–¢ä¿‚ï¼‰
        major_keys = ["C", "G", "D", "A", "E", "B", "F#", "F", "Bb", "Eb", "Ab", "Db"]
        minor_keys = ["Am", "Em", "Bm", "F#m", "C#m", "G#m", "D#m", "Dm", "Gm", "Cm", "Fm", "Bbm"]
        
        # äº”åº¦åœã§ã®éš£æ¥
        if key1 in major_keys and key2 in major_keys:
            idx1, idx2 = major_keys.index(key1), major_keys.index(key2)
            return abs(idx1 - idx2) <= 1 or abs(idx1 - idx2) >= 11
        
        return False
    
    def _evaluate_philosophical_link(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """å“²å­¦çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        source_metadata = source_video.get("metadata", {})
        target_metadata = target_video.get("metadata", {})
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        score = 0.0
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã®å“²å­¦çš„ãƒ†ãƒ¼ãƒæŠ½å‡º
        philosophical_keywords = [
            "æ„›", "æ­»", "ç”Ÿ", "å¤¢", "å¸Œæœ›", "çµ¶æœ›", "æ™‚é–“", "æ°¸é ", "çœŸå®Ÿ", "è‡ªç”±",
            "å­˜åœ¨", "æ„å‘³", "äººç”Ÿ", "é‹å‘½", "è¨˜æ†¶", "æœªæ¥", "éå»", "ä»Š"
        ]
        
        source_title = source_metadata.get("title", "").lower()
        target_title = target_metadata.get("title", "").lower()
        
        source_philosophical = sum(1 for keyword in philosophical_keywords if keyword in source_title)
        target_philosophical = sum(1 for keyword in philosophical_keywords if keyword in target_title)
        
        if source_philosophical > 0 and target_philosophical > 0:
            score += 0.7
        
        # æ­Œè©ã‹ã‚‰ã®å“²å­¦çš„è¦ç´ ï¼ˆã‚‚ã—åˆ©ç”¨å¯èƒ½ãªã‚‰ï¼‰
        source_lyrics = source_insight.get("music_info", {}).get("lyrics", "")
        target_lyrics = target_insight.get("music_info", {}).get("lyrics", "")
        
        if source_lyrics and target_lyrics:
            source_phil_count = sum(1 for keyword in philosophical_keywords if keyword in source_lyrics)
            target_phil_count = sum(1 for keyword in philosophical_keywords if keyword in target_lyrics)
            
            if source_phil_count > 2 and target_phil_count > 2:
                score += 0.8
        
        return min(1.0, score)
    
    def _calculate_surprise_score(self, source_video: Dict[str, Any], target_video: Dict[str, Any], context: Optional[Dict[str, Any]]) -> float:
        """æ„å¤–æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        surprise_score = 0.0
        
        for factor_name, factor_data in self.surprise_factors.items():
            factor_score = self._evaluate_surprise_factor(factor_name, source_video, target_video)
            surprise_score += factor_score * factor_data["impact"]
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹èª¿æ•´
        if context:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®é¸æŠãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ¯”è¼ƒ
            user_pattern_novelty = context.get("pattern_novelty", 0.5)
            surprise_score *= (0.7 + user_pattern_novelty * 0.6)
        
        return min(1.0, surprise_score)
    
    def _evaluate_surprise_factor(self, factor_name: str, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """å€‹åˆ¥ã®æ„å¤–æ€§è¦ç´ ã‚’è©•ä¾¡"""
        
        if factor_name == "genre_transcendence":
            source_genre = source_video.get("creative_insight", {}).get("music_analysis", {}).get("genre", "")
            target_genre = target_video.get("creative_insight", {}).get("music_analysis", {}).get("genre", "")
            
            if source_genre and target_genre and source_genre != target_genre:
                # ç•°ãªã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ã®å ´åˆã€ãã®è·é›¢ã«å¿œã˜ã¦æ„å¤–æ€§ã‚¹ã‚³ã‚¢
                genre_distance = self._calculate_genre_distance(source_genre, target_genre)
                return genre_distance
        
        elif factor_name == "temporal_gap":
            source_date = source_video.get("metadata", {}).get("published_at", "")
            target_date = target_video.get("metadata", {}).get("published_at", "")
            
            if source_date and target_date:
                try:
                    from datetime import datetime
                    source_dt = datetime.fromisoformat(source_date.replace('Z', '+00:00'))
                    target_dt = datetime.fromisoformat(target_date.replace('Z', '+00:00'))
                    
                    year_gap = abs(source_dt.year - target_dt.year)
                    if year_gap > 5:
                        return min(1.0, year_gap / 20)  # 20å¹´ã§æœ€å¤§ã‚¹ã‚³ã‚¢
                except:
                    pass
        
        elif factor_name == "mood_inversion":
            source_mood = source_video.get("creative_insight", {}).get("music_analysis", {}).get("mood", "")
            target_mood = target_video.get("creative_insight", {}).get("music_analysis", {}).get("mood", "")
            
            opposite_moods = {
                ("happy", "sad"), ("energetic", "calm"), ("uplifting", "melancholy"),
                ("bright", "dark"), ("major", "minor")
            }
            
            if (source_mood, target_mood) in opposite_moods or (target_mood, source_mood) in opposite_moods:
                return 0.8
        
        return 0.0
    
    def _calculate_genre_distance(self, genre1: str, genre2: str) -> float:
        """ã‚¸ãƒ£ãƒ³ãƒ«é–“ã®è·é›¢ã‚’è¨ˆç®—"""
        # ã‚¸ãƒ£ãƒ³ãƒ«ãƒãƒƒãƒ—ï¼ˆç°¡ç•¥åŒ–ï¼‰
        genre_map = {
            "pop": [0, 0], "rock": [2, 0], "jazz": [0, 2], "classical": [0, 4],
            "electronic": [4, 0], "folk": [-2, 2], "r&b": [1, 1], "hip-hop": [3, -1]
        }
        
        pos1 = genre_map.get(genre1.lower(), [0, 0])
        pos2 = genre_map.get(genre2.lower(), [0, 0])
        
        distance = math.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)
        return min(1.0, distance / 6.0)  # æ­£è¦åŒ–
    
    def _detect_surprise_elements(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> List[str]:
        """æ„å¤–æ€§è¦ç´ ã‚’æ¤œå‡º"""
        elements = []
        
        # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®é•ã„
        source_channel = source_video.get("metadata", {}).get("channel_title", "")
        target_channel = target_video.get("metadata", {}).get("channel_title", "")
        
        if source_channel != target_channel:
            elements.append("ç•°ãªã‚‹ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ")
        
        # è¦–è´æ•°ã®å¤§ããªå·®
        source_views = source_video.get("metadata", {}).get("view_count", 0)
        target_views = target_video.get("metadata", {}).get("view_count", 0)
        
        if source_views > 0 and target_views > 0:
            view_ratio = max(source_views, target_views) / min(source_views, target_views)
            if view_ratio > 10:
                elements.append("äººæ°—åº¦ã®å¯¾æ¯”")
        
        return elements
    
    def _evaluate_narrative_potential(self, connections: Dict[str, Any]) -> float:
        """ãƒŠãƒ©ãƒ†ã‚£ãƒ–æ½œåœ¨æ€§ã‚’è©•ä¾¡"""
        base_score = 0.0
        
        # æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³æ•°
        pattern_count = len(connections.get("detected_patterns", []))
        base_score += min(0.5, pattern_count * 0.1)
        
        # æ„å¤–æ€§è¦ç´ 
        surprise_elements = len(connections.get("surprise_elements", []))
        base_score += min(0.3, surprise_elements * 0.15)
        
        # ä¸»è¦é–¢é€£æ€§ã®å¼·ã•
        connection_strength = connections.get("connection_strength", 0.0)
        base_score += connection_strength * 0.4
        
        return min(1.0, base_score)
    
    def _generate_recommendation_narrative(self,
                                         source_video: Dict[str, Any],
                                         target_video: Dict[str, Any],
                                         connections: Dict[str, Any],
                                         user_emotion_analysis: Optional[Dict[str, Any]]) -> str:
        """æ¨è–¦ãƒŠãƒ©ãƒ†ã‚£ãƒ–ã‚’ç”Ÿæˆ"""
        
        # ä¸»è¦é–¢é€£æ€§ã‚¿ã‚¤ãƒ—ã«åŸºã¥ããƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé¸æŠ
        primary_type = connections.get("primary_connection_type", "")
        connection_strength = connections.get("connection_strength", 0.0)
        
        # ãƒŠãƒ©ãƒ†ã‚£ãƒ–ã‚«ãƒ†ã‚´ãƒªã®æ±ºå®š
        if connection_strength > 0.8:
            narrative_category = "synergy_narrative"
        elif connections.get("surprise_elements"):
            narrative_category = "discovery_narrative"
        elif primary_type in ["emotional_resonance", "philosophical_link"]:
            narrative_category = "relationship_narrative"
        elif primary_type in ["contrasting_appeal", "mood_inversion"]:
            narrative_category = "transformation_narrative"
        else:
            narrative_category = "journey_narrative"
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é¸æŠ
        templates = self.narrative_templates.get(narrative_category, [])
        if not templates:
            return self._generate_basic_narrative(source_video, target_video)
        
        template = random.choice(templates)
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã®æº–å‚™
        variables = self._prepare_narrative_variables(source_video, target_video, connections, user_emotion_analysis)
        
        try:
            narrative = template.format(**variables)
            return narrative
        except KeyError:
            return self._generate_basic_narrative(source_video, target_video)
    
    def _prepare_narrative_variables(self,
                                   source_video: Dict[str, Any],
                                   target_video: Dict[str, Any],
                                   connections: Dict[str, Any],
                                   user_emotion_analysis: Optional[Dict[str, Any]]) -> Dict[str, str]:
        """ãƒŠãƒ©ãƒ†ã‚£ãƒ–å¤‰æ•°ã‚’æº–å‚™"""
        
        source_title = source_video.get("metadata", {}).get("title", "ã“ã®æ¥½æ›²")
        target_title = target_video.get("metadata", {}).get("title", "ãã®æ¥½æ›²")
        
        # æ„Ÿæƒ…é–¢é€£ã®å¤‰æ•°
        emotion_keywords = ["æ¸©ã‹ã„", "åˆ‡ãªã„", "åŠ›å¼·ã„", "å„ªã—ã„", "æƒ…ç†±çš„", "ç¥ç§˜çš„", "æ‡ã‹ã—ã„"]
        connection_keywords = ["å¿ƒã®å¥¥ã§éŸ¿ãåˆã†", "é­‚ã®æ·±å±¤ã§ç¹‹ãŒã‚‹", "æ„Ÿæƒ…ã®æ³¢é•·ãŒé‡ãªã‚‹", "ç²¾ç¥çš„ã«å…±é³´ã™ã‚‹"]
        transformation_keywords = ["æ˜‡è¯", "é€²åŒ–", "å¤‰å®¹", "æ·±åŒ–", "ç™ºå±•"]
        
        variables = {
            "source_song": source_title,
            "target_song": target_title,
            "emotion": random.choice(emotion_keywords),
            "connection_reason": random.choice(connection_keywords),
            "evolution": random.choice(transformation_keywords),
            "hidden_quality": "éš ã•ã‚ŒãŸç¾ã—ã•",
            "unexpected_element": "äºˆæƒ³å¤–ã®é­…åŠ›",
            "surprise_element": "é©šãã®ç™ºè¦‹",
            "relationship_type": "éŸ³æ¥½çš„ãªä¼´ä¾¶",
            "shared_quality": "å…±é€šã™ã‚‹é­‚ã®éŸ¿ã",
            "personification": "ä¸€ã¤ã®é­‚",
            "complementary_character": "ç†è§£ã—åˆã†ç›¸æ‰‹",
            "connection_metaphor": "è¦‹ãˆãªã„ç³¸",
            "initial_state": "ç´”ç²‹ãªæ„Ÿæƒ…",
            "transformed_state": "æ·±ã„æ´å¯Ÿ",
            "transformation_type": "æ–°ãŸãªè¦–ç‚¹",
            "transformation_journey": "æ„Ÿæƒ…ã®æˆé•·",
            "synergy_effect": "ç›¸ä¹—çš„ãªç¾ã—ã•",
            "quality1": "ç‹¬ç‰¹ã®é­…åŠ›",
            "quality2": "è£œå®Œçš„ãªç¾ã—ã•",
            "combined_effect": "å®Œå…¨ãªèª¿å’Œ",
            "harmony_metaphor": "äº¤éŸ¿æ›²"
        }
        
        return variables
    
    def _generate_basic_narrative(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> str:
        """åŸºæœ¬çš„ãªãƒŠãƒ©ãƒ†ã‚£ãƒ–ã‚’ç”Ÿæˆ"""
        source_title = source_video.get("metadata", {}).get("title", "ã“ã®æ¥½æ›²")
        target_title = target_video.get("metadata", {}).get("title", "ãã®æ¥½æ›²")
        
        basic_templates = [
            f"{source_title}ãŒãŠå¥½ãã§ã—ãŸã‚‰ã€{target_title}ã‚‚ãã£ã¨å¿ƒã«éŸ¿ãã¯ãšã§ã™ã€‚",
            f"{source_title}ã¨{target_title}ã«ã¯ã€éŸ³æ¥½çš„ãªè¦ªå’Œæ€§ã‚’æ„Ÿã˜ã¾ã™ã€‚",
            f"{source_title}ã®æ„Ÿå‹•ã‚’ã€{target_title}ã§ã‚‚ä½“é¨“ã—ã¦ã„ãŸã ã‘ã‚‹ã§ã—ã‚‡ã†ã€‚"
        ]
        
        return random.choice(basic_templates)
    
    def _calculate_creativity_score(self,
                                  connections: Dict[str, Any],
                                  surprise_score: float,
                                  narrative: str) -> float:
        """å‰µé€ æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        base_score = 0.0
        
        # é–¢é€£æ€§ã®å¼·ã•ï¼ˆ40%ï¼‰
        connection_strength = connections.get("connection_strength", 0.0)
        base_score += connection_strength * 0.4
        
        # æ„å¤–æ€§ï¼ˆ30%ï¼‰
        base_score += surprise_score * 0.3
        
        # ãƒŠãƒ©ãƒ†ã‚£ãƒ–æ½œåœ¨æ€§ï¼ˆ20%ï¼‰
        narrative_potential = connections.get("narrative_potential", 0.0)
        base_score += narrative_potential * 0.2
        
        # å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹ï¼ˆ10%ï¼‰
        pattern_diversity = len(connections.get("detected_patterns", []))
        diversity_bonus = min(0.1, pattern_diversity * 0.02)
        base_score += diversity_bonus
        
        return min(1.0, base_score)
    
    def _record_recommendation_generation(self, source_video: Dict[str, Any], recommendations: List[Dict[str, Any]]):
        """æ¨è–¦ç”Ÿæˆã‚’è¨˜éŒ²"""
        record = {
            "timestamp": datetime.now().isoformat(),
            "source_video_id": source_video.get("video_id", ""),
            "recommended_count": len(recommendations),
            "top_creativity_score": recommendations[0]["creativity_score"] if recommendations else 0.0,
            "patterns_used": []
        }
        
        for rec in recommendations:
            patterns = rec.get("creative_connections", {}).get("detected_patterns", [])
            record["patterns_used"].extend([p["pattern"] for p in patterns])
        
        record["patterns_used"] = list(set(record["patterns_used"]))  # é‡è¤‡é™¤å»
        
        self.recommendation_history.append(record)
        
        # å±¥æ­´åˆ¶é™
        if len(self.recommendation_history) > 200:
            self.recommendation_history = self.recommendation_history[-200:]
        
        # å®šæœŸä¿å­˜
        if len(self.recommendation_history) % 10 == 0:
            self._save_recommendation_data()
    
    def get_creativity_statistics(self) -> Dict[str, Any]:
        """å‰µé€ æ€§çµ±è¨ˆã‚’å–å¾—"""
        if not self.recommendation_history:
            return {"message": "æ¨è–¦å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        recent_history = self.recommendation_history[-20:]  # æœ€è¿‘20ä»¶
        
        # å¹³å‡å‰µé€ æ€§ã‚¹ã‚³ã‚¢
        avg_creativity = sum(record.get("top_creativity_score", 0) for record in recent_history) / len(recent_history)
        
        # ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†å¸ƒ
        all_patterns = []
        for record in recent_history:
            all_patterns.extend(record.get("patterns_used", []))
        
        pattern_counts = Counter(all_patterns)
        
        # å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢
        diversity_score = len(set(all_patterns)) / max(len(all_patterns), 1)
        
        return {
            "average_creativity_score": round(avg_creativity, 3),
            "total_recommendations": len(self.recommendation_history),
            "recent_recommendations": len(recent_history),
            "pattern_usage": dict(pattern_counts.most_common(5)),
            "diversity_score": round(diversity_score, 3),
            "most_used_pattern": pattern_counts.most_common(1)[0][0] if pattern_counts else "ãªã—"
        }


# ä½¿ç”¨ä¾‹ãƒ»ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    print("=== å‰µé€ çš„æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")
    
    system = CreativeRecommendationSystem()
    
    # ãƒ†ã‚¹ãƒˆç”¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿
    test_source_video = {
        "video_id": "test_001",
        "metadata": {
            "title": "ã‚¢ãƒ‰ãƒ™ãƒ³ãƒãƒ£ãƒ¼",
            "channel_title": "YOASOBI",
            "published_at": "2023-01-01T00:00:00Z",
            "view_count": 1000000
        },
        "creative_insight": {
            "music_analysis": {
                "genre": "pop",
                "mood": "uplifting",
                "bpm": 120,
                "key": "C"
            },
            "themes": ["adventure", "youth", "hope"],
            "creators": [
                {"name": "Ayase", "role": "composer"},
                {"name": "ikura", "role": "vocal"}
            ]
        }
    }
    
    test_candidate_videos = [
        {
            "video_id": "test_002",
            "metadata": {
                "title": "å¤œã«é§†ã‘ã‚‹",
                "channel_title": "YOASOBI",
                "published_at": "2023-02-01T00:00:00Z",
                "view_count": 2000000
            },
            "creative_insight": {
                "music_analysis": {
                    "genre": "pop",
                    "mood": "energetic",
                    "bpm": 130,
                    "key": "G"
                },
                "themes": ["night", "speed", "emotion"],
                "creators": [
                    {"name": "Ayase", "role": "composer"},
                    {"name": "ikura", "role": "vocal"}
                ]
            }
        },
        {
            "video_id": "test_003",
            "metadata": {
                "title": "ã‚«ãƒãƒ³",
                "channel_title": "Classical",
                "published_at": "1990-01-01T00:00:00Z",
                "view_count": 500000
            },
            "creative_insight": {
                "music_analysis": {
                    "genre": "classical",
                    "mood": "peaceful",
                    "bpm": 70,
                    "key": "D"
                },
                "themes": ["beauty", "harmony", "time"],
                "creators": [
                    {"name": "Pachelbel", "role": "composer"}
                ]
            }
        }
    ]
    
    # å‰µé€ çš„æ¨è–¦ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    recommendations = system.generate_creative_recommendation(
        test_source_video, 
        test_candidate_videos,
        user_emotion_analysis={"dominant_emotions": [("joy", 0.8)]},
        context={"pattern_novelty": 0.7}
    )
    
    print(f"\nğŸ¨ ç”Ÿæˆã•ã‚ŒãŸå‰µé€ çš„æ¨è–¦: {len(recommendations)}ä»¶")
    
    for i, rec in enumerate(recommendations, 1):
        print(f"\n--- æ¨è–¦ {i} ---")
        print(f"å‹•ç”»: {rec['video_data']['metadata']['title']}")
        print(f"å‰µé€ æ€§ã‚¹ã‚³ã‚¢: {rec['creativity_score']:.3f}")
        print(f"æ„å¤–æ€§ã‚¹ã‚³ã‚¢: {rec['surprise_score']:.3f}")
        print(f"ãƒŠãƒ©ãƒ†ã‚£ãƒ–: {rec['narrative']}")
        
        connections = rec['creative_connections']
        print(f"æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³: {len(connections['detected_patterns'])}ä»¶")
        for pattern in connections['detected_patterns']:
            print(f"  - {pattern['pattern']}: {pattern['score']:.2f}")
    
    # çµ±è¨ˆæƒ…å ±
    stats = system.get_creativity_statistics()
    print(f"\nğŸ“Š å‰µé€ æ€§çµ±è¨ˆ:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    def _evaluate_emotional_resonance(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """æ„Ÿæƒ…çš„å…±é³´ã®è©•ä¾¡"""
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        # æ¥½æ›²åˆ†æã‹ã‚‰æ„Ÿæƒ…æƒ…å ±ã‚’å–å¾—
        source_music = source_insight.get("music_analysis", {})
        target_music = target_insight.get("music_analysis", {})
        
        score = 0.0
        
        # ãƒ ãƒ¼ãƒ‰ã®é¡ä¼¼æ€§
        source_mood = source_music.get("mood", "").lower()
        target_mood = target_music.get("mood", "").lower()
        
        if source_mood and target_mood:
            # å®Œå…¨ä¸€è‡´
            if source_mood == target_mood:
                score += 0.8
            # é–¢é€£ãƒ ãƒ¼ãƒ‰
            elif self._are_related_moods(source_mood, target_mood):
                score += 0.6
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ã®æ„Ÿæƒ…çš„é¡ä¼¼æ€§
        source_genre = source_music.get("genre", "").lower()
        target_genre = target_music.get("genre", "").lower()
        
        if source_genre and target_genre:
            genre_emotional_similarity = self._calculate_genre_emotional_similarity(source_genre, target_genre)
            score += genre_emotional_similarity * 0.4
        
        return min(1.0, score)
    
    def _evaluate_contrasting_appeal(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """å¯¾ç…§çš„é­…åŠ›ã®è©•ä¾¡"""
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        source_music = source_insight.get("music_analysis", {})
        target_music = target_insight.get("music_analysis", {})
        
        score = 0.0
        
        # ãƒ ãƒ¼ãƒ‰ã®å¯¾æ¯”
        source_mood = source_music.get("mood", "").lower()
        target_mood = target_music.get("mood", "").lower()
        
        if source_mood and target_mood and source_mood != target_mood:
            if self._are_contrasting_moods(source_mood, target_mood):
                score += 0.7
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ã®å¯¾æ¯”
        source_genre = source_music.get("genre", "").lower()
        target_genre = target_music.get("genre", "").lower()
        
        if source_genre and target_genre and source_genre != target_genre:
            if self._are_contrasting_genres(source_genre, target_genre):
                score += 0.5
        
        # ãƒ†ãƒ³ãƒã®å¯¾æ¯”ï¼ˆæ¨æ¸¬ï¼‰
        source_title = source_video.get("metadata", {}).get("title", "").lower()
        target_title = target_video.get("metadata", {}).get("title", "").lower()
        
        tempo_contrast = self._detect_tempo_contrast(source_title, target_title)
        score += tempo_contrast * 0.3
        
        return min(1.0, score)
    
    def _evaluate_temporal_connection(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """æ™‚ä»£çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        source_metadata = source_video.get("metadata", {})
        target_metadata = target_video.get("metadata", {})
        
        score = 0.0
        
        # å…¬é–‹æ™‚æœŸã®åˆ†æ
        source_published = source_metadata.get("published_at", "")
        target_published = target_metadata.get("published_at", "")
        
        if source_published and target_published:
            # åŒæ™‚æœŸï¼ˆ1å¹´ä»¥å†…ï¼‰
            time_diff = self._calculate_time_difference(source_published, target_published)
            if time_diff <= 365:  # 1å¹´ä»¥å†…
                score += 0.6
            elif time_diff <= 1095:  # 3å¹´ä»¥å†…
                score += 0.4
        
        # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æ´»å‹•æ™‚æœŸ
        source_channel = source_metadata.get("channel_title", "").lower()
        target_channel = target_metadata.get("channel_title", "").lower()
        
        if source_channel == target_channel:
            score += 0.8  # åŒã˜ãƒãƒ£ãƒ³ãƒãƒ«ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ
        
        # æ™‚ä»£çš„ãƒ†ãƒ¼ãƒã®æ¤œå‡º
        temporal_themes = self._detect_temporal_themes(source_video, target_video)
        score += temporal_themes * 0.3
        
        return min(1.0, score)
    
    def _evaluate_artistic_technique(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """èŠ¸è¡“çš„æŠ€æ³•ã®è©•ä¾¡"""
        source_insight = source_video.get("creative_insight", {})
        target_insight = target_video.get("creative_insight", {})
        
        score = 0.0
        
        # ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®å…±é€šæ€§
        source_creators = source_insight.get("creators", [])
        target_creators = target_insight.get("creators", [])
        
        if source_creators and target_creators:
            creator_overlap = self._calculate_creator_overlap(source_creators, target_creators)
            score += creator_overlap * 0.8
        
        # æ¥½æ›²åˆ¶ä½œæŠ€æ³•ã®é¡ä¼¼æ€§
        source_music = source_insight.get("music_analysis", {})
        target_music = target_insight.get("music_analysis", {})
        
        # æ§‹æˆã®é¡ä¼¼æ€§ï¼ˆæ¨æ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
        composition_similarity = self._evaluate_composition_similarity(source_music, target_music)
        score += composition_similarity * 0.5
        
        return min(1.0, score)
    
    def _evaluate_symbolic_connection(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """è±¡å¾´çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        score = 0.0
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã®è±¡å¾´çš„è¦ç´ 
        source_title = source_video.get("metadata", {}).get("title", "").lower()
        target_title = target_video.get("metadata", {}).get("title", "").lower()
        
        symbolic_overlap = self._detect_symbolic_overlap(source_title, target_title)
        score += symbolic_overlap * 0.6
        
        # æ­Œè©ã®è±¡å¾´çš„ãƒ†ãƒ¼ãƒï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        source_lyrics = source_video.get("creative_insight", {}).get("lyrics", {})
        target_lyrics = target_video.get("creative_insight", {}).get("lyrics", {})
        
        if source_lyrics and target_lyrics:
            lyrical_symbolism = self._analyze_lyrical_symbolism(source_lyrics, target_lyrics)
            score += lyrical_symbolism * 0.8
        
        return min(1.0, score)
    
    def _evaluate_musical_theory(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """éŸ³æ¥½ç†è«–çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        source_music = source_video.get("creative_insight", {}).get("music_analysis", {})
        target_music = target_video.get("creative_insight", {}).get("music_analysis", {})
        
        score = 0.0
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ã®éŸ³æ¥½ç†è«–çš„é¡ä¼¼æ€§
        source_genre = source_music.get("genre", "").lower()
        target_genre = target_music.get("genre", "").lower()
        
        if source_genre and target_genre:
            theory_similarity = self._calculate_musical_theory_similarity(source_genre, target_genre)
            score += theory_similarity * 0.7
        
        # æ¨å®šã•ã‚Œã‚‹ã‚­ãƒ¼ãƒ»ã‚¹ã‚±ãƒ¼ãƒ«ã®é–¢é€£æ€§
        key_relationship = self._estimate_key_relationship(source_video, target_video)
        score += key_relationship * 0.5
        
        return min(1.0, score)
    
    def _evaluate_philosophical_link(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        """å“²å­¦çš„é–¢é€£æ€§ã®è©•ä¾¡"""
        score = 0.0
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã®å“²å­¦çš„ãƒ†ãƒ¼ãƒæŠ½å‡º
        source_title = source_video.get("metadata", {}).get("title", "").lower()
        target_title = target_video.get("metadata", {}).get("title", "").lower()
        
        philosophical_themes = self._extract_philosophical_themes(source_title, target_title)
        score += philosophical_themes * 0.8
        
        # èª¬æ˜æ–‡ã‹ã‚‰ã®äººç”Ÿè¦³çš„ãƒ†ãƒ¼ãƒ
        source_desc = source_video.get("metadata", {}).get("description", "").lower()
        target_desc = target_video.get("metadata", {}).get("description", "").lower()
        
        if source_desc and target_desc:
            worldview_similarity = self._analyze_worldview_similarity(source_desc, target_desc)
            score += worldview_similarity * 0.6
        
        return min(1.0, score)
    
    def _are_related_moods(self, mood1: str, mood2: str) -> bool:
        """ãƒ ãƒ¼ãƒ‰ãŒé–¢é€£ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        related_mood_groups = [
            {"æ˜ã‚‹ã„", "æ¥½ã—ã„", "ãƒãƒƒãƒ”ãƒ¼", "ãƒã‚¸ãƒ†ã‚£ãƒ–"},
            {"æš—ã„", "æ‚²ã—ã„", "åˆ‡ãªã„", "ãƒ¡ãƒ©ãƒ³ã‚³ãƒªãƒ¼"},
            {"ç©ã‚„ã‹", "ç™’ã—", "ãƒªãƒ©ãƒƒã‚¯ã‚¹", "å¹³å’Œ"},
            {"æ¿€ã—ã„", "ãƒ‘ãƒ¯ãƒ•ãƒ«", "ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥", "ãƒ‰ãƒ©ãƒãƒãƒƒã‚¯"}
        ]
        
        for group in related_mood_groups:
            if mood1 in group and mood2 in group:
                return True
        
        return False
    
    def _are_contrasting_moods(self, mood1: str, mood2: str) -> bool:
        """ãƒ ãƒ¼ãƒ‰ãŒå¯¾ç…§çš„ã‹ãƒã‚§ãƒƒã‚¯"""
        contrasting_pairs = [
            ("æ˜ã‚‹ã„", "æš—ã„"),
            ("æ¥½ã—ã„", "æ‚²ã—ã„"),
            ("æ¿€ã—ã„", "ç©ã‚„ã‹"),
            ("ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥", "ãƒªãƒ©ãƒƒã‚¯ã‚¹")
        ]
        
        for pair in contrasting_pairs:
            if (mood1 in pair and mood2 in pair) and mood1 != mood2:
                return True
        
        return False
    
    def _calculate_surprise_score(self, source_video: Dict[str, Any], target_video: Dict[str, Any], context: Optional[Dict[str, Any]]) -> float:
        """æ„å¤–æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        surprise_score = 0.0
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ã®æ„å¤–æ€§
        source_genre = source_video.get("creative_insight", {}).get("music_analysis", {}).get("genre", "").lower()
        target_genre = target_video.get("creative_insight", {}).get("music_analysis", {}).get("genre", "").lower()
        
        if source_genre and target_genre and source_genre != target_genre:
            genre_distance = self._calculate_genre_distance(source_genre, target_genre)
            surprise_score += genre_distance * 0.4
        
        # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æ„å¤–æ€§
        source_channel = source_video.get("metadata", {}).get("channel_title", "").lower()
        target_channel = target_video.get("metadata", {}).get("channel_title", "").lower()
        
        if source_channel != target_channel:
            surprise_score += 0.3
        
        # æ™‚ä»£ã®æ„å¤–æ€§
        time_gap = self._calculate_temporal_surprise(source_video, target_video)
        surprise_score += time_gap * 0.2
        
        # äºˆæƒ³å¤–ã®çµ„ã¿åˆã‚ã›ãƒœãƒ¼ãƒŠã‚¹
        unexpected_combination = self._detect_unexpected_combination(source_video, target_video)
        surprise_score += unexpected_combination * 0.3
        
        return min(1.0, surprise_score)
    
    def _generate_recommendation_narrative(self, 
                                         source_video: Dict[str, Any], 
                                         target_video: Dict[str, Any], 
                                         connections: Dict[str, Any],
                                         user_emotion_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """æ¨è–¦ãƒŠãƒ©ãƒ†ã‚£ãƒ–ã‚’ç”Ÿæˆ"""
        
        # ãƒŠãƒ©ãƒ†ã‚£ãƒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é¸æŠ
        narrative_type = self._select_narrative_type(connections, user_emotion_analysis)
        templates = self.narrative_templates.get(narrative_type, self.narrative_templates["discovery_narrative"])
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã®æ§‹ç¯‰
        template_vars = self._build_template_variables(source_video, target_video, connections)
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é¸æŠã¨é©ç”¨
        selected_template = random.choice(templates)
        
        try:
            narrative_text = selected_template.format(**template_vars)
        except KeyError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            narrative_text = f"{template_vars['source_song']}ã‹ã‚‰{template_vars['target_song']}ã¸ã®éŸ³æ¥½çš„ãªæ—…è·¯"
        
        return {
            "type": narrative_type,
            "text": narrative_text,
            "template_vars": template_vars,
            "narrative_strength": self._evaluate_narrative_strength(connections)
        }
    
    def _select_narrative_type(self, connections: Dict[str, Any], user_emotion_analysis: Optional[Dict[str, Any]]) -> str:
        """ãƒŠãƒ©ãƒ†ã‚£ãƒ–ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ"""
        primary_connection = connections.get("primary_connection_type", "")
        
        # é–¢é€£æ€§ã‚¿ã‚¤ãƒ—ã«åŸºã¥ããƒŠãƒ©ãƒ†ã‚£ãƒ–ãƒãƒƒãƒ”ãƒ³ã‚°
        narrative_mapping = {
            "emotional_resonance": "relationship_narrative",
            "contrasting_appeal": "transformation_narrative",
            "temporal_connection": "journey_narrative",
            "artistic_technique": "synergy_narrative",
            "symbolic_connection": "discovery_narrative",
            "philosophical_link": "transformation_narrative"
        }
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹ã«ã‚ˆã‚‹èª¿æ•´
        if user_emotion_analysis:
            dominant_emotions = user_emotion_analysis.get("dominant_emotions", [])
            if dominant_emotions:
                primary_emotion = dominant_emotions[0][0]
                if primary_emotion in ["curiosity", "excitement"]:
                    return "discovery_narrative"
                elif primary_emotion in ["nostalgia", "contemplative"]:
                    return "journey_narrative"
        
        return narrative_mapping.get(primary_connection, "discovery_narrative")
    
    def _build_template_variables(self, source_video: Dict[str, Any], target_video: Dict[str, Any], connections: Dict[str, Any]) -> Dict[str, str]:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã‚’æ§‹ç¯‰"""
        
        # åŸºæœ¬çš„ãªæ¥½æ›²æƒ…å ±
        source_title = self._extract_clean_title(source_video.get("metadata", {}).get("title", ""))
        target_title = self._extract_clean_title(target_video.get("metadata", {}).get("title", ""))
        
        # æ„Ÿæƒ…ãƒ»ç‰¹æ€§ã®æŠ½å‡º
        source_emotion = self._extract_primary_emotion(source_video)
        target_emotion = self._extract_primary_emotion(target_video)
        
        # é–¢é€£æ€§èª¬æ˜
        connection_reason = self._generate_connection_reason(connections)
        
        template_vars = {
            "source_song": source_title,
            "target_song": target_title,
            "emotion": source_emotion,
            "connection_reason": connection_reason,
            "evolution": self._generate_emotion_evolution(source_emotion, target_emotion),
            "hidden_quality": self._generate_hidden_quality(target_video),
            "unexpected_element": self._generate_unexpected_element(connections),
            "surprise_element": self._generate_surprise_element(connections),
            "relationship_type": self._generate_relationship_type(connections),
            "shared_quality": self._generate_shared_quality(source_video, target_video),
            "personification": self._generate_personification(source_video),
            "complementary_character": self._generate_complementary_character(target_video),
            "connection_metaphor": self._generate_connection_metaphor(connections),
            "initial_state": source_emotion,
            "transformed_state": target_emotion,
            "transformation_type": self._generate_transformation_type(source_emotion, target_emotion),
            "transformation_journey": self._generate_transformation_journey(connections),
            "synergy_effect": self._generate_synergy_effect(connections),
            "quality1": self._extract_key_quality(source_video),
            "quality2": self._extract_key_quality(target_video),
            "combined_effect": self._generate_combined_effect(source_video, target_video),
            "harmony_metaphor": self._generate_harmony_metaphor()
        }
        
        return template_vars
    
    def _extract_clean_title(self, title: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if not title:
            return "ã“ã®æ¥½æ›²"
        
        # ä¸è¦ãªè£…é£¾ã‚’é™¤å»
        cleaned = re.sub(r'ã€[^ã€‘]*ã€‘', '', title)
        cleaned = re.sub(r'\[[^\]]*\]', '', cleaned)
        cleaned = re.sub(r'\([^)]*\)', '', cleaned)
        cleaned = re.sub(r'Official.*', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'Music Video.*', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'MV.*', '', cleaned, flags=re.IGNORECASE)
        
        cleaned = cleaned.strip()
        
        return cleaned if cleaned else "ã“ã®æ¥½æ›²"
    
    def _extract_primary_emotion(self, video: Dict[str, Any]) -> str:
        """ä¸»è¦æ„Ÿæƒ…ã‚’æŠ½å‡º"""
        music_analysis = video.get("creative_insight", {}).get("music_analysis", {})
        mood = music_analysis.get("mood", "").lower()
        
        emotion_mapping = {
            "æ˜ã‚‹ã„": "å–œã³",
            "æ¥½ã—ã„": "æ¥½ã—ã•",
            "æ‚²ã—ã„": "æ‚²ã—ã¿",
            "åˆ‡ãªã„": "åˆ‡ãªã•",
            "ç©ã‚„ã‹": "å®‰ã‚‰ã",
            "æ¿€ã—ã„": "æƒ…ç†±"
        }
        
        return emotion_mapping.get(mood, "æ„Ÿå‹•")
    
    def _calculate_creativity_score(self, connections: Dict[str, Any], surprise_score: float, narrative: Dict[str, Any]) -> float:
        """å‰µé€ æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        # é–¢é€£æ€§ã®å¼·åº¦
        connection_strength = connections.get("connection_strength", 0.0)
        
        # ãƒŠãƒ©ãƒ†ã‚£ãƒ–ã®å¼·åº¦
        narrative_strength = narrative.get("narrative_strength", 0.0)
        
        # æ„å¤–æ€§ã®ä¾¡å€¤
        surprise_value = surprise_score
        
        # æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¤šæ§˜æ€§
        pattern_diversity = len(connections.get("detected_patterns", [])) / len(self.creative_patterns)
        
        # ç·åˆå‰µé€ æ€§ã‚¹ã‚³ã‚¢
        creativity_score = (
            connection_strength * 0.3 +
            narrative_strength * 0.3 +
            surprise_value * 0.2 +
            pattern_diversity * 0.2
        )
        
        return min(1.0, creativity_score)
    
    def _record_recommendation_generation(self, source_video: Dict[str, Any], recommendations: List[Dict[str, Any]]):
        """æ¨è–¦ç”Ÿæˆã‚’è¨˜éŒ²"""
        record = {
            "timestamp": datetime.now().isoformat(),
            "source_video_id": source_video.get("video_id", ""),
            "recommendation_count": len(recommendations),
            "average_creativity_score": sum(r["creativity_score"] for r in recommendations) / len(recommendations) if recommendations else 0,
            "top_connection_types": [r.get("creative_connections", {}).get("primary_connection_type", "") for r in recommendations[:3]]
        }
        
        self.recommendation_history.append(record)
        
        # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
        if len(self.recommendation_history) > 200:
            self.recommendation_history = self.recommendation_history[-200:]
        
        # å®šæœŸçš„ã«ä¿å­˜
        if len(self.recommendation_history) % 20 == 0:
            self._save_recommendation_data()
    
    # ä»¥ä¸‹ã€ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã®ç°¡æ˜“å®Ÿè£…
    def _calculate_genre_emotional_similarity(self, genre1: str, genre2: str) -> float:
        """ã‚¸ãƒ£ãƒ³ãƒ«é–“æ„Ÿæƒ…é¡ä¼¼åº¦ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        similar_groups = [
            {"ãƒãƒƒãƒ—ã‚¹", "j-pop", "pop"},
            {"ãƒœã‚«ãƒ­", "vocaloid"},
            {"ãƒ­ãƒƒã‚¯", "rock"},
            {"ãƒãƒ©ãƒ¼ãƒ‰", "ballad"}
        ]
        
        for group in similar_groups:
            if genre1 in group and genre2 in group:
                return 0.8
        
        return 0.2
    
    def _are_contrasting_genres(self, genre1: str, genre2: str) -> bool:
        """ã‚¸ãƒ£ãƒ³ãƒ«ãŒå¯¾ç…§çš„ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        contrasting_pairs = [
            ("ãƒãƒƒãƒ—ã‚¹", "ãƒ­ãƒƒã‚¯"),
            ("ãƒãƒ©ãƒ¼ãƒ‰", "ã‚¢ãƒƒãƒ—ãƒ†ãƒ³ãƒ"),
            ("ã‚¯ãƒ©ã‚·ãƒƒã‚¯", "ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ãƒƒã‚¯")
        ]
        
        for pair in contrasting_pairs:
            if genre1 in pair and genre2 in pair and genre1 != genre2:
                return True
        
        return False
    
    def _generate_connection_reason(self, connections: Dict[str, Any]) -> str:
        """é–¢é€£æ€§ç†ç”±ã‚’ç”Ÿæˆï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        primary_type = connections.get("primary_connection_type", "")
        
        reason_templates = {
            "emotional_resonance": "åŒã˜å¿ƒã®æ·±ã„ã¨ã“ã‚ã§éŸ¿ãåˆã†",
            "contrasting_appeal": "å¯¾ç…§çš„ã§ã‚ã‚ŠãªãŒã‚‰è£œå®Œã—åˆã†",
            "temporal_connection": "æ™‚ä»£ã‚’è¶…ãˆãŸå…±é€šã®ãƒ†ãƒ¼ãƒã§ç¹‹ãŒã‚‹",
            "artistic_technique": "å‰µä½œã«ãŠã‘ã‚‹æŠ€æ³•çš„ãªè¦ªå’Œæ€§",
            "symbolic_connection": "è±¡å¾´çš„ãªæ„å‘³ã§ã®æ·±ã„é–¢é€£æ€§",
            "philosophical_link": "äººç”Ÿã¸ã®åŒã˜å•ã„ã‹ã‘ã‚’æŒã¤"
        }
        
        return reason_templates.get(primary_type, "äºˆæœŸã—ãªã„ç¾ã—ã„é–¢é€£æ€§ã‚’æŒã¤")
    
    # ãã®ä»–ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã¯ç°¡æ˜“å®Ÿè£…
    def _generate_emotion_evolution(self, source_emotion: str, target_emotion: str) -> str:
        return f"{source_emotion}ã‹ã‚‰{target_emotion}ã¸ã®æˆé•·"
    
    def _generate_hidden_quality(self, video: Dict[str, Any]) -> str:
        return "éš ã•ã‚ŒãŸç¾ã—ã•"
    
    def _generate_unexpected_element(self, connections: Dict[str, Any]) -> str:
        return "äºˆæƒ³å¤–ã®é­…åŠ›"
    
    def _generate_surprise_element(self, connections: Dict[str, Any]) -> str:
        return "é©šãã¹ãç™ºè¦‹"
    
    def _generate_relationship_type(self, connections: Dict[str, Any]) -> str:
        return "å§‰å¦¹æ¥½æ›²"
    
    def _generate_shared_quality(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> str:
        return "æ·±ã„æ„Ÿå‹•"
    
    def _generate_personification(self, video: Dict[str, Any]) -> str:
        return "å„ªã—ã„å‹äºº"
    
    def _generate_complementary_character(self, video: Dict[str, Any]) -> str:
        return "ç†è§£ã‚ã‚‹ç›¸æ‰‹"
    
    def _generate_connection_metaphor(self, connections: Dict[str, Any]) -> str:
        return "è¦‹ãˆãªã„ç³¸"
    
    def _generate_transformation_type(self, source_emotion: str, target_emotion: str) -> str:
        return "æ„Ÿæƒ…ã®æ˜‡è¯"
    
    def _generate_transformation_journey(self, connections: Dict[str, Any]) -> str:
        return "å¿ƒã®æˆé•·"
    
    def _generate_synergy_effect(self, connections: Dict[str, Any]) -> str:
        return "æ–°ã—ã„æ„Ÿå‹•"
    
    def _extract_key_quality(self, video: Dict[str, Any]) -> str:
        return "ç‹¬ç‰¹ã®é­…åŠ›"
    
    def _generate_combined_effect(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> str:
        return "ç›¸ä¹—åŠ¹æœçš„ãªç¾ã—ã•"
    
    def _generate_harmony_metaphor(self) -> str:
        return "ç¾ã—ã„ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼"
    
    def _evaluate_narrative_strength(self, connections: Dict[str, Any]) -> float:
        return connections.get("narrative_potential", 0.5)
    
    def _calculate_time_difference(self, date1: str, date2: str) -> int:
        """æ—¥ä»˜å·®åˆ†è¨ˆç®—ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        return 365  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _detect_temporal_themes(self, source_video: Dict[str, Any], target_video: Dict[str, Any]) -> float:
        return 0.5
    
    def _calculate_creator_overlap(self, creators1: List[Dict], creators2: List[Dict]) -> float:
        return 0.5
    
    def _evaluate_composition_similarity(self, music1: Dict, music2: Dict) -> float:
        return 0.5
    
    def _detect_symbolic_overlap(self, title1: str, title2: str) -> float:
        return 0.5
    
    def _analyze_lyrical_symbolism(self, lyrics1: Dict, lyrics2: Dict) -> float:
        return 0.5
    
    def _calculate_musical_theory_similarity(self, genre1: str, genre2: str) -> float:
        return 0.5
    
    def _estimate_key_relationship(self, video1: Dict, video2: Dict) -> float:
        return 0.5
    
    def _extract_philosophical_themes(self, title1: str, title2: str) -> float:
        return 0.5
    
    def _analyze_worldview_similarity(self, desc1: str, desc2: str) -> float:
        return 0.5
    
    def _calculate_genre_distance(self, genre1: str, genre2: str) -> float:
        return 0.5
    
    def _calculate_temporal_surprise(self, video1: Dict, video2: Dict) -> float:
        return 0.5
    
    def _detect_unexpected_combination(self, video1: Dict, video2: Dict) -> float:
        return 0.5
    
    def _detect_surprise_elements(self, source_video: Dict, target_video: Dict) -> List[str]:
        return ["genre_transcendence"]
    
    def _evaluate_narrative_potential(self, connections: Dict) -> float:
        return 0.7
    
    def _detect_tempo_contrast(self, title1: str, title2: str) -> float:
        return 0.3


# ä½¿ç”¨ä¾‹ãƒ»ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    print("=== å‰µé€ çš„æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")
    
    system = CreativeRecommendationSystem()
    
    # ãƒ†ã‚¹ãƒˆç”¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿
    source_video = {
        "video_id": "test1",
        "metadata": {"title": "ã‚¢ãƒ‰ãƒ™ãƒ³ãƒãƒ£ãƒ¼", "channel_title": "YOASOBI"},
        "creative_insight": {
            "music_analysis": {"genre": "ãƒãƒƒãƒ—ã‚¹", "mood": "æ˜ã‚‹ã„"},
            "creators": [{"name": "Ayase", "role": "composer"}]
        }
    }
    
    candidate_videos = [
        {
            "video_id": "test2",
            "metadata": {"title": "XOXO", "channel_title": "TRiNITY"},
            "creative_insight": {
                "music_analysis": {"genre": "ãƒãƒƒãƒ—ã‚¹", "mood": "æ˜ã‚‹ã„"},
                "creators": [{"name": "MATZ", "role": "composer"}]
            }
        }
    ]
    
    # å‰µé€ çš„æ¨è–¦ç”Ÿæˆ
    recommendations = system.generate_creative_recommendation(
        source_video, candidate_videos
    )
    
    print(f"\nğŸ¨ å‰µé€ çš„æ¨è–¦çµæœ:")
    for rec in recommendations:
        print(f"æ¥½æ›²: {rec['video_data']['metadata']['title']}")
        print(f"å‰µé€ æ€§ã‚¹ã‚³ã‚¢: {rec['creativity_score']:.2f}")
        print(f"é–¢é€£æ€§: {rec['creative_connections']['primary_connection_type']}")
        print(f"ãƒŠãƒ©ãƒ†ã‚£ãƒ–: {rec['narrative']['text']}")
        print("---")