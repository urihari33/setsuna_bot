#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼èˆˆå‘³è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ  - Phase 2Då®Ÿè£…
ãƒˆãƒ”ãƒƒã‚¯åˆ¥ã®èˆˆå‘³ãƒ¬ãƒ™ãƒ«ãƒ»ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ¸¬å®šã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¿½è·¡
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
from datetime import datetime, timedelta
import re
import math
from statistics import mean, stdev

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# é–¢é€£ã‚·ã‚¹ãƒ†ãƒ 
try:
    from core.conversation_history_analyzer import ConversationHistoryAnalyzer
    ANALYZER_AVAILABLE = True
except ImportError:
    ANALYZER_AVAILABLE = False

# Windowsãƒ‘ã‚¹è¨­å®š
if os.name == 'nt':
    DATA_DIR = Path("D:/setsuna_bot/data")
    TRACKER_CACHE_DIR = Path("D:/setsuna_bot/interest_tracker_cache")
else:
    DATA_DIR = Path("/mnt/d/setsuna_bot/data")
    TRACKER_CACHE_DIR = Path("/mnt/d/setsuna_bot/interest_tracker_cache")

TRACKER_CACHE_DIR.mkdir(parents=True, exist_ok=True)

@dataclass
class InterestMetrics:
    """èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    topic: str
    current_level: float          # ç¾åœ¨ã®èˆˆå‘³ãƒ¬ãƒ™ãƒ« (0.0-1.0)
    engagement_score: float       # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢
    frequency_score: float        # è¨€åŠé »åº¦ã‚¹ã‚³ã‚¢
    recency_score: float         # æœ€è¿‘æ€§ã‚¹ã‚³ã‚¢
    depth_score: float           # ç†è§£æ·±åº¦ã‚¹ã‚³ã‚¢
    sentiment_score: float       # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢
    trend_direction: str         # "increasing", "stable", "decreasing"
    confidence: float            # ä¿¡é ¼åº¦
    last_updated: str

@dataclass
class EngagementEvent:
    """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    event_id: str
    topic: str
    timestamp: str
    event_type: str              # "mention", "question", "deep_dive", "positive_feedback"
    intensity: float             # ã‚¤ãƒ™ãƒ³ãƒˆå¼·åº¦ (0.0-1.0)
    context: str                 # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    duration: Optional[float]    # æŒç¶šæ™‚é–“ï¼ˆç§’ï¼‰

@dataclass
class InterestCluster:
    """èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    cluster_id: str
    cluster_name: str
    related_topics: List[str]
    cluster_strength: float      # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çµåˆåº¦
    dominant_topic: str          # ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯
    emergence_pattern: str       # å‡ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
    predicted_growth: float      # æˆé•·äºˆæ¸¬

class UserInterestTracker:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼èˆˆå‘³è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
        self.interest_metrics_path = TRACKER_CACHE_DIR / "interest_metrics.json"
        self.engagement_events_path = TRACKER_CACHE_DIR / "engagement_events.json"
        self.interest_clusters_path = TRACKER_CACHE_DIR / "interest_clusters.json"
        self.tracking_history_path = TRACKER_CACHE_DIR / "tracking_history.json"
        
        # ä¼šè©±å±¥æ­´åˆ†æã‚·ã‚¹ãƒ†ãƒ 
        if ANALYZER_AVAILABLE:
            self.history_analyzer = ConversationHistoryAnalyzer()
        else:
            self.history_analyzer = None
            print("[èˆˆå‘³è¿½è·¡] âš ï¸ ä¼šè©±å±¥æ­´åˆ†æã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # ãƒ‡ãƒ¼ã‚¿
        self.interest_metrics = {}
        self.engagement_events = deque(maxlen=1000)  # æœ€æ–°1000ã‚¤ãƒ™ãƒ³ãƒˆ
        self.interest_clusters = {}
        self.tracking_history = []
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¿½è·¡ç”¨
        self.current_session_events = []
        self.session_start_time = datetime.now()
        self.interaction_memory = deque(maxlen=50)  # ç›´è¿‘50ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³
        
        # è¿½è·¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.decay_factor = 0.95       # æ™‚é–“æ¸›è¡°ç‡ï¼ˆæ—¥æ¬¡ï¼‰
        self.recency_weight = 0.3      # æœ€è¿‘æ€§é‡ã¿
        self.frequency_weight = 0.2    # é »åº¦é‡ã¿
        self.depth_weight = 0.2        # æ·±åº¦é‡ã¿
        self.sentiment_weight = 0.3    # æ„Ÿæƒ…é‡ã¿
        
        # ãƒˆãƒ”ãƒƒã‚¯æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
        self.topic_patterns = self._build_topic_patterns()
        self.engagement_indicators = self._build_engagement_indicators()
        self.depth_indicators = self._build_depth_indicators()
        
        # çµ±è¨ˆæƒ…å ±
        self.tracking_statistics = {
            "total_topics_tracked": 0,
            "total_engagement_events": 0,
            "active_clusters": 0,
            "tracking_accuracy": 0.0,
            "last_update": None
        }
        
        self._load_existing_data()
        print("[èˆˆå‘³è¿½è·¡] âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼èˆˆå‘³è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def _build_topic_patterns(self) -> Dict[str, List[str]]:
        """ãƒˆãƒ”ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰"""
        return {
            "éŸ³æ¥½": [
                r"(éŸ³æ¥½|æ›²|æ­Œ|ãƒŸãƒ¥ãƒ¼ã‚¸ãƒƒã‚¯|æ¥½æ›²|ãƒ¡ãƒ­ãƒ‡ã‚£|ãƒªã‚ºãƒ |ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼)",
                r"(ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ|æ­Œæ‰‹|ãƒãƒ³ãƒ‰|ãƒŸãƒ¥ãƒ¼ã‚¸ã‚·ãƒ£ãƒ³|ä½œæ›²å®¶)",
                r"(ã‚¸ãƒ£ãƒ³ãƒ«|ã‚¹ã‚¿ã‚¤ãƒ«|ãƒ†ãƒ³ãƒ|ãƒ“ãƒ¼ãƒˆ)"
            ],
            "å‹•ç”»åˆ¶ä½œ": [
                r"(å‹•ç”»|æ˜ åƒ|ãƒ“ãƒ‡ã‚ª|ã‚³ãƒ³ãƒ†ãƒ³ãƒ„|ç·¨é›†)",
                r"(æ’®å½±|éŒ²ç”»|é…ä¿¡|ã‚¹ãƒˆãƒªãƒ¼ãƒ |ãƒ©ã‚¤ãƒ–)",
                r"(ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ|ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³|ã‚«ãƒƒãƒˆ|ãƒ¢ãƒ³ã‚¿ãƒ¼ã‚¸ãƒ¥)"
            ],
            "ã‚¢ãƒ‹ãƒ¡": [
                r"(ã‚¢ãƒ‹ãƒ¡|ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³|æ¼«ç”»|ãƒãƒ³ã‚¬)",
                r"(ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼|å£°å„ª|ä½œç”»|æ¼”å‡º)",
                r"(äºŒæ¬¡å…ƒ|ã‚ªã‚¿ã‚¯|èŒãˆ|æ¨ã—)"
            ],
            "ã‚²ãƒ¼ãƒ ": [
                r"(ã‚²ãƒ¼ãƒ |ãƒ—ãƒ¬ã‚¤|ã‚²ãƒ¼ãƒŸãƒ³ã‚°|eã‚¹ãƒãƒ¼ãƒ„)",
                r"(å®Ÿæ³|é…ä¿¡|ã‚¹ãƒˆãƒªãƒ¼ãƒãƒ¼|ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼)",
                r"(æ”»ç•¥|ãƒ¬ãƒ™ãƒ«|ã‚¹ã‚­ãƒ«|ãƒ©ãƒ³ã‚¯)"
            ],
            "æŠ€è¡“": [
                r"(æŠ€è¡“|ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼|AI|äººå·¥çŸ¥èƒ½)",
                r"(ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°|ã‚³ãƒ¼ãƒ‰|é–‹ç™º|ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢)",
                r"(ã‚·ã‚¹ãƒ†ãƒ |ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ |ãƒ‡ãƒ¼ã‚¿|ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯)"
            ],
            "å‰µä½œ": [
                r"(å‰µä½œ|åˆ¶ä½œ|ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–|ã‚¢ãƒ¼ãƒˆ)",
                r"(ãƒ‡ã‚¶ã‚¤ãƒ³|ã‚¤ãƒ©ã‚¹ãƒˆ|çµµ|ç”»åƒ)",
                r"(ä½œå“|è¡¨ç¾|ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³|ã‚¢ã‚¤ãƒ‡ã‚¢)"
            ]
        }
    
    def _build_engagement_indicators(self) -> Dict[str, List[str]]:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™æ§‹ç¯‰"""
        return {
            "high_engagement": [
                "ã™ã”ã", "ã¨ã¦ã‚‚", "ã‚ã¡ã‚ƒãã¡ã‚ƒ", "æœ€é«˜", "ç´ æ™´ã‚‰ã—ã„", "æ„Ÿå‹•",
                "å¤¢ä¸­", "ãƒãƒã‚‹", "ãŠæ°—ã«å…¥ã‚Š", "å¤§å¥½ã", "èˆˆå¥®", "ã‚ãã‚ã"
            ],
            "medium_engagement": [
                "ã„ã„ã­", "è‰¯ã„", "é¢ç™½ã„", "èˆˆå‘³æ·±ã„", "æ°—ã«ãªã‚‹", "å¥½ã",
                "ãªã‚‹ã»ã©", "ã¸ãƒ¼", "ãã†ãªã‚“ã ", "çŸ¥ã‚‰ãªã‹ã£ãŸ"
            ],
            "low_engagement": [
                "ã¾ã‚ã¾ã‚", "æ™®é€š", "ãã†ã§ã™ã­", "ãµãƒ¼ã‚“", "ãã†ã‹ã‚‚",
                "ã©ã†ã‹ãª", "å¾®å¦™", "ã„ã¾ã„ã¡"
            ],
            "question_engagement": [
                "ã©ã†ã‚„ã£ã¦", "ãªãœ", "ã©ã‚“ãª", "æ•™ãˆã¦", "è©³ã—ã", "ã‚‚ã£ã¨",
                "ä»–ã«ã¯", "ä¾‹ãˆã°", "å…·ä½“çš„ã«", "åˆ†ã‹ã‚‰ãªã„"
            ]
        }
    
    def _build_depth_indicators(self) -> Dict[str, List[str]]:
        """æ·±åº¦æŒ‡æ¨™æ§‹ç¯‰"""
        return {
            "surface": [
                "çŸ¥ã‚‰ãªã„", "åˆã‚ã¦", "èã„ãŸã“ã¨ãªã„", "ä½•ãã‚Œ", "ã©ã†ã„ã†æ„å‘³",
                "ç°¡å˜ã«", "åŸºæœ¬çš„", "å…¥é–€", "åˆå¿ƒè€…"
            ],
            "intermediate": [
                "çŸ¥ã£ã¦ã‚‹", "èã„ãŸã“ã¨ã‚ã‚‹", "ã ã„ãŸã„", "ã‚ã‚‹ç¨‹åº¦", "ã¾ã‚ã¾ã‚",
                "ä¸€èˆ¬çš„", "æ™®é€š", "æ¨™æº–çš„", "ä¸­ç´š"
            ],
            "advanced": [
                "è©³ã—ã„", "å°‚é–€çš„", "é«˜åº¦", "ãƒãƒ‹ã‚¢ãƒƒã‚¯", "ãƒ—ãƒ­ç´š", "ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ",
                "æ·±ã", "æœ¬æ ¼çš„", "æŠ€è¡“çš„", "ä¸Šç´š"
            ]
        }
    
    def _load_existing_data(self):
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰"""
        # èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        try:
            if self.interest_metrics_path.exists():
                with open(self.interest_metrics_path, 'r', encoding='utf-8') as f:
                    metrics_data = json.load(f)
                    self.interest_metrics = {
                        topic: InterestMetrics(**data) 
                        for topic, data in metrics_data.get("metrics", {}).items()
                    }
                print(f"[èˆˆå‘³è¿½è·¡] ğŸ“Š {len(self.interest_metrics)}å€‹ã®èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[èˆˆå‘³è¿½è·¡] âš ï¸ èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆ
        try:
            if self.engagement_events_path.exists():
                with open(self.engagement_events_path, 'r', encoding='utf-8') as f:
                    events_data = json.load(f)
                    events_list = events_data.get("events", [])
                    self.engagement_events = deque(
                        [EngagementEvent(**event) for event in events_list],
                        maxlen=1000
                    )
                print(f"[èˆˆå‘³è¿½è·¡] ğŸ“Š {len(self.engagement_events)}å€‹ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[èˆˆå‘³è¿½è·¡] âš ï¸ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        # èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
        try:
            if self.interest_clusters_path.exists():
                with open(self.interest_clusters_path, 'r', encoding='utf-8') as f:
                    clusters_data = json.load(f)
                    self.interest_clusters = {
                        cid: InterestCluster(**cluster) 
                        for cid, cluster in clusters_data.get("clusters", {}).items()
                    }
                print(f"[èˆˆå‘³è¿½è·¡] ğŸ“Š {len(self.interest_clusters)}å€‹ã®èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[èˆˆå‘³è¿½è·¡] âš ï¸ èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    def track_user_interaction(self, user_input: str, context: Optional[str] = None) -> List[str]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¿½è·¡"""
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
        interaction = {
            "timestamp": datetime.now().isoformat(),
            "user_input": user_input,
            "context": context or "",
            "processed": False
        }
        self.interaction_memory.append(interaction)
        
        # ãƒˆãƒ”ãƒƒã‚¯æ¤œå‡º
        detected_topics = self._detect_topics_in_text(user_input)
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆç”Ÿæˆ
        for topic in detected_topics:
            events = self._generate_engagement_events(topic, user_input, context)
            for event in events:
                self.engagement_events.append(event)
                self.current_session_events.append(event)
        
        # èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        for topic in detected_topics:
            self._update_interest_metrics(topic, user_input)
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†æ¸ˆã¿ãƒãƒ¼ã‚¯
        interaction["processed"] = True
        
        return detected_topics
    
    def _detect_topics_in_text(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ãƒˆãƒ”ãƒƒã‚¯æ¤œå‡º"""
        detected_topics = []
        
        for topic, patterns in self.topic_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text):
                    detected_topics.append(topic)
                    break
        
        return detected_topics
    
    def _generate_engagement_events(self, topic: str, user_input: str, context: Optional[str]) -> List[EngagementEvent]:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆç”Ÿæˆ"""
        events = []
        timestamp = datetime.now().isoformat()
        
        # åŸºæœ¬è¨€åŠã‚¤ãƒ™ãƒ³ãƒˆ
        base_intensity = 0.3
        event_id = f"mention_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        events.append(EngagementEvent(
            event_id=event_id,
            topic=topic,
            timestamp=timestamp,
            event_type="mention",
            intensity=base_intensity,
            context=user_input[:200],
            duration=None
        ))
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«åˆ¥ã‚¤ãƒ™ãƒ³ãƒˆ
        engagement_level = self._assess_engagement_level(user_input)
        if engagement_level in ["high", "medium"]:
            intensity = 0.8 if engagement_level == "high" else 0.6
            event_id = f"engagement_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
            
            events.append(EngagementEvent(
                event_id=event_id,
                topic=topic,
                timestamp=timestamp,
                event_type=f"{engagement_level}_engagement",
                intensity=intensity,
                context=user_input[:200],
                duration=None
            ))
        
        # è³ªå•ã‚¤ãƒ™ãƒ³ãƒˆ
        if self._is_question_about_topic(user_input, topic):
            event_id = f"question_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
            
            events.append(EngagementEvent(
                event_id=event_id,
                topic=topic,
                timestamp=timestamp,
                event_type="question",
                intensity=0.7,
                context=user_input[:200],
                duration=None
            ))
        
        # æ·±æ˜ã‚Šã‚¤ãƒ™ãƒ³ãƒˆ
        depth_level = self._assess_depth_level(user_input)
        if depth_level == "advanced":
            event_id = f"deep_dive_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
            
            events.append(EngagementEvent(
                event_id=event_id,
                topic=topic,
                timestamp=timestamp,
                event_type="deep_dive",
                intensity=0.9,
                context=user_input[:200],
                duration=None
            ))
        
        return events
    
    def _assess_engagement_level(self, text: str) -> str:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«è©•ä¾¡"""
        high_count = sum(1 for indicator in self.engagement_indicators["high_engagement"] if indicator in text)
        medium_count = sum(1 for indicator in self.engagement_indicators["medium_engagement"] if indicator in text)
        low_count = sum(1 for indicator in self.engagement_indicators["low_engagement"] if indicator in text)
        
        if high_count > 0:
            return "high"
        elif medium_count > 0:
            return "medium"
        elif low_count > 0:
            return "low"
        else:
            return "neutral"
    
    def _is_question_about_topic(self, text: str, topic: str) -> bool:
        """ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹è³ªå•ã‹ã©ã†ã‹åˆ¤å®š"""
        # è³ªå•ãƒãƒ¼ã‚«ãƒ¼
        question_markers = ["?", "ï¼Ÿ", "ä½•", "ã©ã†", "ãªãœ", "ã„ã¤", "ã©ã“", "èª°", "ã©ã‚“ãª"]
        has_question_marker = any(marker in text for marker in question_markers)
        
        # ãƒˆãƒ”ãƒƒã‚¯é–¢é€£
        topic_patterns = self.topic_patterns.get(topic, [])
        has_topic_reference = any(re.search(pattern, text) for pattern in topic_patterns)
        
        return has_question_marker and has_topic_reference
    
    def _assess_depth_level(self, text: str) -> str:
        """æ·±åº¦ãƒ¬ãƒ™ãƒ«è©•ä¾¡"""
        surface_count = sum(1 for indicator in self.depth_indicators["surface"] if indicator in text)
        intermediate_count = sum(1 for indicator in self.depth_indicators["intermediate"] if indicator in text)
        advanced_count = sum(1 for indicator in self.depth_indicators["advanced"] if indicator in text)
        
        if advanced_count > 0:
            return "advanced"
        elif intermediate_count > 0:
            return "intermediate"
        elif surface_count > 0:
            return "surface"
        else:
            return "intermediate"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _update_interest_metrics(self, topic: str, user_input: str):
        """èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°"""
        # æ—¢å­˜ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã¾ãŸã¯æ–°è¦ä½œæˆ
        if topic not in self.interest_metrics:
            self.interest_metrics[topic] = InterestMetrics(
                topic=topic,
                current_level=0.5,
                engagement_score=0.0,
                frequency_score=0.0,
                recency_score=1.0,
                depth_score=0.5,
                sentiment_score=0.5,
                trend_direction="stable",
                confidence=0.5,
                last_updated=datetime.now().isoformat()
            )
        
        metrics = self.interest_metrics[topic]
        
        # å„ç¨®ã‚¹ã‚³ã‚¢æ›´æ–°
        # 1. é »åº¦ã‚¹ã‚³ã‚¢
        metrics.frequency_score = self._calculate_frequency_score(topic)
        
        # 2. æœ€è¿‘æ€§ã‚¹ã‚³ã‚¢
        metrics.recency_score = 1.0  # ç¾åœ¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãªã®ã§æœ€é«˜å€¤
        
        # 3. ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢
        engagement_level = self._assess_engagement_level(user_input)
        engagement_boost = {
            "high": 0.3,
            "medium": 0.2,
            "low": 0.1,
            "neutral": 0.05
        }.get(engagement_level, 0.05)
        metrics.engagement_score = min(1.0, metrics.engagement_score + engagement_boost)
        
        # 4. æ·±åº¦ã‚¹ã‚³ã‚¢
        depth_level = self._assess_depth_level(user_input)
        depth_values = {"surface": 0.2, "intermediate": 0.5, "advanced": 0.9}
        new_depth = depth_values.get(depth_level, 0.5)
        metrics.depth_score = (metrics.depth_score * 0.7) + (new_depth * 0.3)  # ç§»å‹•å¹³å‡
        
        # 5. æ„Ÿæƒ…ã‚¹ã‚³ã‚¢
        sentiment = self._assess_sentiment(user_input)
        metrics.sentiment_score = (metrics.sentiment_score * 0.8) + (sentiment * 0.2)
        
        # 6. ç·åˆèˆˆå‘³ãƒ¬ãƒ™ãƒ«è¨ˆç®—
        metrics.current_level = (
            metrics.frequency_score * self.frequency_weight +
            metrics.recency_score * self.recency_weight +
            metrics.engagement_score * 0.25 +
            metrics.depth_score * self.depth_weight +
            metrics.sentiment_score * self.sentiment_weight
        )
        metrics.current_level = max(0.0, min(1.0, metrics.current_level))
        
        # 7. ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘æ›´æ–°
        metrics.trend_direction = self._calculate_trend_direction(topic)
        
        # 8. ä¿¡é ¼åº¦æ›´æ–°
        metrics.confidence = self._calculate_confidence(topic)
        
        # æ›´æ–°æ™‚åˆ»è¨˜éŒ²
        metrics.last_updated = datetime.now().isoformat()
    
    def _calculate_frequency_score(self, topic: str) -> float:
        """é »åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        # éå»30æ—¥é–“ã®è¨€åŠå›æ•°
        cutoff_date = datetime.now() - timedelta(days=30)
        recent_events = [
            event for event in self.engagement_events 
            if event.topic == topic and datetime.fromisoformat(event.timestamp) > cutoff_date
        ]
        
        frequency = len(recent_events)
        # æ­£è¦åŒ–ï¼ˆé€±1å›ã§0.5ã€æ¯æ—¥ã§1.0ï¼‰
        return min(1.0, frequency / 30)
    
    def _assess_sentiment(self, text: str) -> float:
        """æ„Ÿæƒ…è©•ä¾¡"""
        positive_indicators = ["å¥½ã", "è‰¯ã„", "ç´ æ™´ã‚‰ã—ã„", "æœ€é«˜", "æ°—ã«å…¥ã£ãŸ", "é¢ç™½ã„", "æ¥½ã—ã„"]
        negative_indicators = ["å«Œã„", "æ‚ªã„", "ã¤ã¾ã‚‰ãªã„", "å¾®å¦™", "ã„ã¾ã„ã¡", "æ®‹å¿µ"]
        
        positive_count = sum(1 for indicator in positive_indicators if indicator in text)
        negative_count = sum(1 for indicator in negative_indicators if indicator in text)
        
        if positive_count > negative_count:
            return 0.8
        elif negative_count > positive_count:
            return 0.2
        else:
            return 0.5
    
    def _calculate_trend_direction(self, topic: str) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘è¨ˆç®—"""
        # éå»ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ã‹ã‚‰å‚¾å‘ã‚’åˆ†æ
        # ç°¡æ˜“å®Ÿè£…ï¼šç›´è¿‘3ã‚¤ãƒ™ãƒ³ãƒˆã®å¼·åº¦æ¨ç§»
        recent_events = [
            event for event in list(self.engagement_events)[-10:] 
            if event.topic == topic
        ]
        
        if len(recent_events) < 2:
            return "stable"
        
        recent_intensities = [event.intensity for event in recent_events[-3:]]
        
        if len(recent_intensities) >= 2:
            if recent_intensities[-1] > recent_intensities[0] + 0.1:
                return "increasing"
            elif recent_intensities[-1] < recent_intensities[0] - 0.1:
                return "decreasing"
        
        return "stable"
    
    def _calculate_confidence(self, topic: str) -> float:
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        # ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã¨æ™‚é–“çš„åˆ†æ•£ã«åŸºã¥ãä¿¡é ¼åº¦
        topic_events = [event for event in self.engagement_events if event.topic == topic]
        
        event_count = len(topic_events)
        if event_count == 0:
            return 0.0
        
        # ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã«ã‚ˆã‚‹ä¿¡é ¼åº¦ï¼ˆ10ã‚¤ãƒ™ãƒ³ãƒˆã§0.8ï¼‰
        count_confidence = min(0.8, event_count / 10)
        
        # æ™‚é–“çš„åˆ†æ•£ã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        if event_count > 1:
            timestamps = [datetime.fromisoformat(event.timestamp) for event in topic_events]
            time_span = (max(timestamps) - min(timestamps)).total_seconds()
            span_confidence = min(0.2, time_span / (7 * 24 * 3600))  # 1é€±é–“ã§0.2
        else:
            span_confidence = 0.0
        
        return count_confidence + span_confidence
    
    def analyze_interest_clusters(self) -> Dict[str, InterestCluster]:
        """èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ"""
        print("[èˆˆå‘³è¿½è·¡] ğŸ¯ èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’åˆ†æä¸­...")
        
        clusters = {}
        
        # ãƒˆãƒ”ãƒƒã‚¯é–“ã®é–¢é€£æ€§åˆ†æ
        topic_correlations = self._calculate_topic_correlations()
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        cluster_groups = self._perform_interest_clustering(topic_correlations)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è©³ç´°åˆ†æ
        for i, group in enumerate(cluster_groups):
            cluster_id = f"cluster_{i+1}"
            cluster = self._analyze_cluster_details(cluster_id, group)
            clusters[cluster_id] = cluster
        
        self.interest_clusters = clusters
        self._save_interest_clusters()
        
        print(f"[èˆˆå‘³è¿½è·¡] âœ… {len(clusters)}å€‹ã®èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ç™ºè¦‹")
        return clusters
    
    def _calculate_topic_correlations(self) -> Dict[Tuple[str, str], float]:
        """ãƒˆãƒ”ãƒƒã‚¯é–“ç›¸é–¢è¨ˆç®—"""
        correlations = {}
        topics = list(self.interest_metrics.keys())
        
        for i in range(len(topics)):
            for j in range(i + 1, len(topics)):
                topic1, topic2 = topics[i], topics[j]
                correlation = self._calculate_pairwise_correlation(topic1, topic2)
                correlations[(topic1, topic2)] = correlation
        
        return correlations
    
    def _calculate_pairwise_correlation(self, topic1: str, topic2: str) -> float:
        """ãƒšã‚¢ãƒ¯ã‚¤ã‚ºç›¸é–¢è¨ˆç®—"""
        # åŒã˜ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®å…±èµ·é »åº¦
        co_occurrences = 0
        total_sessions = 0
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å…±èµ·åˆ†æ
        session_topics = defaultdict(set)
        
        for event in self.engagement_events:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ä»£ã‚ã‚Šã«æ™‚é–“çª“ã‚’ä½¿ç”¨ï¼ˆ1æ™‚é–“ä»¥å†…ï¼‰
            session_key = event.timestamp[:13]  # YYYY-MM-DDTHH
            session_topics[session_key].add(event.topic)
        
        for session, topics in session_topics.items():
            total_sessions += 1
            if topic1 in topics and topic2 in topics:
                co_occurrences += 1
        
        if total_sessions == 0:
            return 0.0
        
        return co_occurrences / total_sessions
    
    def _perform_interest_clustering(self, correlations: Dict[Tuple[str, str], float]) -> List[List[str]]:
        """èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ"""
        # ç°¡æ˜“éšå±¤ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        topics = list(self.interest_metrics.keys())
        
        if len(topics) <= 1:
            return [topics] if topics else []
        
        # ç›¸é–¢ã®é«˜ã„ãƒšã‚¢ã‚’è¦‹ã¤ã‘ã‚‹
        clusters = [[topic] for topic in topics]
        correlation_threshold = 0.3
        
        merged = True
        while merged and len(clusters) > 1:
            merged = False
            best_merge = None
            best_correlation = 0
            
            for i in range(len(clusters)):
                for j in range(i + 1, len(clusters)):
                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ã®æœ€å¤§ç›¸é–¢ã‚’è¨ˆç®—
                    max_corr = 0
                    for topic1 in clusters[i]:
                        for topic2 in clusters[j]:
                            pair = (topic1, topic2) if topic1 < topic2 else (topic2, topic1)
                            corr = correlations.get(pair, 0)
                            max_corr = max(max_corr, corr)
                    
                    if max_corr > correlation_threshold and max_corr > best_correlation:
                        best_correlation = max_corr
                        best_merge = (i, j)
            
            if best_merge:
                i, j = best_merge
                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒ¼ã‚¸
                clusters[i].extend(clusters[j])
                clusters.pop(j)
                merged = True
        
        return clusters
    
    def _analyze_cluster_details(self, cluster_id: str, topics: List[str]) -> InterestCluster:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è©³ç´°åˆ†æ"""
        # ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯ï¼ˆæœ€é«˜èˆˆå‘³ãƒ¬ãƒ™ãƒ«ï¼‰
        dominant_topic = max(topics, key=lambda t: self.interest_metrics.get(t, InterestMetrics(
            topic=t, current_level=0, engagement_score=0, frequency_score=0, 
            recency_score=0, depth_score=0, sentiment_score=0, trend_direction="stable",
            confidence=0, last_updated=""
        )).current_level)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¼·åº¦ï¼ˆå¹³å‡èˆˆå‘³ãƒ¬ãƒ™ãƒ«ï¼‰
        cluster_strength = mean([
            self.interest_metrics.get(topic, InterestMetrics(
                topic=topic, current_level=0, engagement_score=0, frequency_score=0,
                recency_score=0, depth_score=0, sentiment_score=0, trend_direction="stable",
                confidence=0, last_updated=""
            )).current_level 
            for topic in topics
        ]) if topics else 0.0
        
        # å‡ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        emergence_pattern = self._analyze_emergence_pattern(topics)
        
        # æˆé•·äºˆæ¸¬
        predicted_growth = self._predict_cluster_growth(topics)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åç”Ÿæˆ
        cluster_name = self._generate_cluster_name(topics, dominant_topic)
        
        return InterestCluster(
            cluster_id=cluster_id,
            cluster_name=cluster_name,
            related_topics=topics,
            cluster_strength=cluster_strength,
            dominant_topic=dominant_topic,
            emergence_pattern=emergence_pattern,
            predicted_growth=predicted_growth
        )
    
    def _analyze_emergence_pattern(self, topics: List[str]) -> str:
        """å‡ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        # å„ãƒˆãƒ”ãƒƒã‚¯ã®åˆå›è¨€åŠæ™‚æœŸåˆ†æ
        first_mentions = {}
        
        for topic in topics:
            topic_events = [event for event in self.engagement_events if event.topic == topic]
            if topic_events:
                first_mentions[topic] = min(event.timestamp for event in topic_events)
        
        if len(first_mentions) <= 1:
            return "single_topic"
        
        # æ™‚é–“çš„è¿‘æ¥æ€§åˆ†æ
        timestamps = [datetime.fromisoformat(ts) for ts in first_mentions.values()]
        time_span = (max(timestamps) - min(timestamps)).total_seconds()
        
        if time_span < 3600:  # 1æ™‚é–“ä»¥å†…
            return "simultaneous"
        elif time_span < 86400:  # 1æ—¥ä»¥å†…
            return "same_day"
        elif time_span < 604800:  # 1é€±é–“ä»¥å†…
            return "gradual"
        else:
            return "distributed"
    
    def _predict_cluster_growth(self, topics: List[str]) -> float:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æˆé•·äºˆæ¸¬"""
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ã«åŸºã¥ãæˆé•·äºˆæ¸¬
        growth_indicators = []
        
        for topic in topics:
            metrics = self.interest_metrics.get(topic)
            if metrics:
                if metrics.trend_direction == "increasing":
                    growth_indicators.append(0.8)
                elif metrics.trend_direction == "stable":
                    growth_indicators.append(0.5)
                else:  # decreasing
                    growth_indicators.append(0.2)
        
        return mean(growth_indicators) if growth_indicators else 0.5
    
    def _generate_cluster_name(self, topics: List[str], dominant_topic: str) -> str:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åç”Ÿæˆ"""
        if len(topics) == 1:
            return topics[0]
        elif len(topics) == 2:
            return f"{topics[0]}ãƒ»{topics[1]}"
        else:
            return f"{dominant_topic}ç³»ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼"
    
    def get_interest_summary(self) -> Dict[str, Any]:
        """èˆˆå‘³ã‚µãƒãƒªãƒ¼å–å¾—"""
        # èˆˆå‘³ãƒ¬ãƒ™ãƒ«é †ã‚½ãƒ¼ãƒˆ
        sorted_interests = sorted(
            self.interest_metrics.items(),
            key=lambda x: x[1].current_level,
            reverse=True
        )
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
        active_clusters = [
            cluster for cluster in self.interest_clusters.values()
            if cluster.cluster_strength > 0.5
        ]
        
        # æœ€è¿‘ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ
        recent_events = [
            event for event in list(self.engagement_events)[-10:]
        ]
        
        return {
            "top_interests": [
                {
                    "topic": topic,
                    "level": metrics.current_level,
                    "trend": metrics.trend_direction,
                    "confidence": metrics.confidence
                }
                for topic, metrics in sorted_interests[:5]
            ],
            "active_clusters": [
                {
                    "name": cluster.cluster_name,
                    "strength": cluster.cluster_strength,
                    "topics": cluster.related_topics
                }
                for cluster in active_clusters
            ],
            "recent_activity": [
                {
                    "topic": event.topic,
                    "type": event.event_type,
                    "intensity": event.intensity,
                    "timestamp": event.timestamp
                }
                for event in recent_events
            ],
            "statistics": self.tracking_statistics
        }
    
    def decay_interest_scores(self):
        """èˆˆå‘³ã‚¹ã‚³ã‚¢æ™‚é–“æ¸›è¡°"""
        print("[èˆˆå‘³è¿½è·¡] â° èˆˆå‘³ã‚¹ã‚³ã‚¢ã®æ™‚é–“æ¸›è¡°ã‚’å®Ÿè¡Œä¸­...")
        
        current_time = datetime.now()
        
        for topic, metrics in self.interest_metrics.items():
            last_updated = datetime.fromisoformat(metrics.last_updated)
            days_elapsed = (current_time - last_updated).total_seconds() / 86400
            
            # æ¸›è¡°é©ç”¨
            decay_multiplier = self.decay_factor ** days_elapsed
            
            metrics.current_level *= decay_multiplier
            metrics.engagement_score *= decay_multiplier
            metrics.recency_score *= decay_multiplier
            
            # æœ€å°å€¤é©ç”¨
            metrics.current_level = max(0.0, metrics.current_level)
            metrics.engagement_score = max(0.0, metrics.engagement_score)
            metrics.recency_score = max(0.0, metrics.recency_score)
        
        print("[èˆˆå‘³è¿½è·¡] âœ… æ™‚é–“æ¸›è¡°å®Œäº†")
    
    def _save_interest_metrics(self):
        """èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜"""
        try:
            metrics_data = {
                "metrics": {topic: asdict(metrics) for topic, metrics in self.interest_metrics.items()},
                "metadata": {
                    "total_topics": len(self.interest_metrics),
                    "last_updated": datetime.now().isoformat()
                }
            }
            
            with open(self.interest_metrics_path, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[èˆˆå‘³è¿½è·¡] âš ï¸ èˆˆå‘³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_engagement_events(self):
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆä¿å­˜"""
        try:
            events_data = {
                "events": [asdict(event) for event in self.engagement_events],
                "metadata": {
                    "total_events": len(self.engagement_events),
                    "last_updated": datetime.now().isoformat()
                }
            }
            
            with open(self.engagement_events_path, 'w', encoding='utf-8') as f:
                json.dump(events_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[èˆˆå‘³è¿½è·¡] âš ï¸ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_interest_clusters(self):
        """èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¿å­˜"""
        try:
            clusters_data = {
                "clusters": {cid: asdict(cluster) for cid, cluster in self.interest_clusters.items()},
                "metadata": {
                    "total_clusters": len(self.interest_clusters),
                    "last_updated": datetime.now().isoformat()
                }
            }
            
            with open(self.interest_clusters_path, 'w', encoding='utf-8') as f:
                json.dump(clusters_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[èˆˆå‘³è¿½è·¡] âš ï¸ èˆˆå‘³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def save_all_data(self):
        """å…¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        self._save_interest_metrics()
        self._save_engagement_events()
        self._save_interest_clusters()
        
        # çµ±è¨ˆæ›´æ–°
        self.tracking_statistics.update({
            "total_topics_tracked": len(self.interest_metrics),
            "total_engagement_events": len(self.engagement_events),
            "active_clusters": len([c for c in self.interest_clusters.values() if c.cluster_strength > 0.5]),
            "last_update": datetime.now().isoformat()
        })
    
    def get_tracking_statistics(self) -> Dict[str, Any]:
        """è¿½è·¡çµ±è¨ˆæƒ…å ±å–å¾—"""
        return dict(self.tracking_statistics)