#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ  - Phase 2Bå®Ÿè£…
å‹•ç”»ãƒ»ä¼šè©±ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆé–“ã®é–¢é€£æ€§ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹çŸ¥è­˜ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
from datetime import datetime
import hashlib
import math
import networkx as nx
from difflib import SequenceMatcher

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Windowsãƒ‘ã‚¹è¨­å®š
if os.name == 'nt':
    DATA_DIR = Path("D:/setsuna_bot/youtube_knowledge_system/data")
    GRAPH_DIR = Path("D:/setsuna_bot/knowledge_graph")
    CONVERSATION_DIR = Path("D:/setsuna_bot/data")
else:
    DATA_DIR = Path("/mnt/d/setsuna_bot/youtube_knowledge_system/data")
    GRAPH_DIR = Path("/mnt/d/setsuna_bot/knowledge_graph")
    CONVERSATION_DIR = Path("/mnt/d/setsuna_bot/data")

GRAPH_DIR.mkdir(parents=True, exist_ok=True)

@dataclass
class KnowledgeNode:
    """çŸ¥è­˜ãƒãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    node_id: str
    node_type: str  # "video", "artist", "genre", "concept", "conversation"
    title: str
    attributes: Dict[str, Any]
    relevance_score: float
    created_at: str
    updated_at: str

@dataclass
class KnowledgeEdge:
    """çŸ¥è­˜ã‚¨ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    edge_id: str
    source_id: str
    target_id: str
    relationship_type: str  # "similarity", "association", "sequence", "genre", "collaboration"
    strength: float
    evidence: List[str]  # é–¢é€£æ€§ã®æ ¹æ‹ 
    created_at: str

@dataclass
class GraphCluster:
    """ã‚°ãƒ©ãƒ•ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    cluster_id: str
    cluster_type: str
    node_ids: List[str]
    central_concepts: List[str]
    cohesion_score: float
    description: str

class KnowledgeGraphSystem:
    """çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.knowledge_db_path = DATA_DIR / "unified_knowledge_db.json"
        self.graph_data_path = GRAPH_DIR / "knowledge_graph.json"
        self.clusters_path = GRAPH_DIR / "graph_clusters.json"
        self.conversation_history_path = CONVERSATION_DIR / "video_conversation_history.json"
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•
        self.graph = nx.Graph()
        self.knowledge_nodes = {}
        self.knowledge_edges = {}
        self.clusters = {}
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.knowledge_db = {}
        self.conversation_history = {}
        
        # é–¢é€£æ€§è¨ˆç®—ç”¨ã®é‡ã¿è¨­å®š
        self.relationship_weights = {
            "same_artist": 0.9,
            "same_genre": 0.7,
            "same_theme": 0.6,
            "similar_mood": 0.5,
            "collaboration": 0.8,
            "sequence": 0.4,
            "user_preference": 0.6,
            "conversation_context": 0.5
        }
        
        # çµ±è¨ˆæƒ…å ±
        self.graph_statistics = {
            "total_nodes": 0,
            "total_edges": 0,
            "clusters_count": 0,
            "last_rebuild": None,
            "coverage_rate": 0.0
        }
        
        self._load_data()
        self._initialize_graph()
        
        print("[çŸ¥è­˜ã‚°ãƒ©ãƒ•] âœ… çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def _load_data(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰"""
        # YouTubeçŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        try:
            if self.knowledge_db_path.exists():
                with open(self.knowledge_db_path, 'r', encoding='utf-8') as f:
                    self.knowledge_db = json.load(f)
                video_count = len(self.knowledge_db.get("videos", {}))
                print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ“Š {video_count}ä»¶ã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] âŒ å‹•ç”»ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ä¼šè©±å±¥æ­´
        try:
            if self.conversation_history_path.exists():
                with open(self.conversation_history_path, 'r', encoding='utf-8') as f:
                    self.conversation_history = json.load(f)
                conv_count = len(self.conversation_history.get("conversations", {}))
                print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ’¬ {conv_count}ä»¶ã®ä¼šè©±å±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] âš ï¸ ä¼šè©±å±¥æ­´ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ—¢å­˜ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
        try:
            if self.graph_data_path.exists():
                with open(self.graph_data_path, 'r', encoding='utf-8') as f:
                    graph_data = json.load(f)
                    self.knowledge_nodes = {nid: KnowledgeNode(**node) for nid, node in graph_data.get("nodes", {}).items()}
                    self.knowledge_edges = {eid: KnowledgeEdge(**edge) for eid, edge in graph_data.get("edges", {}).items()}
                print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ”— æ—¢å­˜ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e:
            print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] âš ï¸ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _initialize_graph(self):
        """ã‚°ãƒ©ãƒ•åˆæœŸåŒ–"""
        # ãƒãƒ¼ãƒ‰è¿½åŠ 
        for node_id, node in self.knowledge_nodes.items():
            self.graph.add_node(node_id, **asdict(node))
        
        # ã‚¨ãƒƒã‚¸è¿½åŠ 
        for edge in self.knowledge_edges.values():
            if edge.source_id in self.graph.nodes and edge.target_id in self.graph.nodes:
                self.graph.add_edge(
                    edge.source_id, 
                    edge.target_id, 
                    weight=edge.strength,
                    relationship_type=edge.relationship_type,
                    edge_data=edge
                )
        
        # çµ±è¨ˆæ›´æ–°
        self._update_statistics()
    
    def build_knowledge_graph(self, force_rebuild: bool = False):
        """çŸ¥è­˜ã‚°ãƒ©ãƒ•æ§‹ç¯‰"""
        if not force_rebuild and self.knowledge_nodes:
            print("[çŸ¥è­˜ã‚°ãƒ©ãƒ•] æ—¢å­˜ã‚°ãƒ©ãƒ•ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆforce_rebuild=Trueã§å†æ§‹ç¯‰ï¼‰")
            return
        
        print("[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ“Š çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ä¸­...")
        
        # ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢
        self.graph.clear()
        self.knowledge_nodes.clear()
        self.knowledge_edges.clear()
        
        # Phase 1: å‹•ç”»ãƒãƒ¼ãƒ‰ä½œæˆ
        self._create_video_nodes()
        
        # Phase 2: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ/æ¦‚å¿µãƒãƒ¼ãƒ‰ä½œæˆ  
        self._create_concept_nodes()
        
        # Phase 3: ä¼šè©±ãƒãƒ¼ãƒ‰ä½œæˆ
        self._create_conversation_nodes()
        
        # Phase 4: é–¢é€£æ€§ã‚¨ãƒƒã‚¸æ§‹ç¯‰
        self._build_relationships()
        
        # Phase 5: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        self._perform_clustering()
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        self._save_graph_data()
        
        # çµ±è¨ˆæ›´æ–°
        self._update_statistics()
        
        print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] âœ… ã‚°ãƒ©ãƒ•æ§‹ç¯‰å®Œäº†: {len(self.knowledge_nodes)}ãƒãƒ¼ãƒ‰, {len(self.knowledge_edges)}ã‚¨ãƒƒã‚¸")
    
    def _create_video_nodes(self):
        """å‹•ç”»ãƒãƒ¼ãƒ‰ä½œæˆ"""
        videos = self.knowledge_db.get("videos", {})
        
        for video_id, video_data in videos.items():
            metadata = video_data.get("metadata", {})
            custom_info = video_data.get("custom_info", {})
            creative_insight = video_data.get("creative_insight", {})
            
            # ãƒãƒ¼ãƒ‰å±æ€§
            attributes = {
                "title": custom_info.get("manual_title") or metadata.get("title", ""),
                "artist": custom_info.get("manual_artist") or metadata.get("channel_title", ""),
                "duration": metadata.get("duration", ""),
                "view_count": metadata.get("view_count", 0),
                "published_at": metadata.get("published_at", ""),
                "themes": creative_insight.get("themes", []),
                "genres": custom_info.get("manual_genre", "").split(",") if custom_info.get("manual_genre") else [],
                "mood": custom_info.get("manual_mood", ""),
                "tags": metadata.get("tags", []),
                "creators": creative_insight.get("creators", [])
            }
            
            # é–¢é€£åº¦ã‚¹ã‚³ã‚¢ï¼ˆå†ç”Ÿæ•°ã€ã„ã„ã­æ•°ç­‰ã‹ã‚‰ç®—å‡ºï¼‰
            relevance_score = self._calculate_video_relevance(metadata)
            
            node = KnowledgeNode(
                node_id=f"video_{video_id}",
                node_type="video",
                title=attributes["title"],
                attributes=attributes,
                relevance_score=relevance_score,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat()
            )
            
            self.knowledge_nodes[node.node_id] = node
            self.graph.add_node(node.node_id, **asdict(node))
    
    def _create_concept_nodes(self):
        """æ¦‚å¿µãƒãƒ¼ãƒ‰ä½œæˆï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã€ã‚¸ãƒ£ãƒ³ãƒ«ç­‰ï¼‰"""
        # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåé›†
        artists = defaultdict(list)
        genres = defaultdict(list)
        themes = defaultdict(list)
        
        for node_id, node in self.knowledge_nodes.items():
            if node.node_type == "video":
                attrs = node.attributes
                
                # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ
                artist = attrs.get("artist", "")
                if artist:
                    artists[artist].append(node_id)
                
                # ã‚¸ãƒ£ãƒ³ãƒ«
                for genre in attrs.get("genres", []):
                    if genre.strip():
                        genres[genre.strip()].append(node_id)
                
                # ãƒ†ãƒ¼ãƒ
                for theme in attrs.get("themes", []):
                    if theme.strip():
                        themes[theme.strip()].append(node_id)
        
        # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆãƒãƒ¼ãƒ‰ä½œæˆ
        for artist, video_nodes in artists.items():
            if len(video_nodes) >= 1:  # æœ€ä½1ã¤ã®å‹•ç”»ã‚’æŒã¤ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ
                node = KnowledgeNode(
                    node_id=f"artist_{hashlib.md5(artist.encode()).hexdigest()[:8]}",
                    node_type="artist",
                    title=artist,
                    attributes={
                        "video_count": len(video_nodes),
                        "associated_videos": video_nodes
                    },
                    relevance_score=min(1.0, len(video_nodes) * 0.2),
                    created_at=datetime.now().isoformat(),
                    updated_at=datetime.now().isoformat()
                )
                self.knowledge_nodes[node.node_id] = node
                self.graph.add_node(node.node_id, **asdict(node))
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ãƒãƒ¼ãƒ‰ä½œæˆ
        for genre, video_nodes in genres.items():
            if len(video_nodes) >= 2:  # æœ€ä½2ã¤ã®å‹•ç”»ã‚’æŒã¤ã‚¸ãƒ£ãƒ³ãƒ«
                node = KnowledgeNode(
                    node_id=f"genre_{hashlib.md5(genre.encode()).hexdigest()[:8]}",
                    node_type="genre",
                    title=genre,
                    attributes={
                        "video_count": len(video_nodes),
                        "associated_videos": video_nodes
                    },
                    relevance_score=min(1.0, len(video_nodes) * 0.15),
                    created_at=datetime.now().isoformat(),
                    updated_at=datetime.now().isoformat()
                )
                self.knowledge_nodes[node.node_id] = node
                self.graph.add_node(node.node_id, **asdict(node))
        
        # ãƒ†ãƒ¼ãƒãƒãƒ¼ãƒ‰ä½œæˆ
        for theme, video_nodes in themes.items():
            if len(video_nodes) >= 2:  # æœ€ä½2ã¤ã®å‹•ç”»ã‚’æŒã¤ãƒ†ãƒ¼ãƒ
                node = KnowledgeNode(
                    node_id=f"theme_{hashlib.md5(theme.encode()).hexdigest()[:8]}",
                    node_type="theme",
                    title=theme,
                    attributes={
                        "video_count": len(video_nodes),
                        "associated_videos": video_nodes
                    },
                    relevance_score=min(1.0, len(video_nodes) * 0.1),
                    created_at=datetime.now().isoformat(),
                    updated_at=datetime.now().isoformat()
                )
                self.knowledge_nodes[node.node_id] = node
                self.graph.add_node(node.node_id, **asdict(node))
    
    def _create_conversation_nodes(self):
        """ä¼šè©±ãƒãƒ¼ãƒ‰ä½œæˆ"""
        conversations = self.conversation_history.get("conversations", {})
        
        for conv_id, conv_data in conversations.items():
            if not conv_data.get("video_ids"):
                continue
            
            node = KnowledgeNode(
                node_id=f"conversation_{conv_id}",
                node_type="conversation",
                title=f"ä¼šè©±_{conv_id}",
                attributes={
                    "video_ids": conv_data.get("video_ids", []),
                    "context": conv_data.get("context", ""),
                    "user_preferences": conv_data.get("user_preferences", {}),
                    "timestamp": conv_data.get("timestamp", "")
                },
                relevance_score=0.3,  # ä¼šè©±ã®åŸºæœ¬é‡è¦åº¦
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat()
            )
            
            self.knowledge_nodes[node.node_id] = node
            self.graph.add_node(node.node_id, **asdict(node))
    
    def _build_relationships(self):
        """é–¢é€£æ€§ã‚¨ãƒƒã‚¸æ§‹ç¯‰"""
        print("[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ”— é–¢é€£æ€§ã‚¨ãƒƒã‚¸ã‚’æ§‹ç¯‰ä¸­...")
        
        # å‹•ç”»é–“ã®é–¢é€£æ€§
        self._build_video_relationships()
        
        # å‹•ç”»-æ¦‚å¿µé–“ã®é–¢é€£æ€§
        self._build_video_concept_relationships()
        
        # ä¼šè©±-å‹•ç”»é–“ã®é–¢é€£æ€§
        self._build_conversation_relationships()
        
        # æ¦‚å¿µé–“ã®é–¢é€£æ€§
        self._build_concept_relationships()
    
    def _build_video_relationships(self):
        """å‹•ç”»é–“é–¢é€£æ€§æ§‹ç¯‰"""
        video_nodes = [n for n in self.knowledge_nodes.values() if n.node_type == "video"]
        
        for i, video1 in enumerate(video_nodes):
            for video2 in video_nodes[i+1:]:
                similarity = self._calculate_video_similarity(video1, video2)
                
                if similarity > 0.3:  # é–¾å€¤
                    relationship_type = self._determine_video_relationship_type(video1, video2)
                    evidence = self._get_similarity_evidence(video1, video2)
                    
                    edge = KnowledgeEdge(
                        edge_id=f"edge_{video1.node_id}_{video2.node_id}",
                        source_id=video1.node_id,
                        target_id=video2.node_id,
                        relationship_type=relationship_type,
                        strength=similarity,
                        evidence=evidence,
                        created_at=datetime.now().isoformat()
                    )
                    
                    self.knowledge_edges[edge.edge_id] = edge
                    self.graph.add_edge(
                        edge.source_id, 
                        edge.target_id, 
                        weight=edge.strength,
                        relationship_type=edge.relationship_type,
                        edge_data=edge
                    )
    
    def _build_video_concept_relationships(self):
        """å‹•ç”»-æ¦‚å¿µé–“é–¢é€£æ€§æ§‹ç¯‰"""
        video_nodes = [n for n in self.knowledge_nodes.values() if n.node_type == "video"]
        concept_nodes = [n for n in self.knowledge_nodes.values() if n.node_type in ["artist", "genre", "theme"]]
        
        for video in video_nodes:
            for concept in concept_nodes:
                strength = self._calculate_video_concept_strength(video, concept)
                
                if strength > 0.5:  # é–¾å€¤
                    relationship_type = f"belongs_to_{concept.node_type}"
                    
                    edge = KnowledgeEdge(
                        edge_id=f"edge_{video.node_id}_{concept.node_id}",
                        source_id=video.node_id,
                        target_id=concept.node_id,
                        relationship_type=relationship_type,
                        strength=strength,
                        evidence=[f"å‹•ç”»ãŒ{concept.node_type}: {concept.title}ã«å±ã™ã‚‹"],
                        created_at=datetime.now().isoformat()
                    )
                    
                    self.knowledge_edges[edge.edge_id] = edge
                    self.graph.add_edge(
                        edge.source_id, 
                        edge.target_id, 
                        weight=edge.strength,
                        relationship_type=edge.relationship_type,
                        edge_data=edge
                    )
    
    def _build_conversation_relationships(self):
        """ä¼šè©±-å‹•ç”»é–“é–¢é€£æ€§æ§‹ç¯‰"""
        conversation_nodes = [n for n in self.knowledge_nodes.values() if n.node_type == "conversation"]
        
        for conv in conversation_nodes:
            video_ids = conv.attributes.get("video_ids", [])
            
            for video_id in video_ids:
                video_node_id = f"video_{video_id}"
                if video_node_id in self.knowledge_nodes:
                    edge = KnowledgeEdge(
                        edge_id=f"edge_{conv.node_id}_{video_node_id}",
                        source_id=conv.node_id,
                        target_id=video_node_id,
                        relationship_type="discussed_in_conversation",
                        strength=0.8,
                        evidence=["ä¼šè©±ã§è¨€åŠã•ã‚ŒãŸå‹•ç”»"],
                        created_at=datetime.now().isoformat()
                    )
                    
                    self.knowledge_edges[edge.edge_id] = edge
                    self.graph.add_edge(
                        edge.source_id, 
                        edge.target_id, 
                        weight=edge.strength,
                        relationship_type=edge.relationship_type,
                        edge_data=edge
                    )
    
    def _build_concept_relationships(self):
        """æ¦‚å¿µé–“é–¢é€£æ€§æ§‹ç¯‰"""
        concept_nodes = [n for n in self.knowledge_nodes.values() if n.node_type in ["artist", "genre", "theme"]]
        
        for i, concept1 in enumerate(concept_nodes):
            for concept2 in concept_nodes[i+1:]:
                strength = self._calculate_concept_similarity(concept1, concept2)
                
                if strength > 0.4:  # é–¾å€¤
                    relationship_type = "conceptual_similarity"
                    
                    edge = KnowledgeEdge(
                        edge_id=f"edge_{concept1.node_id}_{concept2.node_id}",
                        source_id=concept1.node_id,
                        target_id=concept2.node_id,
                        relationship_type=relationship_type,
                        strength=strength,
                        evidence=[f"{concept1.node_type}ã¨{concept2.node_type}ã®æ¦‚å¿µçš„é¡ä¼¼æ€§"],
                        created_at=datetime.now().isoformat()
                    )
                    
                    self.knowledge_edges[edge.edge_id] = edge
                    self.graph.add_edge(
                        edge.source_id, 
                        edge.target_id, 
                        weight=edge.strength,
                        relationship_type=edge.relationship_type,
                        edge_data=edge
                    )
    
    def _calculate_video_relevance(self, metadata: Dict) -> float:
        """å‹•ç”»é–¢é€£åº¦è¨ˆç®—"""
        view_count = metadata.get("view_count", 0)
        like_count = metadata.get("like_count", 0)
        
        # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢
        view_score = min(1.0, view_count / 100000)  # 10ä¸‡å†ç”Ÿã§1.0
        like_score = min(1.0, like_count / 1000)    # 1000ã„ã„ã­ã§1.0
        
        return (view_score * 0.7 + like_score * 0.3)
    
    def _calculate_video_similarity(self, video1: KnowledgeNode, video2: KnowledgeNode) -> float:
        """å‹•ç”»é–“é¡ä¼¼åº¦è¨ˆç®—"""
        attrs1 = video1.attributes
        attrs2 = video2.attributes
        
        total_score = 0.0
        weights_sum = 0.0
        
        # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆä¸€è‡´
        if attrs1.get("artist") == attrs2.get("artist") and attrs1.get("artist"):
            total_score += self.relationship_weights["same_artist"]
            weights_sum += self.relationship_weights["same_artist"]
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ä¸€è‡´
        genres1 = set(attrs1.get("genres", []))
        genres2 = set(attrs2.get("genres", []))
        if genres1 and genres2:
            genre_overlap = len(genres1.intersection(genres2)) / len(genres1.union(genres2))
            total_score += genre_overlap * self.relationship_weights["same_genre"]
            weights_sum += self.relationship_weights["same_genre"]
        
        # ãƒ†ãƒ¼ãƒä¸€è‡´
        themes1 = set(attrs1.get("themes", []))
        themes2 = set(attrs2.get("themes", []))
        if themes1 and themes2:
            theme_overlap = len(themes1.intersection(themes2)) / len(themes1.union(themes2))
            total_score += theme_overlap * self.relationship_weights["same_theme"]
            weights_sum += self.relationship_weights["same_theme"]
        
        # ãƒ ãƒ¼ãƒ‰é¡ä¼¼æ€§
        mood1 = attrs1.get("mood", "")
        mood2 = attrs2.get("mood", "")
        if mood1 and mood2:
            mood_similarity = 1.0 if mood1 == mood2 else 0.3
            total_score += mood_similarity * self.relationship_weights["similar_mood"]
            weights_sum += self.relationship_weights["similar_mood"]
        
        return total_score / weights_sum if weights_sum > 0 else 0.0
    
    def _determine_video_relationship_type(self, video1: KnowledgeNode, video2: KnowledgeNode) -> str:
        """å‹•ç”»é–¢ä¿‚ã‚¿ã‚¤ãƒ—åˆ¤å®š"""
        attrs1 = video1.attributes
        attrs2 = video2.attributes
        
        if attrs1.get("artist") == attrs2.get("artist"):
            return "same_artist"
        
        genres1 = set(attrs1.get("genres", []))
        genres2 = set(attrs2.get("genres", []))
        if genres1.intersection(genres2):
            return "same_genre"
        
        themes1 = set(attrs1.get("themes", []))
        themes2 = set(attrs2.get("themes", []))
        if themes1.intersection(themes2):
            return "same_theme"
        
        return "similarity"
    
    def _get_similarity_evidence(self, video1: KnowledgeNode, video2: KnowledgeNode) -> List[str]:
        """é¡ä¼¼æ€§æ ¹æ‹ å–å¾—"""
        evidence = []
        attrs1 = video1.attributes
        attrs2 = video2.attributes
        
        if attrs1.get("artist") == attrs2.get("artist"):
            evidence.append(f"åŒã˜ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ: {attrs1.get('artist')}")
        
        common_genres = set(attrs1.get("genres", [])).intersection(set(attrs2.get("genres", [])))
        if common_genres:
            evidence.append(f"å…±é€šã‚¸ãƒ£ãƒ³ãƒ«: {', '.join(common_genres)}")
        
        common_themes = set(attrs1.get("themes", [])).intersection(set(attrs2.get("themes", [])))
        if common_themes:
            evidence.append(f"å…±é€šãƒ†ãƒ¼ãƒ: {', '.join(common_themes)}")
        
        return evidence
    
    def _calculate_video_concept_strength(self, video: KnowledgeNode, concept: KnowledgeNode) -> float:
        """å‹•ç”»-æ¦‚å¿µé–“å¼·åº¦è¨ˆç®—"""
        video_attrs = video.attributes
        
        if concept.node_type == "artist":
            return 1.0 if video_attrs.get("artist") == concept.title else 0.0
        elif concept.node_type == "genre":
            return 1.0 if concept.title in video_attrs.get("genres", []) else 0.0
        elif concept.node_type == "theme":
            return 1.0 if concept.title in video_attrs.get("themes", []) else 0.0
        
        return 0.0
    
    def _calculate_concept_similarity(self, concept1: KnowledgeNode, concept2: KnowledgeNode) -> float:
        """æ¦‚å¿µé–“é¡ä¼¼åº¦è¨ˆç®—"""
        # é–¢é€£å‹•ç”»ã®é‡è¤‡åº¦
        videos1 = set(concept1.attributes.get("associated_videos", []))
        videos2 = set(concept2.attributes.get("associated_videos", []))
        
        if videos1 and videos2:
            overlap = len(videos1.intersection(videos2))
            union = len(videos1.union(videos2))
            return overlap / union
        
        return 0.0
    
    def _perform_clustering(self):
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ"""
        print("[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ¯ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
        
        if len(self.graph.nodes) < 3:
            return
        
        try:
            # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º
            communities = nx.algorithms.community.greedy_modularity_communities(self.graph)
            
            for i, community in enumerate(communities):
                if len(community) >= 3:  # æœ€å°ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚º
                    cluster_id = f"cluster_{i}"
                    
                    # ä¸­å¿ƒæ¦‚å¿µæŠ½å‡º
                    central_concepts = self._extract_central_concepts(community)
                    
                    # çµæŸåº¦è¨ˆç®—
                    cohesion_score = self._calculate_cluster_cohesion(community)
                    
                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¤å®š
                    cluster_type = self._determine_cluster_type(community)
                    
                    cluster = GraphCluster(
                        cluster_id=cluster_id,
                        cluster_type=cluster_type,
                        node_ids=list(community),
                        central_concepts=central_concepts,
                        cohesion_score=cohesion_score,
                        description=f"{cluster_type}ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼ˆ{len(community)}ãƒãƒ¼ãƒ‰ï¼‰"
                    )
                    
                    self.clusters[cluster_id] = cluster
            
            print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ¯ {len(self.clusters)}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ç”Ÿæˆ")
            
        except Exception as e:
            print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] âš ï¸ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _extract_central_concepts(self, community: Set[str]) -> List[str]:
        """ä¸­å¿ƒæ¦‚å¿µæŠ½å‡º"""
        concepts = []
        
        for node_id in community:
            if node_id in self.knowledge_nodes:
                node = self.knowledge_nodes[node_id]
                if node.node_type in ["artist", "genre", "theme"]:
                    concepts.append(node.title)
        
        return concepts[:3]  # ä¸Šä½3ã¤
    
    def _calculate_cluster_cohesion(self, community: Set[str]) -> float:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çµæŸåº¦è¨ˆç®—"""
        if len(community) < 2:
            return 0.0
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã‚¨ãƒƒã‚¸æ•°
        internal_edges = 0
        total_possible_edges = len(community) * (len(community) - 1) / 2
        
        for node1 in community:
            for node2 in community:
                if node1 != node2 and self.graph.has_edge(node1, node2):
                    internal_edges += 1
        
        return internal_edges / total_possible_edges if total_possible_edges > 0 else 0.0
    
    def _determine_cluster_type(self, community: Set[str]) -> str:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¤å®š"""
        node_types = []
        
        for node_id in community:
            if node_id in self.knowledge_nodes:
                node_types.append(self.knowledge_nodes[node_id].node_type)
        
        type_counts = Counter(node_types)
        most_common = type_counts.most_common(1)
        
        if most_common:
            dominant_type = most_common[0][0]
            if dominant_type == "video":
                return "video_cluster"
            elif dominant_type == "artist":
                return "artist_cluster"
            elif dominant_type == "genre":
                return "genre_cluster"
            elif dominant_type == "theme":
                return "theme_cluster"
        
        return "mixed_cluster"
    
    def _save_graph_data(self):
        """ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        try:
            graph_data = {
                "nodes": {nid: asdict(node) for nid, node in self.knowledge_nodes.items()},
                "edges": {eid: asdict(edge) for eid, edge in self.knowledge_edges.items()},
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "node_count": len(self.knowledge_nodes),
                    "edge_count": len(self.knowledge_edges)
                }
            }
            
            with open(self.graph_data_path, 'w', encoding='utf-8') as f:
                json.dump(graph_data, f, ensure_ascii=False, indent=2)
            
            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            cluster_data = {
                "clusters": {cid: asdict(cluster) for cid, cluster in self.clusters.items()},
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "cluster_count": len(self.clusters)
                }
            }
            
            with open(self.clusters_path, 'w', encoding='utf-8') as f:
                json.dump(cluster_data, f, ensure_ascii=False, indent=2)
            
            print("[çŸ¥è­˜ã‚°ãƒ©ãƒ•] ğŸ’¾ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            print(f"[çŸ¥è­˜ã‚°ãƒ©ãƒ•] âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_statistics(self):
        """çµ±è¨ˆæƒ…å ±æ›´æ–°"""
        self.graph_statistics.update({
            "total_nodes": len(self.knowledge_nodes),
            "total_edges": len(self.knowledge_edges),
            "clusters_count": len(self.clusters),
            "last_rebuild": datetime.now().isoformat(),
            "coverage_rate": self._calculate_coverage_rate()
        })
    
    def _calculate_coverage_rate(self) -> float:
        """ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡è¨ˆç®—"""
        total_videos = len(self.knowledge_db.get("videos", {}))
        video_nodes = len([n for n in self.knowledge_nodes.values() if n.node_type == "video"])
        
        return video_nodes / total_videos if total_videos > 0 else 0.0
    
    def find_related_content(self, video_id: str, max_results: int = 10) -> List[Dict[str, Any]]:
        """é–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œç´¢"""
        node_id = f"video_{video_id}"
        
        if node_id not in self.graph.nodes:
            return []
        
        # ç›´æ¥æ¥ç¶šã•ã‚ŒãŸãƒãƒ¼ãƒ‰
        neighbors = list(self.graph.neighbors(node_id))
        
        # é–¢é€£åº¦ã§ã‚½ãƒ¼ãƒˆ
        related_items = []
        
        for neighbor_id in neighbors:
            if neighbor_id in self.knowledge_nodes:
                neighbor = self.knowledge_nodes[neighbor_id]
                edge_data = self.graph.get_edge_data(node_id, neighbor_id)
                
                related_items.append({
                    "node_id": neighbor_id,
                    "title": neighbor.title,
                    "type": neighbor.node_type,
                    "relevance": edge_data.get("weight", 0.0),
                    "relationship": edge_data.get("relationship_type", ""),
                    "evidence": edge_data.get("edge_data", {}).get("evidence", [])
                })
        
        # é–¢é€£åº¦ã§ã‚½ãƒ¼ãƒˆ
        related_items.sort(key=lambda x: x["relevance"], reverse=True)
        
        return related_items[:max_results]
    
    def get_cluster_recommendations(self, video_id: str) -> List[Dict[str, Any]]:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åŸºæº–æ¨è–¦"""
        node_id = f"video_{video_id}"
        recommendations = []
        
        # ãƒãƒ¼ãƒ‰ãŒå±ã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’è¦‹ã¤ã‘ã‚‹
        for cluster in self.clusters.values():
            if node_id in cluster.node_ids:
                # åŒã˜ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã®ä»–ã®å‹•ç”»ã‚’æ¨è–¦
                for other_node_id in cluster.node_ids:
                    if other_node_id != node_id and other_node_id in self.knowledge_nodes:
                        other_node = self.knowledge_nodes[other_node_id]
                        if other_node.node_type == "video":
                            recommendations.append({
                                "node_id": other_node_id,
                                "title": other_node.title,
                                "cluster_type": cluster.cluster_type,
                                "cohesion_score": cluster.cohesion_score,
                                "central_concepts": cluster.central_concepts
                            })
                break
        
        return recommendations
    
    def get_graph_statistics(self) -> Dict[str, Any]:
        """ã‚°ãƒ©ãƒ•çµ±è¨ˆæƒ…å ±å–å¾—"""
        return dict(self.graph_statistics)
    
    def analyze_knowledge_patterns(self) -> Dict[str, Any]:
        """çŸ¥è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        patterns = {
            "popular_artists": [],
            "dominant_genres": [],
            "common_themes": [],
            "cluster_analysis": {},
            "connectivity_analysis": {}
        }
        
        # äººæ°—ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ
        artist_nodes = [n for n in self.knowledge_nodes.values() if n.node_type == "artist"]
        artist_nodes.sort(key=lambda x: x.attributes.get("video_count", 0), reverse=True)
        patterns["popular_artists"] = [
            {"name": n.title, "video_count": n.attributes.get("video_count", 0)}
            for n in artist_nodes[:10]
        ]
        
        # æ”¯é…çš„ã‚¸ãƒ£ãƒ³ãƒ«
        genre_nodes = [n for n in self.knowledge_nodes.values() if n.node_type == "genre"]
        genre_nodes.sort(key=lambda x: x.attributes.get("video_count", 0), reverse=True)
        patterns["dominant_genres"] = [
            {"name": n.title, "video_count": n.attributes.get("video_count", 0)}
            for n in genre_nodes[:10]
        ]
        
        # ä¸€èˆ¬çš„ãƒ†ãƒ¼ãƒ
        theme_nodes = [n for n in self.knowledge_nodes.values() if n.node_type == "theme"]
        theme_nodes.sort(key=lambda x: x.attributes.get("video_count", 0), reverse=True)
        patterns["common_themes"] = [
            {"name": n.title, "video_count": n.attributes.get("video_count", 0)}
            for n in theme_nodes[:10]
        ]
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ
        patterns["cluster_analysis"] = {
            "total_clusters": len(self.clusters),
            "cluster_types": Counter([c.cluster_type for c in self.clusters.values()]),
            "average_cohesion": sum(c.cohesion_score for c in self.clusters.values()) / len(self.clusters) if self.clusters else 0
        }
        
        # æ¥ç¶šæ€§åˆ†æ
        if self.graph.number_of_nodes() > 0:
            patterns["connectivity_analysis"] = {
                "density": nx.density(self.graph),
                "average_clustering": nx.average_clustering(self.graph),
                "number_of_components": nx.number_connected_components(self.graph)
            }
        
        return patterns