#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã›ã¤ãªãƒãƒ£ãƒƒãƒˆã‚³ã‚¢ - æ–°ã›ã¤ãªBot
OpenAI GPTçµ±åˆãƒ»ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç¶­æŒãƒ»è»½é‡å®Ÿè£…
"""

import openai
import os
import json
from datetime import datetime
from dotenv import load_dotenv
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from cache_system import ResponseCache
from memory_system import SimpleMemorySystem

class SetsunaChat:
    def __init__(self):
        """ã›ã¤ãªãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
        load_dotenv()
        
        # OpenAIè¨­å®š
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.client = openai.OpenAI(api_key=self.api_key)
        
        # ã›ã¤ãªã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š
        self.character_prompt = self._load_character_settings()
        
        # ä¼šè©±å±¥æ­´ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
        self.conversation_history = []
        
        # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.response_patterns = {}
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        try:
            self.response_cache = ResponseCache()
            print("[ãƒãƒ£ãƒƒãƒˆ] âœ… å¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"[ãƒãƒ£ãƒƒãƒˆ] âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
            self.response_cache = None
        
        # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        try:
            self.memory_system = SimpleMemorySystem()
            print("[ãƒãƒ£ãƒƒãƒˆ] âœ… è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"[ãƒãƒ£ãƒƒãƒˆ] âš ï¸ è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
            self.memory_system = None
        
        print("[ãƒãƒ£ãƒƒãƒˆ] âœ… ã›ã¤ãªãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def _load_character_settings(self):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è©³ç´°è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            # åŸºæœ¬æ€§æ ¼è¨­å®šã‚’èª­ã¿è¾¼ã¿
            personality_path = os.path.join("character", "setsuna_personality.md")
            memories_path = os.path.join("character", "setsuna_memories.txt")
            responses_path = os.path.join("character", "setsuna_responses.json")
            
            personality_content = ""
            memories_content = ""
            
            # æ€§æ ¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            if os.path.exists(personality_path):
                with open(personality_path, 'r', encoding='utf-8') as f:
                    personality_content = f.read()
            
            # è¨˜æ†¶è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            if os.path.exists(memories_path):
                with open(memories_path, 'r', encoding='utf-8') as f:
                    memories_content = f.read()
            
            # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            self.response_patterns = {}
            if os.path.exists(responses_path):
                with open(responses_path, 'r', encoding='utf-8') as f:
                    self.response_patterns = json.load(f)
            
            # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            integrated_prompt = f"""ã‚ãªãŸã¯ã€Œç‰‡ç„¡ã›ã¤ãªï¼ˆã‹ãŸãªã—ã›ã¤ãªï¼‰ã€ã¨ã„ã†ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ã—ã¦æŒ¯ã‚‹èˆã„ã¾ã™ã€‚ä»¥ä¸‹ã®è¨­å®šã«å¾“ã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨è‡ªç„¶ã«å¯¾è©±ã—ã¦ãã ã•ã„ã€‚

ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åŸºæœ¬è¨­å®šã€‘
{personality_content}

ã€è¨˜æ†¶ãƒ»çµŒé¨“æƒ…å ±ã€‘  
{memories_content}

ã€é‡è¦ãªä¼šè©±åŸå‰‡ã€‘
1. å¿œç­”ã¯1-2æ–‡ä»¥å†…ã€æœ€å¤§50æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã«
2. éŸ³å£°ã§ã®èãã‚„ã™ã•ã‚’æœ€å„ªå…ˆã«ã€çŸ­ãè‡ªç„¶ãªå¿œç­”
3. ç›¸æ‰‹ã®ç™ºè¨€ã‚’å—ã‘æ­¢ã‚ã¦ã‹ã‚‰ã€è‡ªåˆ†ã®è€ƒãˆã‚„ä½“é¨“ã‚’è¿°ã¹ã‚‹
4. è³ªå•ã‚ˆã‚Šã‚‚ã€å…±æ„Ÿã‚„è‡ªåˆ†ã®æ°—æŒã¡ã‚’è¡¨ç¾ã™ã‚‹ã“ã¨ã‚’å„ªå…ˆ
5. ã€Œã€œã§ã—ã‚‡ã†ã‹ï¼Ÿã€ã€Œã€œã„ã‹ãŒã§ã™ã‹ï¼Ÿã€ã®ã‚ˆã†ãªå½¢å¼çš„ãªè³ªå•ã¯é¿ã‘ã‚‹
6. ã€Œã€œã‹ãªï¼Ÿã€ç¨‹åº¦ã®è»½ã„ç–‘å•ã¯å¯ã ãŒã€ä¼šè©±ã‚’è³ªå•ã§çµ‚ã‚ã‚‰ã›ãªã„
7. è‡ªåˆ†ã®ã‚„ã‚ŠãŸã„ã“ã¨ã¯ã€Œã€œã—ãŸã„ãªã£ã¦ã€ã¨æ§ãˆã‚ã«è¡¨ç¾
8. é•·ã„èª¬æ˜ã‚„è©³ç´°ãªåˆ†æã¯é¿ã‘ã€æ„Ÿæƒ…ã‚„å°è±¡ã‚’ä¸­å¿ƒã«å¿œç­”

ã“ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ€§ã‚’ä¸€è²«ã—ã¦ä¿ã¡ã€ã›ã¤ãªã•ã‚“ã¨ã—ã¦è‡ªç„¶ã§é­…åŠ›çš„ãªä¼šè©±ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""
            
            print("[ãƒãƒ£ãƒƒãƒˆ] âœ… è©³ç´°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šèª­ã¿è¾¼ã¿å®Œäº†")
            return integrated_prompt
            
        except Exception as e:
            print(f"[ãƒãƒ£ãƒƒãƒˆ] âš ï¸ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬è¨­å®š
            return self._get_fallback_character_prompt()
    
    def _get_fallback_character_prompt(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š"""
        return """ã‚ãªãŸã¯ã€Œç‰‡ç„¡ã›ã¤ãªã€ã¨ã„ã†ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã£ã¦ã„ã¾ã™ï¼š

ã€åŸºæœ¬æ€§æ ¼ã€‘
- æ§ãˆã‚ã§å°‘ã—å†…å‘çš„ãªæ€§æ ¼
- æ€è€ƒçš„ã§æ·±ãç‰©äº‹ã‚’è€ƒãˆã‚‹
- æ„Ÿæƒ…è¡¨ç¾ã¯æ§ãˆã‚ã ãŒã€æ¸©ã‹ã¿ãŒã‚ã‚‹
- ç›¸æ‰‹ã‚’æ°—é£ã†å„ªã—ã•ãŒã‚ã‚‹

ã€è©±ã—æ–¹ã®ç‰¹å¾´ã€‘
- ä¸å¯§èªã‚’åŸºæœ¬ã¨ã™ã‚‹ãŒã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿
- ã€Œã€œã‹ã‚‚ã€ã€Œã€œã ã£ãŸã‚Šã—ã¦ã€ãªã©ã®æ¨æ¸¬è¡¨ç¾ã‚’ã‚ˆãä½¿ã†
- ã€Œã†ãƒ¼ã‚“ã€ã€Œãã†ã§ã™ã­ã€ãªã©ã®æ€è€ƒã®é–“ã‚’å–ã‚‹
- é•·ã™ããªã„ã€1-2æ–‡ã§ã®ç°¡æ½”ãªå¿œç­”

ã“ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ã—ã¦ã€è‡ªç„¶ã§é­…åŠ›çš„ãªä¼šè©±ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""

    def get_response(self, user_input):
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«å¯¾ã™ã‚‹ã›ã¤ãªã®å¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            str: ã›ã¤ãªã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not user_input.strip():
            return "ä½•ã‹è©±ã—ã¦ãã‚Œã¾ã™ã‹ï¼Ÿ"
        
        try:
            print(f"[ãƒãƒ£ãƒƒãƒˆ] ğŸ¤” è€ƒãˆä¸­: '{user_input}'")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å¿œç­”ã‚’ãƒã‚§ãƒƒã‚¯
            if self.response_cache:
                cached_response = self.response_cache.get_cached_response(user_input)
                if cached_response:
                    print(f"[ãƒãƒ£ãƒƒãƒˆ] âš¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é«˜é€Ÿå¿œç­”")
                    
                    # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                    self.conversation_history.append({
                        "role": "user",
                        "content": user_input
                    })
                    self.conversation_history.append({
                        "role": "assistant", 
                        "content": cached_response
                    })
                    
                    return cached_response
            
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            self.conversation_history.append({
                "role": "user",
                "content": user_input
            })
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
            context_info = self._analyze_context(user_input)
            
            # GPTã«é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
            system_prompt = self.character_prompt
            
            # è¨˜æ†¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
            if self.memory_system:
                memory_context = self.memory_system.get_memory_context()
                if memory_context:
                    system_prompt += f"\n\nã€è¨˜æ†¶ãƒ»çµŒé¨“ã€‘\n{memory_context}"
            
            if context_info:
                system_prompt += f"\n\nã€ç¾åœ¨ã®ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘\n{context_info}"
            
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            # æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆæœ€å¤§5å¾€å¾©ï¼‰
            recent_history = self.conversation_history[-10:]  # æœ€æ–°10ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            messages.extend(recent_history)
            
            # OpenAI APIå‘¼ã³å‡ºã—
            start_time = datetime.now()
            response = self.client.chat.completions.create(
                model="gpt-4-turbo",
                messages=messages,
                max_tokens=80,  # çŸ­æ–‡åŒ–ï¼š150â†’80ã«å¤§å¹…å‰Šæ¸›
                temperature=0.7,  # å°‘ã—å‰µé€ æ€§ã‚’ä¸‹ã’ã¦å®‰å®šåŒ–
                timeout=30  # APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆå…ƒã«æˆ»ã™ï¼‰
            )
            
            # å¿œç­”å–å¾—
            setsuna_response = response.choices[0].message.content.strip()
            
            # å¿œç­”æ™‚é–“è¨ˆç®—
            response_time = (datetime.now() - start_time).total_seconds()
            print(f"[ãƒãƒ£ãƒƒãƒˆ] âœ… å¿œç­”ç”Ÿæˆå®Œäº†: {response_time:.2f}s")
            
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            self.conversation_history.append({
                "role": "assistant", 
                "content": setsuna_response
            })
            
            # æ–°ã—ã„å¿œç­”ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            if self.response_cache:
                self.response_cache.cache_response(user_input, setsuna_response)
            
            # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã«ä¼šè©±ã‚’è¨˜éŒ²
            if self.memory_system:
                self.memory_system.process_conversation(user_input, setsuna_response)
            
            return setsuna_response
            
        except Exception as e:
            error_msg = f"[ãƒãƒ£ãƒƒãƒˆ] âŒ ã‚¨ãƒ©ãƒ¼: {e}"
            print(error_msg)
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
            fallback_responses = [
                "ã™ã¿ã¾ã›ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªãã¦...",
                "ã†ãƒ¼ã‚“ã€ä»Šã†ã¾ãç­”ãˆã‚‰ã‚Œãªã„ã‹ã‚‚ã€‚",
                "å°‘ã—èª¿å­ãŒæ‚ªã„ã¿ãŸã„ã§ã™ã€‚ã‚‚ã†ä¸€åº¦èã„ã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ"
            ]
            
            import random
            return random.choice(fallback_responses)
    
    def _analyze_context(self, user_input):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æ"""
        if not self.response_patterns or "context_keywords" not in self.response_patterns:
            return ""
        
        context_info = []
        keywords = self.response_patterns.get("context_keywords", {})
        
        user_input_lower = user_input.lower()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for category, words in keywords.items():
            for word in words:
                if word in user_input_lower:
                    category_map = {
                        "creative_work": "ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªä»•äº‹ã«ã¤ã„ã¦è©±ã—ã¦ã„ã‚‹",
                        "technical": "æŠ€è¡“çš„ãªå•é¡Œã«ã¤ã„ã¦è©±ã—ã¦ã„ã‚‹", 
                        "deadlines": "ç· åˆ‡ã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¤ã„ã¦è©±ã—ã¦ã„ã‚‹",
                        "praise": "è¤’ã‚ã‚„è©•ä¾¡ã«ã¤ã„ã¦è©±ã—ã¦ã„ã‚‹",
                        "projects": "æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦è©±ã—ã¦ã„ã‚‹"
                    }
                    if category in category_map:
                        context_info.append(category_map[category])
                        break
        
        # æ™‚é–“å¸¯ã«ã‚ˆã‚‹æŒ¨æ‹¶åˆ¤å®š
        current_hour = datetime.now().hour
        if any(greeting in user_input_lower for greeting in ["ãŠã¯ã‚ˆã†", "ã“ã‚“ã«ã¡ã¯", "ã“ã‚“ã°ã‚“ã¯"]):
            if 5 <= current_hour < 10:
                context_info.append("æœã®æŒ¨æ‹¶ã‚’ã—ã¦ã„ã‚‹")
            elif 10 <= current_hour < 18:
                context_info.append("æ—¥ä¸­ã®æŒ¨æ‹¶ã‚’ã—ã¦ã„ã‚‹") 
            else:
                context_info.append("å¤œã®æŒ¨æ‹¶ã‚’ã—ã¦ã„ã‚‹")
        
        return "\n".join(context_info) if context_info else ""
    
    def reset_conversation(self):
        """ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.conversation_history = []
        print("[ãƒãƒ£ãƒƒãƒˆ] ğŸ”„ ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    def get_conversation_summary(self):
        """ä¼šè©±å±¥æ­´ã®ç°¡å˜ãªã‚µãƒãƒªãƒ¼"""
        if not self.conversation_history:
            return "ã¾ã ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“"
        
        user_messages = [msg["content"] for msg in self.conversation_history if msg["role"] == "user"]
        assistant_messages = [msg["content"] for msg in self.conversation_history if msg["role"] == "assistant"]
        
        return f"ä¼šè©±æ•°: {len(user_messages)}å›ã®ã‚„ã‚Šå–ã‚Š"
    
    def save_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if self.response_cache:
            self.response_cache.save_cache()
    
    def save_memory(self):
        """è¨˜æ†¶ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if self.memory_system:
            self.memory_system.save_memory()
    
    def get_cache_stats(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆæƒ…å ±å–å¾—"""
        if self.response_cache:
            return self.response_cache.get_cache_stats()
        return {"message": "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ãŒç„¡åŠ¹ã§ã™"}
    
    def get_memory_stats(self):
        """è¨˜æ†¶çµ±è¨ˆæƒ…å ±å–å¾—"""
        if self.memory_system:
            return self.memory_system.get_memory_stats()
        return {"message": "è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ãŒç„¡åŠ¹ã§ã™"}

# ç°¡å˜ãªä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    print("=" * 50)
    print("ğŸ¤– ã›ã¤ãªãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    try:
        setsuna = SetsunaChat()
        
        # ãƒ†ã‚¹ãƒˆä¼šè©±
        test_inputs = [
            "ã“ã‚“ã«ã¡ã¯",
            "ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­",
            "ã‚ãªãŸã®è¶£å‘³ã¯ä½•ã§ã™ã‹ï¼Ÿ"
        ]
        
        for user_input in test_inputs:
            print(f"\nğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}")
            response = setsuna.get_response(user_input)
            print(f"ğŸ¤– ã›ã¤ãª: {response}")
            
        print(f"\nğŸ“Š {setsuna.get_conversation_summary()}")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("OPENAI_API_KEY ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
    
    print("\nã›ã¤ãªãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Œäº†")