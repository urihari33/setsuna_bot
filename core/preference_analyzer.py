#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æã«ã‚ˆã‚‹å¥½ã¿æ¨æ¸¬ã‚·ã‚¹ãƒ†ãƒ 
YouTubeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ä¼šè©±å±¥æ­´ã‹ã‚‰ã›ã¤ãªã®å¥½ã¿ã‚’åˆ†æãƒ»æ¨æ¸¬ã™ã‚‹
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import re
from collections import defaultdict, Counter

class PreferenceAnalyzer:
    def __init__(self):
        """å¥½ã¿æ¨æ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã®è¨­å®š
        self.youtube_db_path = Path("D:/setsuna_bot/youtube_knowledge_system/data/unified_knowledge_db.json")
        self.video_history_path = Path("D:/setsuna_bot/data/video_conversation_history.json")
        self.multi_turn_path = Path("D:/setsuna_bot/data/multi_turn_conversations.json")
        
        # åˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.preference_cache = {}
        self.last_analysis_time = None
        
        # å¥½ã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é‡ã¿è¨­å®š
        self.preference_weights = {
            "positive_reaction": 2.0,
            "high_familiarity": 1.5,
            "multiple_conversations": 1.3,
            "analysis_quality": 1.2,
            "recent_activity": 1.1
        }
        
        print("[å¥½ã¿åˆ†æ] âœ… å¥½ã¿æ¨æ¸¬ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def analyze_music_preferences(self) -> Dict[str, Any]:
        """
        YouTubeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰éŸ³æ¥½çš„å¥½ã¿ã‚’åˆ†æ
        
        Returns:
            Dict: éŸ³æ¥½çš„å¥½ã¿ã®åˆ†æçµæœ
        """
        try:
            # YouTubeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿
            if not self.youtube_db_path.exists():
                print(f"[å¥½ã¿åˆ†æ] âš ï¸ YouTubeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.youtube_db_path}")
                return {}
            
            with open(self.youtube_db_path, 'r', encoding='utf-8') as f:
                youtube_data = json.load(f)
            
            videos = youtube_data.get("videos", {})
            if not videos:
                print("[å¥½ã¿åˆ†æ] âš ï¸ å‹•ç”»ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
            
            # æ¥½æ›²åˆ†æã®å®Ÿè¡Œ
            genre_analysis = self._analyze_genres(videos)
            artist_analysis = self._analyze_artists(videos)
            theme_analysis = self._analyze_themes(videos)
            quality_analysis = self._analyze_quality_indicators(videos)
            
            music_preferences = {
                "preferred_genres": genre_analysis,
                "preferred_artists": artist_analysis,
                "preferred_themes": theme_analysis,
                "quality_indicators": quality_analysis,
                "analysis_timestamp": datetime.now().isoformat(),
                "total_videos_analyzed": len(videos)
            }
            
            print(f"[å¥½ã¿åˆ†æ] âœ… éŸ³æ¥½çš„å¥½ã¿åˆ†æå®Œäº†: {len(videos)}ä»¶ã®å‹•ç”»ã‚’åˆ†æ")
            return music_preferences
            
        except Exception as e:
            print(f"[å¥½ã¿åˆ†æ] âŒ éŸ³æ¥½çš„å¥½ã¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def analyze_reaction_patterns(self) -> Dict[str, Any]:
        """
        ä¼šè©±å±¥æ­´ã‹ã‚‰åå¿œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        
        Returns:
            Dict: åå¿œãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æçµæœ
        """
        try:
            # ä¼šè©±å±¥æ­´ã®èª­ã¿è¾¼ã¿
            video_history = self._load_video_history()
            multi_turn_data = self._load_multi_turn_data()
            
            if not video_history:
                print("[å¥½ã¿åˆ†æ] âš ï¸ ä¼šè©±å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
            
            # åå¿œãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
            positive_patterns = self._analyze_positive_reactions(video_history)
            negative_patterns = self._analyze_negative_reactions(video_history)
            familiarity_patterns = self._analyze_familiarity_patterns(video_history)
            conversation_patterns = self._analyze_conversation_patterns(multi_turn_data)
            
            reaction_patterns = {
                "positive_reaction_patterns": positive_patterns,
                "negative_reaction_patterns": negative_patterns,
                "familiarity_patterns": familiarity_patterns,
                "conversation_patterns": conversation_patterns,
                "analysis_timestamp": datetime.now().isoformat(),
                "total_conversations_analyzed": len(video_history)
            }
            
            print(f"[å¥½ã¿åˆ†æ] âœ… åå¿œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æå®Œäº†: {len(video_history)}ä»¶ã®ä¼šè©±ã‚’åˆ†æ")
            return reaction_patterns
            
        except Exception as e:
            print(f"[å¥½ã¿åˆ†æ] âŒ åå¿œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def generate_preference_profile(self) -> Dict[str, Any]:
        """
        ç·åˆçš„ãªå¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        
        Returns:
            Dict: ç·åˆçš„ãªå¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
        """
        try:
            print("[å¥½ã¿åˆ†æ] ğŸ” ç·åˆçš„ãªå¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆé–‹å§‹")
            
            # å„ç¨®åˆ†æã®å®Ÿè¡Œ
            music_preferences = self.analyze_music_preferences()
            reaction_patterns = self.analyze_reaction_patterns()
            
            # å¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±åˆ
            preference_profile = {
                "music_preferences": music_preferences,
                "reaction_patterns": reaction_patterns,
                "inferred_preferences": self._infer_preferences(music_preferences, reaction_patterns),
                "creative_suggestions": self._generate_creative_suggestion_patterns(),
                "personality_alignment": self._analyze_personality_alignment(),
                "profile_timestamp": datetime.now().isoformat()
            }
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.preference_cache = preference_profile
            self.last_analysis_time = datetime.now()
            
            print("[å¥½ã¿åˆ†æ] âœ… ç·åˆçš„ãªå¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†")
            return preference_profile
            
        except Exception as e:
            print(f"[å¥½ã¿åˆ†æ] âŒ å¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_genres(self, videos: Dict) -> Dict[str, Any]:
        """ã‚¸ãƒ£ãƒ³ãƒ«åˆ†æ"""
        genre_count = defaultdict(int)
        genre_quality = defaultdict(list)
        
        for video_id, video_data in videos.items():
            # ã‚¿ã‚°ã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«æ¨å®š
            tags = video_data.get("metadata", {}).get("tags", [])
            themes = video_data.get("creative_insight", {}).get("themes", [])
            
            for tag in tags:
                if any(keyword in tag.lower() for keyword in ["vtuber", "vtube", "ãƒãƒ¼ãƒãƒ£ãƒ«"]):
                    genre_count["VTuber"] += 1
                elif any(keyword in tag.lower() for keyword in ["anime", "ã‚¢ãƒ‹ãƒ¡"]):
                    genre_count["ã‚¢ãƒ‹ãƒ¡"] += 1
                elif any(keyword in tag.lower() for keyword in ["game", "ã‚²ãƒ¼ãƒ "]):
                    genre_count["ã‚²ãƒ¼ãƒ "] += 1
            
            for theme in themes:
                genre_count[theme] += 1
                # å“è³ªæŒ‡æ¨™ã‚‚è¨˜éŒ²
                view_count = video_data.get("metadata", {}).get("view_count", 0)
                like_count = video_data.get("metadata", {}).get("like_count", 0)
                genre_quality[theme].append({"views": view_count, "likes": like_count})
        
        return {
            "genre_distribution": dict(genre_count),
            "genre_quality_metrics": dict(genre_quality),
            "top_genres": sorted(genre_count.items(), key=lambda x: x[1], reverse=True)[:5]
        }
    
    def _analyze_artists(self, videos: Dict) -> Dict[str, Any]:
        """ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåˆ†æ"""
        artist_count = defaultdict(int)
        artist_quality = defaultdict(list)
        
        for video_id, video_data in videos.items():
            channel_title = video_data.get("metadata", {}).get("channel_title", "")
            creators = video_data.get("creative_insight", {}).get("creators", [])
            
            if channel_title:
                artist_count[channel_title] += 1
                view_count = video_data.get("metadata", {}).get("view_count", 0)
                like_count = video_data.get("metadata", {}).get("like_count", 0)
                artist_quality[channel_title].append({"views": view_count, "likes": like_count})
            
            for creator in creators:
                creator_name = creator.get("name", "")
                if creator_name:
                    artist_count[creator_name] += 1
        
        return {
            "artist_distribution": dict(artist_count),
            "artist_quality_metrics": dict(artist_quality),
            "top_artists": sorted(artist_count.items(), key=lambda x: x[1], reverse=True)[:10]
        }
    
    def _analyze_themes(self, videos: Dict) -> Dict[str, Any]:
        """ãƒ†ãƒ¼ãƒåˆ†æ"""
        theme_count = defaultdict(int)
        title_keywords = defaultdict(int)
        
        for video_id, video_data in videos.items():
            title = video_data.get("metadata", {}).get("title", "")
            themes = video_data.get("creative_insight", {}).get("themes", [])
            
            for theme in themes:
                theme_count[theme] += 1
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            if title:
                # æ¥½æ›²åã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
                keywords = self._extract_keywords_from_title(title)
                for keyword in keywords:
                    title_keywords[keyword] += 1
        
        return {
            "theme_distribution": dict(theme_count),
            "title_keywords": dict(title_keywords),
            "top_themes": sorted(theme_count.items(), key=lambda x: x[1], reverse=True)[:10]
        }
    
    def _analyze_quality_indicators(self, videos: Dict) -> Dict[str, Any]:
        """å“è³ªæŒ‡æ¨™åˆ†æ"""
        quality_metrics = []
        
        for video_id, video_data in videos.items():
            metadata = video_data.get("metadata", {})
            view_count = metadata.get("view_count", 0)
            like_count = metadata.get("like_count", 0)
            comment_count = metadata.get("comment_count", 0)
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—
            engagement_rate = 0
            if view_count > 0:
                engagement_rate = (like_count + comment_count) / view_count * 100
            
            quality_metrics.append({
                "video_id": video_id,
                "view_count": view_count,
                "like_count": like_count,
                "comment_count": comment_count,
                "engagement_rate": engagement_rate
            })
        
        # å“è³ªæŒ‡æ¨™ã®çµ±è¨ˆ
        if quality_metrics:
            avg_views = sum(m["view_count"] for m in quality_metrics) / len(quality_metrics)
            avg_likes = sum(m["like_count"] for m in quality_metrics) / len(quality_metrics)
            avg_engagement = sum(m["engagement_rate"] for m in quality_metrics) / len(quality_metrics)
            
            return {
                "average_views": avg_views,
                "average_likes": avg_likes,
                "average_engagement_rate": avg_engagement,
                "high_quality_videos": [m for m in quality_metrics if m["engagement_rate"] > avg_engagement],
                "quality_threshold": avg_engagement
            }
        
        return {}
    
    def _load_video_history(self) -> Dict:
        """å‹•ç”»ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if self.video_history_path.exists():
                with open(self.video_history_path, 'r', encoding='utf-8') as f:
                    return json.load(f).get("video_conversations", {})
        except Exception as e:
            print(f"[å¥½ã¿åˆ†æ] âš ï¸ å‹•ç”»å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}
    
    def _load_multi_turn_data(self) -> Dict:
        """ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if self.multi_turn_path.exists():
                with open(self.multi_turn_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"[å¥½ã¿åˆ†æ] âš ï¸ ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}
    
    def _analyze_positive_reactions(self, video_history: Dict) -> Dict[str, Any]:
        """ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        positive_videos = []
        
        for video_id, video_data in video_history.items():
            reactions = video_data.get("user_reactions", [])
            positive_count = reactions.count("positive")
            total_count = len(reactions)
            
            if positive_count > 0 and total_count > 0:
                positive_ratio = positive_count / total_count
                if positive_ratio >= 0.5:  # 50%ä»¥ä¸ŠãŒãƒã‚¸ãƒ†ã‚£ãƒ–
                    positive_videos.append({
                        "video_id": video_id,
                        "title": video_data.get("video_title", ""),
                        "positive_ratio": positive_ratio,
                        "conversation_count": video_data.get("conversation_count", 0),
                        "familiarity_score": video_data.get("familiarity_score", 0)
                    })
        
        return {
            "positive_videos": positive_videos,
            "positive_video_count": len(positive_videos),
            "common_characteristics": self._find_common_characteristics(positive_videos)
        }
    
    def _analyze_negative_reactions(self, video_history: Dict) -> Dict[str, Any]:
        """ãƒã‚¬ãƒ†ã‚£ãƒ–ãªåå¿œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        negative_videos = []
        
        for video_id, video_data in video_history.items():
            reactions = video_data.get("user_reactions", [])
            negative_count = reactions.count("negative")
            total_count = len(reactions)
            
            if negative_count > 0 and total_count > 0:
                negative_ratio = negative_count / total_count
                if negative_ratio >= 0.5:  # 50%ä»¥ä¸ŠãŒãƒã‚¬ãƒ†ã‚£ãƒ–
                    negative_videos.append({
                        "video_id": video_id,
                        "title": video_data.get("video_title", ""),
                        "negative_ratio": negative_ratio,
                        "conversation_count": video_data.get("conversation_count", 0)
                    })
        
        return {
            "negative_videos": negative_videos,
            "negative_video_count": len(negative_videos),
            "avoidance_patterns": self._find_avoidance_patterns(negative_videos)
        }
    
    def _analyze_familiarity_patterns(self, video_history: Dict) -> Dict[str, Any]:
        """é¦´æŸ“ã¿åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        familiarity_data = []
        
        for video_id, video_data in video_history.items():
            familiarity_score = video_data.get("familiarity_score", 0)
            conversation_count = video_data.get("conversation_count", 0)
            
            if familiarity_score > 0:
                familiarity_data.append({
                    "video_id": video_id,
                    "title": video_data.get("video_title", ""),
                    "familiarity_score": familiarity_score,
                    "conversation_count": conversation_count
                })
        
        # é«˜é¦´æŸ“ã¿åº¦ã®å‹•ç”»ã‚’ç‰¹å®š
        high_familiarity_videos = [v for v in familiarity_data if v["familiarity_score"] >= 0.5]
        
        return {
            "familiarity_distribution": familiarity_data,
            "high_familiarity_videos": high_familiarity_videos,
            "familiarity_characteristics": self._analyze_familiarity_characteristics(high_familiarity_videos)
        }
    
    def _analyze_conversation_patterns(self, multi_turn_data: Dict) -> Dict[str, Any]:
        """ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        if not multi_turn_data:
            return {}
        
        turns = multi_turn_data.get("current_session", {}).get("turns", [])
        
        conversation_analysis = {
            "total_turns": len(turns),
            "mentioned_videos": [],
            "emotional_signals": [],
            "topic_transitions": []
        }
        
        for turn in turns:
            # è¨€åŠã•ã‚ŒãŸå‹•ç”»ã®åé›†
            mentioned_videos = turn.get("mentioned_videos", [])
            for video in mentioned_videos:
                conversation_analysis["mentioned_videos"].append({
                    "video_id": video.get("video_id", ""),
                    "title": video.get("title", ""),
                    "search_score": video.get("search_score", 0)
                })
            
            # æ„Ÿæƒ…ã‚·ã‚°ãƒŠãƒ«ã®åé›†
            emotional_signals = turn.get("emotional_signals", {})
            if emotional_signals:
                conversation_analysis["emotional_signals"].append(emotional_signals)
        
        return conversation_analysis
    
    def _infer_preferences(self, music_preferences: Dict, reaction_patterns: Dict) -> Dict[str, Any]:
        """éŸ³æ¥½çš„å¥½ã¿ã¨åå¿œãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æ¨è«–"""
        inferred = {
            "strongly_preferred": [],
            "preferred": [],
            "less_preferred": [],
            "creative_opportunities": []
        }
        
        # é«˜å“è³ªã‹ã¤ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œã®æ¥½æ›²ã‚’ç‰¹å®š
        if music_preferences and reaction_patterns:
            top_genres = dict(music_preferences.get("genre_distribution", {}))
            positive_videos = reaction_patterns.get("positive_reaction_patterns", {}).get("positive_videos", [])
            
            # å¼·ãå¥½ã¾ã‚Œã‚‹ã‚¸ãƒ£ãƒ³ãƒ«
            for genre, count in top_genres.items():
                if count >= 3:  # 3å›ä»¥ä¸Šç™»å ´
                    inferred["strongly_preferred"].append({
                        "type": "genre",
                        "value": genre,
                        "confidence": min(count / 10, 1.0)
                    })
            
            # å‰µä½œæ©Ÿä¼šã®ææ¡ˆ
            for video in positive_videos:
                if video.get("familiarity_score", 0) >= 0.5:
                    inferred["creative_opportunities"].append({
                        "type": "video_based_creation",
                        "title": video.get("title", ""),
                        "reason": "é«˜ã„é¦´æŸ“ã¿åº¦ã¨ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œ"
                    })
        
        return inferred
    
    def _generate_creative_suggestion_patterns(self) -> Dict[str, List[str]]:
        """å‰µä½œææ¡ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ"""
        return {
            "music_analysis_based": [
                "ã“ã®æ¥½æ›²ã®æ§‹æˆã€æ˜ åƒåˆ¶ä½œã«ã‚‚æ´»ã‹ã›ãã†ã ã‚ˆã­",
                "æ¥½æ›²ã®æ„Ÿæƒ…çš„ãªéƒ¨åˆ†ã€æ˜ åƒã§è¡¨ç¾ã—ãŸã‚‰ç¶ºéº—ã ã¨æ€ã†ã‚“ã ã‘ã©",
                "ã“ã®ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æŠ€è¡“åŠ›ã€å‚è€ƒã«ãªã‚‹ãªã"
            ],
            "visual_creation_based": [
                "ã“ã®æ¥½æ›²ã§æ˜ åƒä½œã£ãŸã‚‰ã©ã†ã‹ãªï¼Ÿ",
                "æ­Œè©ã®ä¸–ç•Œè¦³ã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã§è¡¨ç¾ã§ããã†ã ã‚ˆã­",
                "ã“ã®ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®æ˜ åƒæŠ€è¡“ã€é¢ç™½ã„ã­"
            ],
            "technical_discussion": [
                "ã“ã®æ¥½æ›²ã®æ§‹æˆè¨­è¨ˆã€å‹‰å¼·ã«ãªã‚‹ã­",
                "ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼é™£ã®å½¹å‰²åˆ†æ‹…ã€å‚è€ƒã«ãªã‚Šãã†",
                "ã“ã†ã„ã†æŠ€è¡“çš„ãªè©±ã€é…ä¿¡ã§ã‚‚è©±ã—ã¦ã¿ãŸã„ãª"
            ]
        }
    
    def _analyze_personality_alignment(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ¼ã‚½ãƒŠãƒªãƒ†ã‚£ã¨ã®æ•´åˆæ€§åˆ†æ"""
        return {
            "value_alignment_indicators": [
                "æ¥½æ›²ã®æœ¬è³ªçš„ãªé­…åŠ›ã¸ã®æ³¨ç›®",
                "ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®æŠ€è¡“åŠ›ã¸ã®è©•ä¾¡",
                "æ„Ÿæƒ…çš„ãªæ·±ã•ã¸ã®å…±æ„Ÿ"
            ],
            "consistency_checks": [
                "æ´¾æ‰‹ãªæ¼”å‡ºã‚ˆã‚Šã‚‚æœ¬è³ªé‡è¦–",
                "ä½œç‚ºçš„ã§ãªã„è‡ªç„¶ãªè¡¨ç¾",
                "å¯¾ç­‰ãªãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã¨ã—ã¦ã®æ„è¦‹äº¤æ›"
            ],
            "response_patterns": [
                "ã€Œã€œã ã¨æ€ã†ã‚“ã ã‘ã©ã€å½¢å¼ã§ã®æ„è¦‹è¡¨æ˜",
                "ã€Œã€œã—ãŸã„ãªã£ã¦æ€ã£ã¦ã¦ã€å½¢å¼ã§ã®å¸Œæœ›è¡¨ç¾",
                "ä½“é¨“è«‡ã‚’äº¤ãˆãŸå…·ä½“çš„ãªææ¡ˆ"
            ]
        }
    
    def _extract_keywords_from_title(self, title: str) -> List[str]:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        keywords = []
        
        # æ¥½æ›²åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã€Œã€ã€ã€ã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†ï¼‰
        song_patterns = re.findall(r'[ã€Œã€]([^ã€ã€]+)[ã€ã€]', title)
        keywords.extend(song_patterns)
        
        # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆâ–½â–²ãªã©ã®ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ï¼‰
        artist_patterns = re.findall(r'[â–½â–²]([^â–²â–½\s]+)[â–²â–½]', title)
        keywords.extend(artist_patterns)
        
        return keywords
    
    def _find_common_characteristics(self, videos: List[Dict]) -> Dict[str, Any]:
        """å…±é€šç‰¹å¾´ã‚’è¦‹ã¤ã‘ã‚‹"""
        if not videos:
            return {}
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã®å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        all_titles = [v.get("title", "") for v in videos]
        common_keywords = []
        
        for title in all_titles:
            keywords = self._extract_keywords_from_title(title)
            common_keywords.extend(keywords)
        
        keyword_count = Counter(common_keywords)
        
        return {
            "common_keywords": dict(keyword_count.most_common(5)),
            "average_familiarity": sum(v.get("familiarity_score", 0) for v in videos) / len(videos),
            "total_conversations": sum(v.get("conversation_count", 0) for v in videos)
        }
    
    def _find_avoidance_patterns(self, videos: List[Dict]) -> Dict[str, Any]:
        """å›é¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹"""
        if not videos:
            return {}
        
        return {
            "negative_characteristics": [
                "éåº¦ã«å•†æ¥­çš„ãªæ¥½æ›²",
                "æœ¬è³ªçš„ãªé­…åŠ›ã«æ¬ ã‘ã‚‹æ¥½æ›²",
                "ä½œç‚ºçš„ãªæ¼”å‡ºã®æ¥½æ›²"
            ],
            "avoidance_indicators": [
                "è¡¨é¢çš„ãªé­…åŠ›ã®ã¿",
                "æŠ€è¡“çš„å®Œæˆåº¦ã®ä½ã•",
                "æ„Ÿæƒ…çš„ãªæ·±ã•ã®æ¬ å¦‚"
            ]
        }
    
    def _analyze_familiarity_characteristics(self, videos: List[Dict]) -> Dict[str, Any]:
        """é¦´æŸ“ã¿åº¦ã®ç‰¹å¾´åˆ†æ"""
        if not videos:
            return {}
        
        return {
            "high_familiarity_indicators": [
                "è¤‡æ•°å›ã®ä¼šè©±",
                "ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œ",
                "æŠ€è¡“çš„ãªå®Œæˆåº¦"
            ],
            "familiarity_building_factors": [
                "æ¥½æ›²ã®å“è³ª",
                "ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®æŠ€è¡“åŠ›",
                "æ„Ÿæƒ…çš„ãªéŸ¿ã"
            ]
        }
    
    def get_cached_preferences(self) -> Optional[Dict[str, Any]]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå¥½ã¿æƒ…å ±ã‚’å–å¾—"""
        return self.preference_cache if self.preference_cache else None
    
    def needs_refresh(self, max_age_hours: int = 24) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self.last_analysis_time:
            return True
        
        time_diff = datetime.now() - self.last_analysis_time
        return time_diff.total_seconds() > (max_age_hours * 3600)

# ä½¿ç”¨ä¾‹ãƒ»ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    print("=" * 50)
    print("ğŸµ å¥½ã¿æ¨æ¸¬ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    try:
        analyzer = PreferenceAnalyzer()
        
        # å¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
        profile = analyzer.generate_preference_profile()
        
        if profile:
            print("\nğŸ“Š éŸ³æ¥½çš„å¥½ã¿åˆ†æçµæœ:")
            music_prefs = profile.get("music_preferences", {})
            top_genres = music_prefs.get("preferred_genres", {}).get("top_genres", [])
            for genre, count in top_genres[:3]:
                print(f"  - {genre}: {count}ä»¶")
            
            print("\nğŸ’­ åå¿œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æçµæœ:")
            reaction_patterns = profile.get("reaction_patterns", {})
            positive_count = reaction_patterns.get("positive_reaction_patterns", {}).get("positive_video_count", 0)
            print(f"  - ãƒã‚¸ãƒ†ã‚£ãƒ–åå¿œå‹•ç”»: {positive_count}ä»¶")
            
            print("\nğŸ¨ å‰µä½œææ¡ˆãƒ‘ã‚¿ãƒ¼ãƒ³:")
            creative_suggestions = profile.get("creative_suggestions", {})
            music_suggestions = creative_suggestions.get("music_analysis_based", [])
            for suggestion in music_suggestions[:2]:
                print(f"  - {suggestion}")
                
        else:
            print("âš ï¸ å¥½ã¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\nå¥½ã¿æ¨æ¸¬ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")