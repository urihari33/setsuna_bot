#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ - Phase 2Aå‹•ä½œç¢ºèª
"""

import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from core.semantic_search_engine import SemanticSearchEngine
import json

class SemanticSearchTester:
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ãƒ†ã‚¹ã‚¿ãƒ¼"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.engine = SemanticSearchEngine()
        
    def run_comprehensive_test(self):
        """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("ğŸ” ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³åŒ…æ‹¬ãƒ†ã‚¹ãƒˆ")
        print("=" * 60)
        
        test_results = {}
        
        # ãƒ†ã‚¹ãƒˆ1: åŸºæœ¬æ¤œç´¢æ©Ÿèƒ½
        test_results["basic_search"] = self.test_basic_search()
        
        # ãƒ†ã‚¹ãƒˆ2: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è§£æ
        test_results["semantic_analysis"] = self.test_semantic_analysis()
        
        # ãƒ†ã‚¹ãƒˆ3: ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæ¤œå‡º
        test_results["intent_detection"] = self.test_intent_detection()
        
        # ãƒ†ã‚¹ãƒˆ4: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        test_results["keyword_extraction"] = self.test_keyword_extraction()
        
        # ãƒ†ã‚¹ãƒˆ5: é–¢é€£æ€§ã‚¹ã‚³ã‚¢
        test_results["relevance_scoring"] = self.test_relevance_scoring()
        
        # ãƒ†ã‚¹ãƒˆ6: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½
        test_results["caching"] = self.test_caching()
        
        # ç·åˆçµæœ
        self.display_comprehensive_results(test_results)
        
        return test_results
    
    def test_basic_search(self):
        """åŸºæœ¬æ¤œç´¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” åŸºæœ¬æ¤œç´¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        test_queries = [
            "TRiNITY",
            "ãƒœã‚«ãƒ­",
            "ãƒ­ãƒƒã‚¯",
            "æ˜ã‚‹ã„æ›²",
            "ã‚²ãƒ¼ãƒ éŸ³æ¥½"
        ]
        
        results = {}
        
        for query in test_queries:
            try:
                search_results = self.engine.search(query, max_results=5)
                results[query] = {
                    "success": True,
                    "result_count": len(search_results),
                    "top_result": search_results[0].title if search_results else None,
                    "avg_relevance": sum(r.relevance_score for r in search_results) / len(search_results) if search_results else 0
                }
                print(f"âœ… '{query}': {len(search_results)}ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                if search_results:
                    print(f"   ãƒˆãƒƒãƒ—çµæœ: {search_results[0].title} (é–¢é€£åº¦: {search_results[0].relevance_score:.3f})")
                
            except Exception as e:
                results[query] = {"success": False, "error": str(e)}
                print(f"âŒ '{query}': ã‚¨ãƒ©ãƒ¼ - {e}")
        
        success_rate = len([r for r in results.values() if r.get("success", False)]) / len(test_queries) * 100
        print(f"\nğŸ“Š åŸºæœ¬æ¤œç´¢æˆåŠŸç‡: {success_rate:.1f}%")
        
        return {"success_rate": success_rate, "details": results}
    
    def test_semantic_analysis(self):
        """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è§£æãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§  ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è§£æãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        test_cases = [
            {
                "query": "æ˜ã‚‹ã„æ„Ÿã˜ã®æ¥½æ›²ã‚’æ¢ã—ã¦ã„ã‚‹",
                "expected_keywords": ["æ˜ã‚‹ã„", "éŸ³æ¥½"],
                "expected_intent": "search"
            },
            {
                "query": "ä½•ã‹ã„ã„ã‚¢ãƒ‹ã‚½ãƒ³ãªã„ï¼Ÿ",
                "expected_keywords": ["ã‚¢ãƒ‹ãƒ¡"],
                "expected_intent": "recommendation"
            },
            {
                "query": "TRiNITYã¨ãƒœã‚«ãƒ­ã®é•ã„ã£ã¦ä½•ï¼Ÿ",
                "expected_keywords": ["ãƒœã‚«ãƒ­"],
                "expected_intent": "comparison"
            }
        ]
        
        results = {}
        
        for i, case in enumerate(test_cases, 1):
            try:
                semantic_query = self.engine.parse_semantic_query(case["query"])
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒã‚§ãƒƒã‚¯
                keyword_match = any(kw in semantic_query.extracted_keywords for kw in case["expected_keywords"])
                
                # ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæ¤œå‡ºãƒã‚§ãƒƒã‚¯
                intent_match = semantic_query.intent_type == case["expected_intent"]
                
                results[f"case_{i}"] = {
                    "success": True,
                    "query": case["query"],
                    "extracted_keywords": semantic_query.extracted_keywords,
                    "detected_intent": semantic_query.intent_type,
                    "keyword_match": keyword_match,
                    "intent_match": intent_match
                }
                
                print(f"âœ… ã‚±ãƒ¼ã‚¹{i}: '{case['query']}'")
                print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {semantic_query.extracted_keywords}")
                print(f"   ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆ: {semantic_query.intent_type}")
                print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é©åˆ: {'â—‹' if keyword_match else 'Ã—'}")
                print(f"   ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆé©åˆ: {'â—‹' if intent_match else 'Ã—'}")
                
            except Exception as e:
                results[f"case_{i}"] = {"success": False, "error": str(e)}
                print(f"âŒ ã‚±ãƒ¼ã‚¹{i}: ã‚¨ãƒ©ãƒ¼ - {e}")
        
        success_rate = len([r for r in results.values() if r.get("success", False)]) / len(test_cases) * 100
        print(f"\nğŸ“Š ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è§£ææˆåŠŸç‡: {success_rate:.1f}%")
        
        return {"success_rate": success_rate, "details": results}
    
    def test_intent_detection(self):
        """ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ¯ ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        intent_examples = {
            "search": [
                "TRiNITYã®æ›²ã‚’æ¢ã—ã¦ã„ã‚‹",
                "ãƒ­ãƒƒã‚¯ãªå‹•ç”»ã‚ã‚‹ï¼Ÿ",
                "ã“ã®æ›²ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„"
            ],
            "recommendation": [
                "ä½•ã‹ã„ã„æ›²ãªã„ï¼Ÿ",
                "ãŠã™ã™ã‚ã®å‹•ç”»æ•™ãˆã¦",
                "ä¼¼ãŸã‚ˆã†ãªéŸ³æ¥½ã‚ã‚‹ï¼Ÿ"
            ],
            "comparison": [
                "Aã¨Bã®é•ã„ã¯ï¼Ÿ",
                "ã©ã£ã¡ãŒã„ã„ï¼Ÿ",
                "æ¯”è¼ƒã—ã¦ã¿ã¦"
            ],
            "analysis": [
                "ã“ã®æ›²ã®ç‰¹å¾´ã¯ï¼Ÿ",
                "ãªãœäººæ°—ãªã®ï¼Ÿ",
                "åˆ†æã—ã¦ãã ã•ã„"
            ]
        }
        
        results = {}
        total_tests = 0
        correct_detections = 0
        
        for expected_intent, queries in intent_examples.items():
            for query in queries:
                total_tests += 1
                try:
                    semantic_query = self.engine.parse_semantic_query(query)
                    detected_intent = semantic_query.intent_type
                    
                    is_correct = detected_intent == expected_intent
                    if is_correct:
                        correct_detections += 1
                    
                    results[query] = {
                        "expected": expected_intent,
                        "detected": detected_intent,
                        "correct": is_correct
                    }
                    
                    status = "âœ…" if is_correct else "âŒ"
                    print(f"{status} '{query}' â†’ {detected_intent} (æœŸå¾…: {expected_intent})")
                    
                except Exception as e:
                    print(f"âŒ '{query}': ã‚¨ãƒ©ãƒ¼ - {e}")
        
        accuracy = correct_detections / total_tests * 100 if total_tests > 0 else 0
        print(f"\nğŸ“Š ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæ¤œå‡ºç²¾åº¦: {accuracy:.1f}%")
        
        return {"accuracy": accuracy, "details": results}
    
    def test_keyword_extraction(self):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        test_cases = [
            {
                "text": "æ˜ã‚‹ã„ãƒ­ãƒƒã‚¯éŸ³æ¥½ãŒå¥½ã",
                "expected_categories": ["mood", "genre", "content_type"]
            },
            {
                "text": "ãƒœã‚«ãƒ­ã®ãƒãƒ©ãƒ¼ãƒ‰ã‚’æ¢ã—ã¦ã„ã‚‹",
                "expected_categories": ["technology", "genre"]
            },
            {
                "text": "ã‚²ãƒ¼ãƒ å®Ÿæ³ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹BGM",
                "expected_categories": ["content_type", "purpose"]
            }
        ]
        
        results = {}
        
        for i, case in enumerate(test_cases, 1):
            try:
                semantic_query = self.engine.parse_semantic_query(case["text"])
                extracted_keywords = semantic_query.extracted_keywords
                
                # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
                found_categories = []
                if any(kw in ["æ˜ã‚‹ã„", "æš—ã„", "æ¿€ã—ã„", "ç©ã‚„ã‹"] for kw in extracted_keywords):
                    found_categories.append("mood")
                if any(kw in ["ãƒ­ãƒƒã‚¯", "ãƒãƒƒãƒ—", "ãƒœã‚«ãƒ­", "ã‚¯ãƒ©ã‚·ãƒƒã‚¯"] for kw in extracted_keywords):
                    found_categories.append("genre")
                if any(kw in ["éŸ³æ¥½", "å‹•ç”»", "ã‚²ãƒ¼ãƒ "] for kw in extracted_keywords):
                    found_categories.append("content_type")
                
                results[f"case_{i}"] = {
                    "text": case["text"],
                    "extracted_keywords": extracted_keywords,
                    "found_categories": found_categories,
                    "extraction_count": len(extracted_keywords)
                }
                
                print(f"âœ… ã‚±ãƒ¼ã‚¹{i}: '{case['text']}'")
                print(f"   æŠ½å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {extracted_keywords}")
                print(f"   ã‚«ãƒ†ã‚´ãƒª: {found_categories}")
                
            except Exception as e:
                results[f"case_{i}"] = {"error": str(e)}
                print(f"âŒ ã‚±ãƒ¼ã‚¹{i}: ã‚¨ãƒ©ãƒ¼ - {e}")
        
        return {"details": results}
    
    def test_relevance_scoring(self):
        """é–¢é€£æ€§ã‚¹ã‚³ã‚¢ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“Š é–¢é€£æ€§ã‚¹ã‚³ã‚¢ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        test_query = "TRiNITY"
        
        try:
            search_results = self.engine.search(test_query, max_results=10)
            
            if not search_results:
                print("âŒ æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“")
                return {"success": False, "error": "No results"}
            
            # ã‚¹ã‚³ã‚¢åˆ†æ
            scores = [r.relevance_score for r in search_results]
            avg_score = sum(scores) / len(scores)
            max_score = max(scores)
            min_score = min(scores)
            
            # ã‚½ãƒ¼ãƒˆç¢ºèª
            is_sorted = all(scores[i] >= scores[i+1] for i in range(len(scores)-1))
            
            print(f"âœ… æ¤œç´¢çµæœ: {len(search_results)}ä»¶")
            print(f"   å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.3f}")
            print(f"   æœ€é«˜ã‚¹ã‚³ã‚¢: {max_score:.3f}")
            print(f"   æœ€ä½ã‚¹ã‚³ã‚¢: {min_score:.3f}")
            print(f"   æ­£ã—ãã‚½ãƒ¼ãƒˆ: {'â—‹' if is_sorted else 'Ã—'}")
            
            # ä¸Šä½çµæœè¡¨ç¤º
            print("\n   ä¸Šä½3ä»¶:")
            for i, result in enumerate(search_results[:3], 1):
                print(f"   {i}. {result.title} (ã‚¹ã‚³ã‚¢: {result.relevance_score:.3f})")
            
            return {
                "success": True,
                "result_count": len(search_results),
                "avg_score": avg_score,
                "max_score": max_score,
                "min_score": min_score,
                "is_sorted": is_sorted
            }
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "error": str(e)}
    
    def test_caching(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        test_query = "ãƒœã‚«ãƒ­"
        
        try:
            # åˆå›æ¤œç´¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—ï¼‰
            import time
            start_time = time.time()
            results1 = self.engine.search(test_query, max_results=5, use_cache=True)
            first_time = time.time() - start_time
            
            # 2å›ç›®æ¤œç´¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼‰
            start_time = time.time()
            results2 = self.engine.search(test_query, max_results=5, use_cache=True)
            second_time = time.time() - start_time
            
            # çµæœæ¯”è¼ƒ
            results_match = len(results1) == len(results2)
            if results_match and results1:
                results_match = all(r1.video_id == r2.video_id for r1, r2 in zip(results1, results2))
            
            # çµ±è¨ˆæƒ…å ±
            stats = self.engine.get_search_statistics()
            
            print(f"âœ… åˆå›æ¤œç´¢: {len(results1)}ä»¶ ({first_time:.4f}ç§’)")
            print(f"âœ… 2å›ç›®æ¤œç´¢: {len(results2)}ä»¶ ({second_time:.4f}ç§’)")
            print(f"   çµæœä¸€è‡´: {'â—‹' if results_match else 'Ã—'}")
            print(f"   é«˜é€ŸåŒ–: {first_time/second_time:.1f}å€" if second_time > 0 else "   é«˜é€ŸåŒ–: è¨ˆæ¸¬ä¸å¯")
            print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°: {stats.get('cache_hits', 0)}")
            
            return {
                "success": True,
                "results_match": results_match,
                "speedup": first_time/second_time if second_time > 0 else 0,
                "cache_hits": stats.get('cache_hits', 0)
            }
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "error": str(e)}
    
    def display_comprehensive_results(self, test_results):
        """ç·åˆçµæœè¡¨ç¤º"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ç·åˆãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 60)
        
        total_tests = 0
        passed_tests = 0
        
        for test_name, result in test_results.items():
            total_tests += 1
            
            if result.get("success", False) or result.get("success_rate", 0) > 70:
                passed_tests += 1
                status = "âœ… åˆæ ¼"
            else:
                status = "âŒ ä¸åˆæ ¼"
            
            print(f"{status} {test_name}")
            
            # è©³ç´°è¡¨ç¤º
            if "success_rate" in result:
                print(f"    æˆåŠŸç‡: {result['success_rate']:.1f}%")
            elif "accuracy" in result:
                print(f"    ç²¾åº¦: {result['accuracy']:.1f}%")
        
        overall_success_rate = passed_tests / total_tests * 100
        print(f"\nğŸ¯ ç·åˆæˆåŠŸç‡: {overall_success_rate:.1f}% ({passed_tests}/{total_tests})")
        
        if overall_success_rate >= 80:
            print("ğŸ‰ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
        elif overall_success_rate >= 60:
            print("âš ï¸ ä¸€éƒ¨æ©Ÿèƒ½ã«æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")
        else:
            print("ğŸ”§ å¤§å¹…ãªä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    tester = SemanticSearchTester()
    results = tester.run_comprehensive_test()
    
    print(f"\nâœ¨ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    return results

if __name__ == "__main__":
    main()