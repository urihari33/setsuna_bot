#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚·ãƒ³ãƒ—ãƒ«ãªãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ãƒã‚§ãƒƒã‚¯
ç›´æ¥OpenAI APIã‚’å‘¼ã³å‡ºã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’ç¢ºèª
"""

import openai
import os
from dotenv import load_dotenv

def test_token_limits_direct():
    """ç›´æ¥OpenAI APIã§ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”¬ ç›´æ¥APIãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ãƒ†ã‚¹ãƒˆ")
    print("=" * 40)
    
    # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    client = openai.OpenAI(api_key=api_key)
    
    test_prompt = "æ˜ åƒåˆ¶ä½œã§é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚æŠ€è¡“çš„ãªé¢ã¨å‰µä½œçš„ãªé¢ã®ä¸¡æ–¹ã‹ã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    
    # ãƒ†ã‚¹ãƒˆè¨­å®šï¼ˆä¿®æ­£å¾Œã®å€¤ï¼‰
    test_configs = [
        {"mode": "ultra_fast", "max_tokens": 80, "description": "è¶…é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆä¿®æ­£å¾Œï¼‰"},
        {"mode": "fast_response", "max_tokens": 120, "description": "é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆä¿®æ­£å¾Œï¼‰"},
        {"mode": "normal", "max_tokens": 160, "description": "é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆä¿®æ­£å¾Œï¼‰"}
    ]
    
    for config in test_configs:
        print(f"\n--- {config['description']} (max_tokens={config['max_tokens']}) ---")
        
        try:
            response = client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯æ˜ åƒåˆ¶ä½œã«è©³ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§è¦ªã—ã¿ã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": test_prompt}
                ],
                max_tokens=config['max_tokens'],
                temperature=0.6
            )
            
            response_text = response.choices[0].message.content.strip()
            actual_tokens = response.usage.completion_tokens
            
            print(f"è¨­å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {config['max_tokens']}")
            print(f"å®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {actual_tokens}")
            print(f"æ–‡å­—æ•°: {len(response_text)}")
            print(f"å¿œç­”: {response_text}")
            
            # æ–‡ç« ã®å®Œçµæ€§ãƒã‚§ãƒƒã‚¯
            is_complete = (
                response_text.endswith("ã€‚") or 
                response_text.endswith("ï¼") or 
                response_text.endswith("ï¼Ÿ") or
                response_text.endswith("ã§ã™") or
                response_text.endswith("ã¾ã™")
            )
            
            print(f"æ–‡ç« å®Œçµæ€§: {'âœ… å®Œçµ' if is_complete else 'âš ï¸ ä¸å®Œå…¨'}")
            
            if actual_tokens >= config['max_tokens'] * 0.9:
                print("ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    test_token_limits_direct()

if __name__ == "__main__":
    main()