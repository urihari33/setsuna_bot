# ç¬¬8ç« : ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã¨é‹ç”¨ç®¡ç†

## **ç« ã®æ¦‚è¦**

ã“ã®ç« ã§ã¯ã€YouTubeãƒŠãƒ¬ãƒƒã‚¸ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨é‹ç”¨ç®¡ç†ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚ç’°å¢ƒè¨­å®šç®¡ç†ã€ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥ã¾ã§ã€å®Ÿè·µçš„ãªã‚·ã‚¹ãƒ†ãƒ é‹ç”¨æŠ€è¡“ã‚’ä½“ç³»çš„ã«å­¦ã³ã¾ã™ã€‚

**å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«**: çµ±åˆè¨­å®šãƒ»é‹ç”¨ç®¡ç†å…¨èˆ¬  
**ä¸»è¦æŠ€è¡“**: ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã€ãƒ­ã‚°ç®¡ç†ã€ç›£è¦–ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã€é‹ç”¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

---

## **ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**

### **çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å…¨ä½“åƒ**

YouTubeãƒŠãƒ¬ãƒƒã‚¸ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä»¥ä¸‹ã®å±¤æ§‹é€ ã§è¨­è¨ˆã•ã‚ŒãŸ**ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ï¼š

```
YouTube Knowledge System - çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ–¥ï¸ Presentation Layer (ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å±¤)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ GUI Layer       â”‚ CLI Interface   â”‚ Web API (å°†æ¥)   â”‚     â”‚
â”‚  â”‚ gui/            â”‚ (ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³)  â”‚ (REST API)      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”§ Business Logic Layer (ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å±¤)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Managers        â”‚ Analyzers       â”‚ Collectors      â”‚     â”‚
â”‚  â”‚ è¨­å®šç®¡ç†         â”‚ AIåˆ†æã‚¨ãƒ³ã‚¸ãƒ³    â”‚ ãƒ‡ãƒ¼ã‚¿åé›†       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¾ Data Access Layer (ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å±¤)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Storage         â”‚ External APIs   â”‚ Configuration   â”‚     â”‚
â”‚  â”‚ unified_storage â”‚ YouTube/OpenAI  â”‚ ç’°å¢ƒè¨­å®šç®¡ç†      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ—ƒï¸ Infrastructure Layer (ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£å±¤)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ File System     â”‚ Logging         â”‚ Error Handling  â”‚     â”‚
â”‚  â”‚ JSON Database   â”‚ é‹ç”¨ç›£è¦–         â”‚ ä¾‹å¤–å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ä¾å­˜é–¢ä¿‚**

#### **ğŸ”— ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆä¾å­˜å›³**

```python
# ä¾å­˜é–¢ä¿‚ã®éšå±¤æ§‹é€ ï¼ˆä¸‹ä½ã‹ã‚‰ä¸Šä½ã¸ï¼‰

# Layer 1: Core Foundation
core/
â”œâ”€â”€ data_models.py          # ãƒ‡ãƒ¼ã‚¿æ§‹é€ å®šç¾©
â””â”€â”€ __init__.py

# Layer 2: Infrastructure & Configuration
config/
â”œâ”€â”€ settings.py             # ç’°å¢ƒè¨­å®šç®¡ç†
â””â”€â”€ __init__.py

# Layer 3: Data Access
storage/
â”œâ”€â”€ unified_storage.py      # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
â””â”€â”€ __init__.py

# Layer 4: Business Logic
collectors/
â”œâ”€â”€ multi_playlist_collector.py  # YouTube APIæ“ä½œ
â””â”€â”€ __init__.py

analyzers/
â”œâ”€â”€ description_analyzer.py      # AIåˆ†æå‡¦ç†
â””â”€â”€ __init__.py

managers/
â”œâ”€â”€ playlist_config_manager.py   # è¨­å®šç®¡ç†
â””â”€â”€ __init__.py

# Layer 5: Presentation
gui/
â”œâ”€â”€ video_main_window.py         # ãƒ¡ã‚¤ãƒ³GUI
â”œâ”€â”€ widgets/                     # ã‚«ã‚¹ã‚¿ãƒ ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
â””â”€â”€ utils/                       # GUIæ”¯æ´ãƒ„ãƒ¼ãƒ«
```

**åˆå¿ƒè€…å‘ã‘: ä¾å­˜é–¢ä¿‚è¨­è¨ˆã®åŸå‰‡**

```python
# âœ… è‰¯ã„ä¾å­˜é–¢ä¿‚ï¼ˆä¸Šä½ãŒä¸‹ä½ã«ä¾å­˜ï¼‰
class VideoMainWindow:      # GUIå±¤
    def __init__(self):
        self.storage = UnifiedStorage()    # ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å±¤ã«ä¾å­˜
        self.analyzer = DescriptionAnalyzer()  # ãƒ“ã‚¸ãƒã‚¹å±¤ã«ä¾å­˜

# âŒ æ‚ªã„ä¾å­˜é–¢ä¿‚ï¼ˆä¸‹ä½ãŒä¸Šä½ã«ä¾å­˜ï¼‰
class UnifiedStorage:       # ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å±¤
    def save_data(self):
        gui.show_message("ä¿å­˜å®Œäº†")  # GUIå±¤ã«ä¾å­˜ï¼ˆå¾ªç’°ä¾å­˜ï¼‰

# è¨­è¨ˆåŸå‰‡ï¼š
# 1. ä¸‹ä½å±¤ã¯ä¸Šä½å±¤ã‚’çŸ¥ã‚‰ãªã„
# 2. ä¸Šä½å±¤ã¯ä¸‹ä½å±¤ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ã¿ä½¿ç”¨
# 3. åŒã˜å±¤å†…ã§ã¯ç›¸äº’ä¾å­˜ã‚’é¿ã‘ã‚‹
```

---

## **âš™ï¸ ç’°å¢ƒè¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ **

### **ç’°å¢ƒå¯¾å¿œè¨­å®šã®å®Ÿè£…**

#### **ğŸŒ ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ**

```python
# config/settings.py ã®ç’°å¢ƒæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 

def get_data_dir():
    """ç’°å¢ƒã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
    import platform
    import shutil
    
    # Windowsç’°å¢ƒã‹WSL2ã‹ã‚’åˆ¤å®š
    system = platform.system().lower()
    
    if system == "windows":
        # ç´”ç²‹ãªWindowsç’°å¢ƒ
        windows_path = Path("D:/setsuna_bot/youtube_knowledge_system/data")
        wsl_path = Path("/mnt/d/setsuna_bot/youtube_knowledge_system/data")
        
        # Windowsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        if not windows_path.exists():
            windows_path.mkdir(parents=True, exist_ok=True)
            print(f"Windows ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {windows_path}")
        
        # WSL2ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚³ãƒ”ãƒ¼
        if wsl_path.exists():
            migrate_data_from_wsl_to_windows(wsl_path, windows_path)
        
        return windows_path
    else:
        # Linux/WSL2ç’°å¢ƒã§ã®è‡ªå‹•æ¤œå‡º
        return detect_best_data_path()
```

**åˆå¿ƒè€…å‘ã‘: platform.system() ã®æ´»ç”¨**

```python
import platform

# ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ¤œå‡ºã®åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³
system_info = {
    'system': platform.system(),        # 'Windows', 'Linux', 'Darwin'
    'release': platform.release(),      # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    'machine': platform.machine(),      # 'AMD64', 'x86_64', 'arm64'
    'processor': platform.processor()   # ãƒ—ãƒ­ã‚»ãƒƒã‚µæƒ…å ±
}

# WSL2ã®æ¤œå‡ºæ–¹æ³•
def is_wsl2():
    """WSL2ç’°å¢ƒã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    try:
        with open('/proc/version', 'r') as f:
            version_info = f.read().lower()
        return 'microsoft' in version_info and 'wsl2' in version_info
    except:
        return False

# ç”¨é€”åˆ¥ãƒ‘ã‚¹è¨­å®š
if platform.system() == "Windows":
    config_path = Path.home() / "AppData" / "Local" / "AppName"
elif platform.system() == "Darwin":  # macOS
    config_path = Path.home() / "Library" / "Application Support" / "AppName"
else:  # Linux
    config_path = Path.home() / ".config" / "appname"
```

#### **ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½**

```python
def migrate_data_from_wsl_to_windows(wsl_path: Path, windows_path: Path):
    """WSL2ã‹ã‚‰Windowsã¸ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    migration_items = [
        {
            'source': 'unified_knowledge_db.json',
            'target': 'unified_knowledge_db.json',
            'description': 'ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹'
        },
        {
            'source': 'playlist_configs.json',
            'target': 'playlist_configs.json', 
            'description': 'ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆè¨­å®š'
        },
        {
            'source': 'backups/',
            'target': 'backups/',
            'description': 'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª',
            'recursive': True
        }
    ]
    
    print("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
    migrated_count = 0
    
    for item in migration_items:
        source_path = wsl_path / item['source']
        target_path = windows_path / item['target']
        
        try:
            if item.get('recursive') and source_path.is_dir():
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã®ã‚³ãƒ”ãƒ¼
                shutil.copytree(str(source_path), str(target_path), dirs_exist_ok=True)
                print(f"   ğŸ“ {item['description']}: {source_path} â†’ {target_path}")
                migrated_count += 1
                
            elif source_path.is_file() and not target_path.exists():
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼
                shutil.copy2(str(source_path), str(target_path))
                print(f"   ğŸ“„ {item['description']}: {source_path} â†’ {target_path}")
                migrated_count += 1
                
        except Exception as e:
            print(f"   âŒ {item['description']} ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
    
    if migrated_count > 0:
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {migrated_count}ä»¶ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç§»è¡Œã—ã¾ã—ãŸ")
    else:
        print("â„¹ï¸  ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
```

### **è¨­å®šé …ç›®ã®éšå±¤ç®¡ç†**

#### **ğŸ—ï¸ è¨­å®šã‚«ãƒ†ã‚´ãƒªã®æ§‹é€ åŒ–**

```python
# è¨­å®šé …ç›®ã®éšå±¤åŒ–
class SystemSettings:
    """ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã®çµ±åˆç®¡ç†"""
    
    def __init__(self):
        self.paths = PathSettings()
        self.api = APISettings()
        self.performance = PerformanceSettings()
        self.logging = LoggingSettings()
        self.features = FeatureSettings()

class PathSettings:
    """ãƒ‘ã‚¹é–¢é€£è¨­å®š"""
    def __init__(self):
        self.data_dir = get_data_dir()
        self.log_dir = self.data_dir.parent / "logs"
        self.backup_dir = self.data_dir / "backups"
        self.config_dir = self.data_dir.parent / "config"

class APISettings:
    """APIé–¢é€£è¨­å®š"""
    def __init__(self):
        self.youtube_service_name = "youtube"
        self.youtube_api_version = "v3"
        self.youtube_scopes = ["https://www.googleapis.com/auth/youtube.readonly"]
        self.openai_model = "gpt-4o-mini"
        self.max_tokens = 1200
        self.temperature = 0.1

class PerformanceSettings:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¢é€£è¨­å®š"""
    def __init__(self):
        self.max_results_per_request = 50
        self.max_total_videos = 1000
        self.quota_limit_per_day = 10000
        self.concurrent_workers = 4
        self.request_delay = 1.0

class LoggingSettings:
    """ãƒ­ã‚°é–¢é€£è¨­å®š"""
    def __init__(self):
        self.level = "INFO"
        self.format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        self.file_max_size = 10 * 1024 * 1024  # 10MB
        self.backup_count = 5
        self.console_output = True

class FeatureSettings:
    """æ©Ÿèƒ½æœ‰åŠ¹/ç„¡åŠ¹è¨­å®š"""
    def __init__(self):
        self.auto_backup = True
        self.periodic_sync = True
        self.telemetry_enabled = False
        self.debug_mode = False
        self.experimental_features = []
```

**è¨­å®šã®å‹•çš„æ›´æ–°æ©Ÿèƒ½**

```python
class ConfigManager:
    """è¨­å®šã®å‹•çš„ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_file: Path = None):
        self.config_file = config_file or (DATA_DIR.parent / "config" / "system_config.json")
        self.settings = SystemSettings()
        self.load_config()
    
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                # è¨­å®šã‚’å‹•çš„ã«é©ç”¨
                self.apply_config(config_data)
                print(f"è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.config_file}")
                
            except Exception as e:
                print(f"è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
    
    def apply_config(self, config_data: dict):
        """è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’é©ç”¨"""
        for category, settings in config_data.items():
            if hasattr(self.settings, category):
                category_obj = getattr(self.settings, category)
                for key, value in settings.items():
                    if hasattr(category_obj, key):
                        setattr(category_obj, key, value)
    
    def save_config(self):
        """ç¾åœ¨ã®è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        config_data = self.to_dict()
        
        try:
            self.config_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {self.config_file}")
            return True
            
        except Exception as e:
            print(f"è¨­å®šä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def to_dict(self) -> dict:
        """è¨­å®šã‚’ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªå½¢å¼ã§å–å¾—"""
        return {
            'paths': vars(self.settings.paths),
            'api': vars(self.settings.api),
            'performance': vars(self.settings.performance),
            'logging': vars(self.settings.logging),
            'features': vars(self.settings.features)
        }
```

---

## **ğŸ“ ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¨ç›£è¦–**

### **æ§‹é€ åŒ–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…**

#### **ğŸ—ï¸ éšå±¤åŒ–ãƒ­ã‚°è¨­å®š**

```python
import logging
import logging.handlers
from datetime import datetime
from pathlib import Path
import json

class StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, name: str, log_dir: Path = None):
        self.name = name
        self.log_dir = log_dir or (DATA_DIR.parent / "logs")
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ­ã‚¬ãƒ¼ä½œæˆ
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # é‡è¤‡ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’é˜²ã
        if not self.logger.handlers:
            self.setup_handlers()
    
    def setup_handlers(self):
        """ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š"""
        
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ï¼ˆå›è»¢ãƒ­ã‚°ï¼‰
        file_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / f"{self.name}.log",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        file_handler.setLevel(logging.INFO)
        
        # 2. ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.WARNING)
        
        # 3. ã‚¨ãƒ©ãƒ¼å°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«
        error_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / f"{self.name}_errors.log",
            maxBytes=5*1024*1024,   # 5MB
            backupCount=3,
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼è¨­å®š
        detailed_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
        )
        
        simple_formatter = logging.Formatter(
            '%(levelname)s: %(message)s'
        )
        
        file_handler.setFormatter(detailed_formatter)
        console_handler.setFormatter(simple_formatter) 
        error_handler.setFormatter(detailed_formatter)
        
        # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¿½åŠ 
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        self.logger.addHandler(error_handler)
    
    def log_operation(self, operation: str, **kwargs):
        """æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'operation': operation,
            'component': self.name,
            **kwargs
        }
        
        # JSONå½¢å¼ã§ãƒ­ã‚°å‡ºåŠ›
        self.logger.info(f"STRUCTURED_LOG: {json.dumps(log_entry, ensure_ascii=False)}")
    
    def log_error(self, error: Exception, context: dict = None):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°å‡ºåŠ›"""
        import traceback
        
        error_data = {
            'timestamp': datetime.now().isoformat(),
            'error_type': type(error).__name__,
            'error_message': str(error),
            'traceback': traceback.format_exc(),
            'context': context or {}
        }
        
        self.logger.error(f"ERROR_LOG: {json.dumps(error_data, ensure_ascii=False)}")
    
    def log_performance(self, operation: str, duration: float, **metrics):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°å‡ºåŠ›"""
        perf_data = {
            'timestamp': datetime.now().isoformat(),
            'operation': operation,
            'duration_seconds': duration,
            'metrics': metrics
        }
        
        self.logger.info(f"PERFORMANCE_LOG: {json.dumps(perf_data, ensure_ascii=False)}")
```

**åˆå¿ƒè€…å‘ã‘: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®ä½¿ã„åˆ†ã‘**

```python
import logging

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®éšå±¤ï¼ˆæ•°å€¤ã¯é‡è¦åº¦ï¼‰
# CRITICAL (50) > ERROR (40) > WARNING (30) > INFO (20) > DEBUG (10)

logger = logging.getLogger("example")

# ä½¿ã„åˆ†ã‘ã®ä¾‹
def example_operations():
    
    # DEBUG: é–‹ç™ºæ™‚ã®è©³ç´°ãªå‹•ä½œç¢ºèª
    logger.debug("å‡¦ç†é–‹å§‹: å‹•ç”»ID=abc123")
    
    # INFO: é€šå¸¸ã®å‹•ä½œãƒ­ã‚°ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã‚‚æ®‹ã™ï¼‰
    logger.info("å‹•ç”»åˆ†æå®Œäº†: æˆåŠŸ=10ä»¶, å¤±æ•—=2ä»¶")
    
    # WARNING: æ³¨æ„ãŒå¿…è¦ã ãŒå‡¦ç†ã¯ç¶šè¡Œ
    logger.warning("APIåˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™: ä½¿ç”¨é‡=9500/10000")
    
    # ERROR: ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŒå¾©æ—§å¯èƒ½
    logger.error("å‹•ç”»å–å¾—å¤±æ•—: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼, å†è©¦è¡Œã—ã¾ã™")
    
    # CRITICAL: ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ãƒ¬ãƒ™ãƒ«ã®è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼
    logger.critical("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ç ´æ: ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã™")

# æœ¬ç•ªç’°å¢ƒã®è¨­å®šä¾‹
production_config = {
    'console': logging.WARNING,  # è­¦å‘Šä»¥ä¸Šã®ã¿ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    'file': logging.INFO,        # æƒ…å ±ä»¥ä¸Šã‚’ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    'error_file': logging.ERROR  # ã‚¨ãƒ©ãƒ¼ä»¥ä¸Šã‚’å°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
}
```

#### **ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ **

```python
class MetricsCollector:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
    
    def __init__(self):
        self.logger = StructuredLogger("metrics")
        self.start_time = datetime.now()
        self.operation_counts = {}
        self.error_counts = {}
        self.performance_data = []
    
    def record_operation(self, operation: str, success: bool = True, duration: float = None):
        """æ“ä½œè¨˜éŒ²"""
        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ›´æ–°
        if operation not in self.operation_counts:
            self.operation_counts[operation] = {'success': 0, 'failure': 0}
        
        if success:
            self.operation_counts[operation]['success'] += 1
        else:
            self.operation_counts[operation]['failure'] += 1
            self.error_counts[operation] = self.error_counts.get(operation, 0) + 1
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²
        if duration:
            self.performance_data.append({
                'operation': operation,
                'duration': duration,
                'timestamp': datetime.now(),
                'success': success
            })
        
        # ãƒ­ã‚°å‡ºåŠ›
        self.logger.log_operation(
            operation="operation_recorded",
            op_type=operation,
            success=success,
            duration=duration
        )
    
    def get_system_health(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹æƒ…å ±å–å¾—"""
        now = datetime.now()
        uptime = (now - self.start_time).total_seconds()
        
        # ç·æ“ä½œæ•°è¨ˆç®—
        total_operations = sum(
            data['success'] + data['failure'] 
            for data in self.operation_counts.values()
        )
        
        # æˆåŠŸç‡è¨ˆç®—
        total_success = sum(data['success'] for data in self.operation_counts.values())
        success_rate = (total_success / total_operations) if total_operations > 0 else 0
        
        # ã‚¨ãƒ©ãƒ¼ç‡è¨ˆç®—
        total_errors = sum(self.error_counts.values())
        error_rate = (total_errors / total_operations) if total_operations > 0 else 0
        
        # å¹³å‡å‡¦ç†æ™‚é–“è¨ˆç®—
        recent_performance = [
            p for p in self.performance_data 
            if (now - p['timestamp']).total_seconds() < 3600  # éå»1æ™‚é–“
        ]
        
        avg_duration = (
            sum(p['duration'] for p in recent_performance) / len(recent_performance)
            if recent_performance else 0
        )
        
        health_status = {
            'uptime_seconds': uptime,
            'total_operations': total_operations,
            'success_rate': success_rate,
            'error_rate': error_rate,
            'average_duration': avg_duration,
            'operations_per_hour': len(recent_performance),
            'status': self._determine_health_status(success_rate, error_rate)
        }
        
        return health_status
    
    def _determine_health_status(self, success_rate: float, error_rate: float) -> str:
        """ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š"""
        if success_rate >= 0.95 and error_rate <= 0.05:
            return "healthy"
        elif success_rate >= 0.85 and error_rate <= 0.15:
            return "warning"
        else:
            return "critical"
    
    def export_metrics(self, output_file: Path = None):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not output_file:
            output_file = DATA_DIR / f"metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        metrics_data = {
            'collection_period': {
                'start': self.start_time.isoformat(),
                'end': datetime.now().isoformat()
            },
            'system_health': self.get_system_health(),
            'operation_counts': self.operation_counts,
            'error_counts': self.error_counts,
            'performance_summary': self._summarize_performance()
        }
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, ensure_ascii=False, indent=2)
            
            print(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {output_file}")
            return output_file
            
        except Exception as e:
            self.logger.log_error(e, {'operation': 'export_metrics'})
            return None
```

### **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ **

#### **âš¡ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½**

```python
class SystemMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, check_interval: int = 60):
        self.check_interval = check_interval
        self.logger = StructuredLogger("monitor")
        self.metrics = MetricsCollector()
        self.alerts = []
        self.last_check = datetime.now()
    
    def run_health_checks(self) -> dict:
        """åŒ…æ‹¬çš„ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        checks = {
            'database_health': self._check_database_health(),
            'api_connectivity': self._check_api_connectivity(), 
            'disk_space': self._check_disk_space(),
            'memory_usage': self._check_memory_usage(),
            'log_file_health': self._check_log_file_health(),
            'error_rates': self._check_error_rates()
        }
        
        # ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        failed_checks = [name for name, result in checks.items() if not result.get('healthy', False)]
        overall_health = len(failed_checks) == 0
        
        health_report = {
            'timestamp': datetime.now().isoformat(),
            'overall_healthy': overall_health,
            'failed_checks': failed_checks,
            'check_details': checks
        }
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ
        if not overall_health:
            self._generate_alerts(failed_checks, checks)
        
        self.logger.log_operation(
            "health_check_completed",
            overall_healthy=overall_health,
            failed_checks=len(failed_checks)
        )
        
        return health_report
    
    def _check_database_health(self) -> dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            from storage.unified_storage import get_storage
            storage = get_storage()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
            db = storage.load_database()
            stats = storage.get_statistics()
            
            # åŸºæœ¬çš„ãªæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            total_videos = stats.get('total_videos', 0)
            analysis_rate = stats.get('analysis_success_rate', 0)
            
            healthy = (
                total_videos > 0 and 
                analysis_rate >= 0 and 
                db.last_updated is not None
            )
            
            return {
                'healthy': healthy,
                'total_videos': total_videos,
                'analysis_rate': analysis_rate,
                'last_updated': db.last_updated.isoformat() if db.last_updated else None,
                'message': "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ­£å¸¸" if healthy else "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç•°å¸¸æ¤œå‡º"
            }
            
        except Exception as e:
            return {
                'healthy': False,
                'error': str(e),
                'message': "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼"
            }
    
    def _check_api_connectivity(self) -> dict:
        """APIæ¥ç¶šæ€§ãƒã‚§ãƒƒã‚¯"""
        api_results = {}
        
        # YouTube API ãƒã‚§ãƒƒã‚¯
        try:
            from collectors.multi_playlist_collector import MultiPlaylistCollector
            collector = MultiPlaylistCollector()
            youtube_ok = collector._initialize_service()
            api_results['youtube'] = youtube_ok
        except:
            api_results['youtube'] = False
        
        # OpenAI API ãƒã‚§ãƒƒã‚¯
        try:
            from analyzers.description_analyzer import DescriptionAnalyzer
            analyzer = DescriptionAnalyzer()
            # è»½é‡ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            openai_ok = hasattr(analyzer, 'client') and analyzer.client is not None
            api_results['openai'] = openai_ok
        except:
            api_results['openai'] = False
        
        all_apis_healthy = all(api_results.values())
        
        return {
            'healthy': all_apis_healthy,
            'api_status': api_results,
            'message': "å…¨APIæ¥ç¶šOK" if all_apis_healthy else "APIæ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
        }
    
    def _check_disk_space(self) -> dict:
        """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯"""
        try:
            import shutil
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å®¹é‡ãƒã‚§ãƒƒã‚¯
            total, used, free = shutil.disk_usage(DATA_DIR)
            
            # ãƒã‚¤ãƒˆã‚’GBã«å¤‰æ›
            total_gb = total / (1024**3)
            used_gb = used / (1024**3)
            free_gb = free / (1024**3)
            usage_percent = (used / total) * 100
            
            # è­¦å‘Šé–¾å€¤: ä½¿ç”¨ç‡90%ä»¥ä¸Šã§è­¦å‘Š
            healthy = usage_percent < 90
            
            return {
                'healthy': healthy,
                'total_gb': round(total_gb, 2),
                'used_gb': round(used_gb, 2),
                'free_gb': round(free_gb, 2),
                'usage_percent': round(usage_percent, 1),
                'message': f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {usage_percent:.1f}%" + 
                          ("" if healthy else " (è­¦å‘Š: 90%è¶…é)")
            }
            
        except Exception as e:
            return {
                'healthy': False,
                'error': str(e),
                'message': "ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼"
            }
    
    def _generate_alerts(self, failed_checks: list, check_details: dict):
        """ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ"""
        alert = {
            'timestamp': datetime.now().isoformat(),
            'level': 'warning' if len(failed_checks) <= 2 else 'critical',
            'failed_checks': failed_checks,
            'summary': f"{len(failed_checks)}å€‹ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãŒå¤±æ•—ã—ã¾ã—ãŸ",
            'details': {check: check_details[check] for check in failed_checks}
        }
        
        self.alerts.append(alert)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ­ã‚°å‡ºåŠ›
        self.logger.logger.warning(f"SYSTEM_ALERT: {json.dumps(alert, ensure_ascii=False)}")
        
        # é‡è¦ã‚¢ãƒ©ãƒ¼ãƒˆã®å ´åˆã¯å³åº§ã«é€šçŸ¥
        if alert['level'] == 'critical':
            self._send_critical_alert(alert)
    
    def _send_critical_alert(self, alert: dict):
        """é‡è¦ã‚¢ãƒ©ãƒ¼ãƒˆã®é€šçŸ¥"""
        # å°†æ¥çš„ã«ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ãƒ»Slacké€šçŸ¥ãªã©ã‚’å®Ÿè£…
        print(f"ğŸš¨ CRITICAL ALERT: {alert['summary']}")
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ç‰¹åˆ¥ãªè¨˜éŒ²ã‚’æ®‹ã™
        critical_log_file = self.logger.log_dir / "critical_alerts.log"
        try:
            with open(critical_log_file, 'a', encoding='utf-8') as f:
                f.write(f"{datetime.now().isoformat()} - {json.dumps(alert, ensure_ascii=False)}\n")
        except Exception as e:
            print(f"é‡è¦ã‚¢ãƒ©ãƒ¼ãƒˆã®è¨˜éŒ²ã«å¤±æ•—: {e}")
```

---

## **ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ **

### **åŒ…æ‹¬çš„ä¾‹å¤–å‡¦ç†æˆ¦ç•¥**

#### **ğŸ›¡ï¸ å¤šå±¤é˜²å¾¡ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**

```python
class RobustErrorHandler:
    """å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = StructuredLogger("error_handler")
        self.retry_strategies = {
            'network': {'max_retries': 3, 'backoff_factor': 2.0},
            'api_limit': {'max_retries': 1, 'backoff_factor': 60.0},
            'file_io': {'max_retries': 2, 'backoff_factor': 1.0},
            'database': {'max_retries': 2, 'backoff_factor': 0.5}
        }
        self.circuit_breakers = {}
    
    def execute_with_retry(self, operation_func, operation_type: str = 'default', **kwargs):
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãå®Ÿè¡Œ"""
        strategy = self.retry_strategies.get(operation_type, {'max_retries': 1, 'backoff_factor': 1.0})
        max_retries = strategy['max_retries']
        backoff_factor = strategy['backoff_factor']
        
        last_exception = None
        
        for attempt in range(max_retries + 1):
            try:
                # ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
                if self._is_circuit_broken(operation_type):
                    raise CircuitBreakerException(f"Circuit breaker open for {operation_type}")
                
                # æ“ä½œå®Ÿè¡Œ
                start_time = time.time()
                result = operation_func(**kwargs)
                duration = time.time() - start_time
                
                # æˆåŠŸè¨˜éŒ²
                self._record_success(operation_type, duration)
                return result
                
            except Exception as e:
                last_exception = e
                self._record_failure(operation_type, e)
                
                if attempt < max_retries:
                    wait_time = backoff_factor * (2 ** attempt)
                    self.logger.logger.warning(
                        f"æ“ä½œå¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries + 1}): {e}. "
                        f"{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™"
                    )
                    time.sleep(wait_time)
                else:
                    self.logger.log_error(e, {
                        'operation_type': operation_type,
                        'total_attempts': max_retries + 1,
                        'final_failure': True
                    })
        
        # å…¨è©¦è¡Œå¤±æ•—
        raise last_exception
    
    def _is_circuit_broken(self, operation_type: str) -> bool:
        """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯"""
        breaker = self.circuit_breakers.get(operation_type)
        if not breaker:
            return False
        
        now = time.time()
        
        # ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼æœŸé–“çµ‚äº†ãƒã‚§ãƒƒã‚¯
        if now - breaker['opened_at'] > breaker['timeout']:
            # åŠé–‹çŠ¶æ…‹ã«ç§»è¡Œ
            self.circuit_breakers[operation_type]['state'] = 'half_open'
            return False
        
        return breaker['state'] == 'open'
    
    def _record_success(self, operation_type: str, duration: float):
        """æˆåŠŸè¨˜éŒ²"""
        # ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒªã‚»ãƒƒãƒˆ
        if operation_type in self.circuit_breakers:
            self.circuit_breakers[operation_type]['consecutive_failures'] = 0
            if self.circuit_breakers[operation_type]['state'] == 'half_open':
                self.circuit_breakers[operation_type]['state'] = 'closed'
    
    def _record_failure(self, operation_type: str, error: Exception):
        """å¤±æ•—è¨˜éŒ²"""
        if operation_type not in self.circuit_breakers:
            self.circuit_breakers[operation_type] = {
                'consecutive_failures': 0,
                'state': 'closed',
                'failure_threshold': 5,
                'timeout': 300  # 5åˆ†
            }
        
        breaker = self.circuit_breakers[operation_type]
        breaker['consecutive_failures'] += 1
        
        # é–¾å€¤è¶…éã§ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼é–‹æ”¾
        if breaker['consecutive_failures'] >= breaker['failure_threshold']:
            breaker['state'] = 'open'
            breaker['opened_at'] = time.time()
            
            self.logger.logger.critical(
                f"ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼é–‹æ”¾: {operation_type} "
                f"(é€£ç¶šå¤±æ•—: {breaker['consecutive_failures']}å›)"
            )

class CircuitBreakerException(Exception):
    """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ä¾‹å¤–"""
    pass
```

**åˆå¿ƒè€…å‘ã‘: ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³**

```python
# ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã®å‹•ä½œçŠ¶æ…‹

# 1. CLOSEDçŠ¶æ…‹ï¼ˆé€šå¸¸å‹•ä½œï¼‰
# â†’ æ“ä½œãŒæ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã‚‹
# â†’ å¤±æ•—ãŒé€£ç¶šã§ç™ºç”Ÿã™ã‚‹ã¨ OPEN ã¸

# 2. OPENçŠ¶æ…‹ï¼ˆé®æ–­çŠ¶æ…‹ï¼‰
# â†’ æ“ä½œã‚’å³åº§ã«æ‹’å¦ï¼ˆã‚¨ãƒ©ãƒ¼ã®æ‹¡æ•£ã‚’é˜²ãï¼‰
# â†’ ä¸€å®šæ™‚é–“å¾Œã« HALF_OPEN ã¸

# 3. HALF_OPENçŠ¶æ…‹ï¼ˆè©¦é¨“å‹•ä½œï¼‰
# â†’ é™å®šçš„ã«æ“ä½œã‚’è¨±å¯
# â†’ æˆåŠŸã™ã‚Œã° CLOSED ã¸ã€å¤±æ•—ã™ã‚Œã° OPEN ã¸

# é›»æ°—ã®ãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã¨åŒã˜ä»•çµ„ã¿ï¼š
# ç•°å¸¸ãªé›»æµï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰ãŒæµã‚Œç¶šã‘ã‚‹ã¨ã€
# è‡ªå‹•çš„ã«å›è·¯ã‚’é®æ–­ï¼ˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä¿è­·ï¼‰
```

#### **ğŸ”„ è‡ªå‹•å¾©æ—§ãƒ¡ã‚«ãƒ‹ã‚ºãƒ **

```python
class AutoRecoverySystem:
    """è‡ªå‹•å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = StructuredLogger("auto_recovery")
        self.recovery_strategies = {
            'database_corruption': self._recover_database,
            'api_auth_failure': self._recover_api_auth,
            'disk_full': self._recover_disk_space,
            'memory_leak': self._recover_memory,
            'config_missing': self._recover_config
        }
        self.recovery_history = []
    
    def detect_and_recover(self, error: Exception, context: dict = None) -> bool:
        """ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã¨è‡ªå‹•å¾©æ—§"""
        recovery_type = self._classify_error(error, context)
        
        if recovery_type in self.recovery_strategies:
            try:
                self.logger.log_operation(
                    "auto_recovery_start",
                    recovery_type=recovery_type,
                    error_type=type(error).__name__
                )
                
                recovery_func = self.recovery_strategies[recovery_type]
                success = recovery_func(error, context)
                
                # å¾©æ—§å±¥æ­´è¨˜éŒ²
                recovery_record = {
                    'timestamp': datetime.now().isoformat(),
                    'recovery_type': recovery_type,
                    'error_type': type(error).__name__,
                    'success': success,
                    'context': context
                }
                self.recovery_history.append(recovery_record)
                
                if success:
                    self.logger.log_operation(
                        "auto_recovery_success",
                        recovery_type=recovery_type
                    )
                    print(f"âœ… è‡ªå‹•å¾©æ—§æˆåŠŸ: {recovery_type}")
                else:
                    self.logger.log_operation(
                        "auto_recovery_failed",
                        recovery_type=recovery_type
                    )
                    print(f"âŒ è‡ªå‹•å¾©æ—§å¤±æ•—: {recovery_type}")
                
                return success
                
            except Exception as recovery_error:
                self.logger.log_error(recovery_error, {
                    'original_error': str(error),
                    'recovery_type': recovery_type
                })
                return False
        
        return False
    
    def _classify_error(self, error: Exception, context: dict = None) -> str:
        """ã‚¨ãƒ©ãƒ¼åˆ†é¡"""
        error_message = str(error).lower()
        error_type = type(error).__name__
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ã‚¨ãƒ©ãƒ¼
        if any(keyword in error_message for keyword in ['corrupt', 'invalid json', 'decode']):
            return 'database_corruption'
        
        # APIèªè¨¼ã‚¨ãƒ©ãƒ¼
        if any(keyword in error_message for keyword in ['auth', 'credential', 'token', 'permission']):
            return 'api_auth_failure'
        
        # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚¨ãƒ©ãƒ¼
        if any(keyword in error_message for keyword in ['no space', 'disk full', 'storage']):
            return 'disk_full'
        
        # ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼
        if error_type in ['MemoryError', 'OutOfMemoryError']:
            return 'memory_leak'
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼
        if any(keyword in error_message for keyword in ['config', 'setting', 'not found']):
            return 'config_missing'
        
        return 'unknown'
    
    def _recover_database(self, error: Exception, context: dict) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§"""
        try:
            from storage.unified_storage import get_storage
            storage = get_storage()
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©æ—§
            backup_files = list(storage.backup_dir.glob("unified_knowledge_db_*.json"))
            if backup_files:
                # æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½¿ç”¨
                latest_backup = max(backup_files, key=lambda x: x.stat().st_mtime)
                
                import shutil
                shutil.copy2(latest_backup, storage.db_file)
                
                # å¾©æ—§ãƒ†ã‚¹ãƒˆ
                storage._database = None
                db = storage.load_database()
                
                print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¾©æ—§ã—ã¾ã—ãŸ: {latest_backup}")
                return True
            
        except Exception as e:
            self.logger.log_error(e, {'recovery_operation': 'database'})
        
        return False
    
    def _recover_api_auth(self, error: Exception, context: dict) -> bool:
        """APIèªè¨¼å¾©æ—§"""
        try:
            # èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿæˆã‚’è©¦è¡Œ
            if 'youtube' in str(error).lower():
                from collectors.multi_playlist_collector import MultiPlaylistCollector
                collector = MultiPlaylistCollector()
                
                # æ—¢å­˜ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‰Šé™¤
                if collector.token_path.exists():
                    collector.token_path.unlink()
                
                # å†èªè¨¼å®Ÿè¡Œ
                success = collector._initialize_service()
                if success:
                    print("YouTube APIèªè¨¼ã‚’å¾©æ—§ã—ã¾ã—ãŸ")
                    return True
            
        except Exception as e:
            self.logger.log_error(e, {'recovery_operation': 'api_auth'})
        
        return False
    
    def _recover_disk_space(self, error: Exception, context: dict) -> bool:
        """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡å¾©æ—§"""
        try:
            cleaned_space = 0
            
            # å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            log_dir = DATA_DIR.parent / "logs"
            if log_dir.exists():
                for log_file in log_dir.glob("*.log.*"):  # ãƒ­ãƒ¼ãƒ†ãƒ¼ãƒˆã•ã‚ŒãŸãƒ­ã‚°
                    if (datetime.now() - datetime.fromtimestamp(log_file.stat().st_mtime)).days > 30:
                        size = log_file.stat().st_size
                        log_file.unlink()
                        cleaned_space += size
            
            # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤
            storage = get_storage()
            storage.cleanup_old_backups(keep_days=7)
            
            if cleaned_space > 1024*1024:  # 1MBä»¥ä¸Šå‰Šé™¤ã—ãŸå ´åˆ
                print(f"ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’å¾©æ—§ã—ã¾ã—ãŸ: {cleaned_space/1024/1024:.1f}MBå‰Šé™¤")
                return True
            
        except Exception as e:
            self.logger.log_error(e, {'recovery_operation': 'disk_space'})
        
        return False
```

---

## **ğŸ“¦ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥**

### **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°è¨­è¨ˆ**

#### **ğŸ“‹ requirements.txt ç”Ÿæˆ**

```python
# requirements.txt - ä¾å­˜é–¢ä¿‚ç®¡ç†
"""
# YouTube Knowledge System Dependencies

# Core Dependencies
openai>=1.0.0
google-api-python-client>=2.100.0
google-auth-oauthlib>=1.0.0
google-auth-httplib2>=0.2.0

# Data Processing
requests>=2.31.0
python-dotenv>=1.0.0

# GUI Components (Tkinter ã¯æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª)
pillow>=10.0.0  # ç”»åƒå‡¦ç†ã‚µãƒãƒ¼ãƒˆ

# Development & Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
black>=23.0.0
flake8>=6.0.0

# Optional: Enhanced logging
colorlog>=6.7.0
"""

def generate_requirements():
    """å‹•çš„requirements.txtç”Ÿæˆ"""
    import pkg_resources
    import subprocess
    
    # ç¾åœ¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’å–å¾—
    installed_packages = [d for d in pkg_resources.working_set]
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã¿æŠ½å‡º
    used_packages = [
        'openai', 'google-api-python-client', 'google-auth-oauthlib',
        'requests', 'python-dotenv', 'pillow'
    ]
    
    requirements = []
    for package in installed_packages:
        if package.project_name.lower() in used_packages:
            requirements.append(f"{package.project_name}=={package.version}")
    
    # requirements.txt ã«æ›¸ãå‡ºã—
    requirements_file = Path("requirements.txt")
    with open(requirements_file, 'w', encoding='utf-8') as f:
        f.write("# YouTube Knowledge System Dependencies\n")
        f.write("# Generated automatically\n\n")
        for req in sorted(requirements):
            f.write(f"{req}\n")
    
    print(f"requirements.txt ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {len(requirements)}å€‹ã®ä¾å­˜é–¢ä¿‚")
    return requirements_file
```

#### **ğŸ—ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**

```python
# setup.py - ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
from setuptools import setup, find_packages
from pathlib import Path

# READMEèª­ã¿è¾¼ã¿
readme_file = Path(__file__).parent / "README.md"
long_description = readme_file.read_text(encoding='utf-8') if readme_file.exists() else ""

# requirementsèª­ã¿è¾¼ã¿
requirements_file = Path(__file__).parent / "requirements.txt"
requirements = []
if requirements_file.exists():
    requirements = requirements_file.read_text(encoding='utf-8').strip().split('\n')
    requirements = [req for req in requirements if req and not req.startswith('#')]

setup(
    name="youtube-knowledge-system",
    version="2.0.0",
    author="Setsuna Bot Development Team",
    author_email="setsuna@example.com",
    description="YouTubeå‹•ç”»ã®çŸ¥è­˜ç®¡ç†ãƒ»åˆ†æã‚·ã‚¹ãƒ†ãƒ ",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/setsuna-bot/youtube-knowledge-system",
    
    packages=find_packages(),
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    
    python_requires=">=3.9",
    install_requires=requirements,
    
    extras_require={
        "dev": [
            "pytest>=7.4.0",
            "black>=23.0.0",
            "flake8>=6.0.0",
            "mypy>=1.5.0"
        ],
        "gui": [
            "pillow>=10.0.0"
        ]
    },
    
    entry_points={
        "console_scripts": [
            "youtube-knowledge=youtube_knowledge_system.gui.video_main_window:main",
            "yt-knowledge-cli=youtube_knowledge_system.cli.main:main",
        ],
    },
    
    include_package_data=True,
    package_data={
        "youtube_knowledge_system": [
            "config/*.json",
            "docs/*.md",
            "gui/assets/*"
        ],
    },
    
    zip_safe=False,
)
```

### **ç’°å¢ƒåˆ¥ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ**

#### **ğŸš€ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**

```python
#!/usr/bin/env python3
"""
YouTube Knowledge System ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼
"""

import os
import sys
import subprocess
import platform
from pathlib import Path

class SystemInstaller:
    """ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼"""
    
    def __init__(self):
        self.system = platform.system().lower()
        self.python_version = sys.version_info
        self.project_root = Path(__file__).parent
        
    def install(self):
        """ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Ÿè¡Œ"""
        print("ğŸµ YouTube Knowledge System ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«é–‹å§‹")
        print(f"OS: {platform.platform()}")
        print(f"Python: {sys.version}")
        
        try:
            # 1. Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
            self.check_python_version()
            
            # 2. ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ãƒã‚§ãƒƒã‚¯
            self.check_system_requirements()
            
            # 3. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
            self.install_dependencies()
            
            # 4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            self.create_config_files()
            
            # 5. ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            self.create_data_directories()
            
            # 6. åˆæœŸåŒ–å®Ÿè¡Œ
            self.initialize_system()
            
            print("âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†!")
            self.show_next_steps()
            
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def check_python_version(self):
        """Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯"""
        if self.python_version < (3, 9):
            raise Exception(f"Python 3.9ä»¥ä¸ŠãŒå¿…è¦ã§ã™ (ç¾åœ¨: {sys.version})")
        
        print(f"âœ… Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ OK: {sys.version}")
    
    def check_system_requirements(self):
        """ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ãƒã‚§ãƒƒã‚¯"""
        # tkinter å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
        try:
            import tkinter
            print("âœ… tkinter OK")
        except ImportError:
            if self.system == "linux":
                print("âŒ tkinter ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                print("Ubuntu/Debian: sudo apt-get install python3-tk")
                print("CentOS/RHEL: sudo yum install tkinter")
                raise Exception("tkinter ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
        
        # Git å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯ (é–‹ç™ºæ™‚ã®ã¿)
        try:
            subprocess.run(['git', '--version'], capture_output=True, check=True)
            print("âœ… Git OK")
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("âš ï¸  Git ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (é–‹ç™ºæ™‚ã®ã¿å¿…è¦)")
    
    def install_dependencies(self):
        """ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
        requirements_file = self.project_root / "requirements.txt"
        
        if requirements_file.exists():
            print("ğŸ“¦ ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
            
            cmd = [sys.executable, "-m", "pip", "install", "-r", str(requirements_file)]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"pip install ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                raise Exception("ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            print("âœ… ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†")
        else:
            print("âš ï¸  requirements.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    def create_config_files(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        config_dir = self.project_root / "config"
        config_dir.mkdir(exist_ok=True)
        
        # .env ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        env_file = self.project_root / ".env"
        if not env_file.exists():
            env_template = """# YouTube Knowledge System Configuration
# OpenAI API Key (required)
OPENAI_API_KEY=your_openai_api_key_here

# YouTube APIè¨­å®š (optional - èªè¨¼æ™‚ã«è‡ªå‹•è¨­å®š)
# YOUTUBE_CLIENT_ID=your_client_id
# YOUTUBE_CLIENT_SECRET=your_client_secret

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
LOG_LEVEL=INFO

# é–‹ç™ºãƒ¢ãƒ¼ãƒ‰
DEBUG=False
"""
            env_file.write_text(env_template, encoding='utf-8')
            print(f"âœ… .env ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {env_file}")
            print("âš ï¸  OpenAI API ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        
        # ã‚·ã‚¹ãƒ†ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        system_config = config_dir / "system_config.json"
        if not system_config.exists():
            config_data = {
                "api": {
                    "openai_model": "gpt-4o-mini",
                    "max_tokens": 1200,
                    "temperature": 0.1
                },
                "performance": {
                    "max_results_per_request": 50,
                    "concurrent_workers": 4,
                    "request_delay": 1.0
                },
                "logging": {
                    "level": "INFO",
                    "file_max_size": 10485760,
                    "backup_count": 5
                }
            }
            
            import json
            with open(system_config, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {system_config}")
    
    def create_data_directories(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ"""
        from config.settings import get_data_dir
        
        data_dir = get_data_dir()
        
        directories = [
            data_dir,
            data_dir / "backups",
            data_dir / "logs",
            data_dir / "exports",
            data_dir / "cache"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            print(f"âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {directory}")
    
    def initialize_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        try:
            # ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
            from storage.unified_storage import get_storage
            storage = get_storage()
            db = storage.load_database()
            
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†: {storage.db_file}")
            
        except Exception as e:
            print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def show_next_steps(self):
        """æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¡¨ç¤º"""
        print("\nğŸ‰ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†!")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. .env ãƒ•ã‚¡ã‚¤ãƒ«ã« OpenAI API ã‚­ãƒ¼ã‚’è¨­å®š")
        print("2. YouTube API èªè¨¼è¨­å®š (åˆå›å®Ÿè¡Œæ™‚ã«è‡ªå‹•å®Ÿè¡Œ)")
        print("3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•:")
        print("   python gui/video_main_window.py")
        print("\nè©³ç´°ã¯ docs/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æŠ€è¡“æ›¸ã‚’å‚ç…§ã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    installer = SystemInstaller()
    installer.install()
```

### **é‹ç”¨ä¿å®ˆç®¡ç†**

#### **ğŸ” ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ»ã‚³ãƒãƒ³ãƒ‰**

```python
#!/usr/bin/env python3
"""
ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ»ä¿å®ˆãƒ„ãƒ¼ãƒ«
"""

import argparse
import json
from datetime import datetime, timedelta
from pathlib import Path

class MaintenanceTool:
    """ä¿å®ˆãƒ„ãƒ¼ãƒ«"""
    
    def __init__(self):
        from config.settings import DATA_DIR
        from logging_system import StructuredLogger
        
        self.data_dir = DATA_DIR
        self.logger = StructuredLogger("maintenance")
    
    def health_check(self):
        """ç·åˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        from monitoring import SystemMonitor
        
        monitor = SystemMonitor()
        health_report = monitor.run_health_checks()
        
        print("ğŸ¥ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ")
        print("=" * 50)
        print(f"ç·åˆçŠ¶æ…‹: {'âœ… æ­£å¸¸' if health_report['overall_healthy'] else 'âŒ ç•°å¸¸'}")
        print(f"ãƒã‚§ãƒƒã‚¯æ™‚åˆ»: {health_report['timestamp']}")
        
        if health_report['failed_checks']:
            print(f"\nâš ï¸  å¤±æ•—ã—ãŸãƒã‚§ãƒƒã‚¯: {', '.join(health_report['failed_checks'])}")
            
            for check_name in health_report['failed_checks']:
                details = health_report['check_details'][check_name]
                print(f"\n{check_name}:")
                print(f"  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {details.get('message', 'N/A')}")
                if 'error' in details:
                    print(f"  ã‚¨ãƒ©ãƒ¼: {details['error']}")
        
        # ãƒ˜ãƒ«ã‚¹ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_file = self.data_dir / f"health_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(health_report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        
        return health_report['overall_healthy']
    
    def cleanup_logs(self, days: int = 30):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†"""
        log_dir = self.data_dir.parent / "logs"
        if not log_dir.exists():
            print("ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        cutoff_date = datetime.now() - timedelta(days=days)
        cleaned_files = 0
        freed_space = 0
        
        print(f"ğŸ§¹ {days}æ—¥ä»¥å‰ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­...")
        
        for log_file in log_dir.glob("*.log*"):
            if log_file.is_file():
                file_mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
                
                if file_mtime < cutoff_date:
                    file_size = log_file.stat().st_size
                    log_file.unlink()
                    cleaned_files += 1
                    freed_space += file_size
                    print(f"  å‰Šé™¤: {log_file.name}")
        
        print(f"âœ… ãƒ­ã‚°æ•´ç†å®Œäº†: {cleaned_files}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤, {freed_space/1024/1024:.1f}MBè§£æ”¾")
    
    def backup_data(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        from storage.unified_storage import get_storage
        
        storage = get_storage()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        backup_name = f"manual_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        backup_file = storage.backup_dir / backup_name
        
        import shutil
        shutil.copy2(storage.db_file, backup_file)
        
        print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        config_files = [
            self.data_dir / "playlist_configs.json",
            self.data_dir.parent / ".env",
            self.data_dir.parent / "config" / "system_config.json"
        ]
        
        config_backup_dir = storage.backup_dir / "config"
        config_backup_dir.mkdir(exist_ok=True)
        
        for config_file in config_files:
            if config_file.exists():
                backup_config = config_backup_dir / f"{config_file.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}{config_file.suffix}"
                shutil.copy2(config_file, backup_config)
                print(f"âš™ï¸  è¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_config}")
        
        return backup_file

def main():
    parser = argparse.ArgumentParser(description="YouTube Knowledge System ä¿å®ˆãƒ„ãƒ¼ãƒ«")
    
    subparsers = parser.add_subparsers(dest='command', help='åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰')
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    health_parser = subparsers.add_parser('health', help='ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯')
    
    # ãƒ­ã‚°æ•´ç†
    cleanup_parser = subparsers.add_parser('cleanup', help='ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†')
    cleanup_parser.add_argument('--days', type=int, default=30, help='ä¿æŒæ—¥æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥)')
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    backup_parser = subparsers.add_parser('backup', help='ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—')
    
    # çµ±è¨ˆè¡¨ç¤º
    stats_parser = subparsers.add_parser('stats', help='ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆè¡¨ç¤º')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    tool = MaintenanceTool()
    
    if args.command == 'health':
        success = tool.health_check()
        sys.exit(0 if success else 1)
        
    elif args.command == 'cleanup':
        tool.cleanup_logs(args.days)
        
    elif args.command == 'backup':
        backup_file = tool.backup_data()
        print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_file}")
        
    elif args.command == 'stats':
        from storage.unified_storage import get_storage
        storage = get_storage()
        stats = storage.get_statistics()
        
        print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ")
        print("=" * 30)
        print(f"ç·å‹•ç”»æ•°: {stats['total_videos']}")
        print(f"ç·ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæ•°: {stats['total_playlists']}")
        print(f"åˆ†ææ¸ˆã¿å‹•ç”»æ•°: {stats['analyzed_videos']}")
        print(f"åˆ†ææˆåŠŸç‡: {stats['analysis_success_rate']:.1%}")
        print(f"æœ€çµ‚æ›´æ–°: {stats['last_updated']}")

if __name__ == "__main__":
    import sys
    main()
```

ã“ã®ç« ã§ã¯ã€YouTubeãƒŠãƒ¬ãƒƒã‚¸ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‹ã‚‰é‹ç”¨ç®¡ç†ã¾ã§ã€å®Ÿè·µçš„ãªã‚·ã‚¹ãƒ†ãƒ é‹ç”¨æŠ€è¡“ã‚’å­¦ã³ã¾ã—ãŸã€‚ç’°å¢ƒè¨­å®šç®¡ç†ã€æ§‹é€ åŒ–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã€åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€è‡ªå‹•å¾©æ—§æ©Ÿèƒ½ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥ã€ä¿å®ˆãƒ„ãƒ¼ãƒ«ã¾ã§ã€æœ¬æ ¼çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é‹ç”¨ã§å¿…è¦ã¨ãªã‚‹é‡è¦ãªæŠ€è¡“ã‚’ç¿’å¾—ã§ãã¾ã—ãŸã€‚æ¬¡ç« ã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚