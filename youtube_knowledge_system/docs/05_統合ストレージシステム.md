# 第5章: 統合ストレージシステム

## **章の概要**

この章では、YouTubeナレッジシステムの統合データストレージシステムについて詳しく解説します。ファイルベースデータベース設計、自動バックアップ機能、検索インデックス、レガシーデータ移行まで、実践的なデータ管理技術を体系的に学びます。

**対象ファイル**: `storage/unified_storage.py` (約447行)  
**主要技術**: JSON Database, インデックス設計, バックアップシステム, シングルトンパターン

---

## **📋 unified_storage.pyファイルの全体像**

### **ファイルの目的と役割**

`storage/unified_storage.py`は、YouTubeナレッジシステムにおける**データ永続化の中核エンジン**です。このファイルが担う役割は：

1. **統合データ管理**: 動画・プレイリスト・分析結果の一元管理
2. **ファイルベースDB**: JSONによる軽量データベース実装
3. **自動バックアップ**: データ保護とバージョン管理
4. **高速検索**: インデックスベースの効率的データ検索
5. **データ移行**: 既存システムからの段階的移行サポート

### **システム内での位置づけ**

```
YouTube Knowledge System データフロー
┌─────────────────────────────────────┐
│  collectors/multi_playlist_collector.py │  ← データ収集
└─────────────────────────────────────┘
                    │
                    ▼ 収集データ
┌─────────────────────────────────────┐
│  analyzers/description_analyzer.py   │  ← AI分析
└─────────────────────────────────────┘
                    │
                    ▼ 分析結果
┌─────────────────────────────────────┐
│  storage/unified_storage.py          │  ← このファイル
│  ・JSONデータベース管理               │
│  ・バックアップ・復旧                │
│  ・検索インデックス                  │
│  ・統計情報管理                      │
└─────────────────────────────────────┘
                    │
                    ▼ 構造化データ
┌─────────────────────────────────────┐
│  gui/video_main_window.py           │  ← GUI表示
└─────────────────────────────────────┘
```

### **他ファイルとの関連性**

- **`core/data_models.py`**: `KnowledgeDatabase`・`Video`・`Playlist`オブジェクトの保存・復元
- **`collectors/multi_playlist_collector.py`**: 収集したデータをストレージに保存
- **`analyzers/description_analyzer.py`**: AI分析結果をデータベースに統合
- **`managers/playlist_config_manager.py`**: プレイリスト設定との連携
- **`gui/video_main_window.py`**: GUI操作によるデータ取得・更新

### **ファイル構成（447行の内訳）**

1. **初期化・設定** (1-35行): クラス定義、ディレクトリ設定、基本構造
2. **データベース管理** (36-93行): 読み込み・保存・バックアップ機能
3. **CRUD操作** (94-212行): データの作成・読み取り・更新・削除
4. **検索・フィルタ** (213-275行): インデックスベース高速検索
5. **統計・分析** (276-318行): データ統計とメトリクス計算
6. **保守・移行** (319-447行): バックアップ管理、データ移行、エクスポート

---

## **💾 ファイルベースデータベース設計**

### **ファイルベースDBとは（初心者向け解説）**

#### **🗃️ データベースの基本概念**

**従来のデータベース vs ファイルベースDB**

```
従来のリレーショナルDB（MySQL, PostgreSQL等）:
┌─────────────────┐
│  専用サーバー      │  ← 別途データベースサーバーが必要
│  複雑な設定       │  ← インストール・設定が複雑
│  SQL言語         │  ← 専用クエリ言語の学習必要
│  高性能・高機能    │  ← 大規模システム向け
└─────────────────┘

ファイルベースDB（JSON, SQLite等）:
┌─────────────────┐
│  単一ファイル      │  ← ファイルコピーで簡単バックアップ
│  簡単セットアップ   │  ← 追加ソフト不要
│  プログラム言語    │  ← Pythonの辞書操作で直接アクセス
│  中小規模システム  │  ← 適度な性能と簡便性
└─────────────────┘
```

**ファイルベースDBの利点**

1. **シンプルさ**: インストール・設定不要
2. **ポータビリティ**: ファイルコピーでデータ移行
3. **可読性**: テキストエディタで中身確認可能
4. **バックアップ容易性**: 通常のファイル操作で完了
5. **開発効率**: 追加学習コスト最小

#### **🔧 JSONデータベースの特徴**

**JSON形式の利点**

```json
// 人間が読みやすい構造
{
  "videos": {
    "video_123": {
      "title": "サンプル動画",
      "creators": {
        "vocal": "田中太郎",
        "composer": "鈴木花子"
      },
      "analysis_date": "2024-06-25T10:30:00"
    }
  },
  "playlists": {
    "playlist_456": {
      "title": "お気に入り楽曲",
      "video_ids": ["video_123", "video_789"]
    }
  }
}
```

**初心者向け: JSONデータベースの制約**

Web検索結果より：JSONの課題と対策

```
制約1: 検索パフォーマンス
問題: 大量データでの線形検索は遅い
対策: インデックス構造の併用

制約2: 同時アクセス制御
問題: 複数プロセスからの同時書き込み
対策: ファイルロック機構の実装

制約3: データ整合性
問題: 部分的な書き込み失敗
対策: アトミック書き込み（一時ファイル経由）
```

### **データベース構造の実装**

#### **📁 ディレクトリ構造の設計**

```python
class UnifiedStorage:
    def __init__(self, data_dir: Path = None):
        self.data_dir = data_dir or DATA_DIR
        self.db_file = self.data_dir / "unified_knowledge_db.json"
        self.backup_dir = self.data_dir / "backups"
        self.legacy_dir = self.data_dir / "legacy"
        
        # ディレクトリ作成
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.legacy_dir.mkdir(parents=True, exist_ok=True)
        
        self._database: Optional[KnowledgeDatabase] = None
```

**ディレクトリ構造の役割**

```
data/
├── unified_knowledge_db.json    # メインデータベース
├── backups/                     # 自動バックアップ
│   ├── unified_knowledge_db_20250625_103000.json
│   ├── unified_knowledge_db_20250625_104500.json
│   └── ...
└── legacy/                      # 旧形式データ
    ├── old_playlist_data.json
    └── ...
```

#### **🔄 データベース読み込みシステム**

```python
def load_database(self) -> KnowledgeDatabase:
    """データベースを読み込み"""
    if self._database is None:
        if self.db_file.exists():
            try:
                with open(self.db_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self._database = KnowledgeDatabase.from_dict(data)
                print(f"統合データベースを読み込みました: {self._database.total_videos}動画, {self._database.total_playlists}プレイリスト")
            except Exception as e:
                print(f"データベース読み込みエラー: {e}")
                print("新しいデータベースを作成します")
                self._database = create_empty_database()
        else:
            # 既存データがあるか確認
            legacy_files = self._find_legacy_files()
            if legacy_files:
                print("既存データを新しい形式に移行します...")
                self._database = self._migrate_legacy_data(legacy_files)
                self.save_database()
            else:
                self._database = create_empty_database()
    
    return self._database
```

**読み込み処理の特徴**

1. **遅延読み込み**: 初回アクセス時にのみファイル読み込み
2. **エラー復旧**: 破損ファイルからの自動復旧
3. **レガシー対応**: 旧形式データの自動検出・移行
4. **メモリキャッシュ**: 読み込み後はメモリ上で高速アクセス

### **アトミック保存システム**

#### **🛡️ データ整合性の保証**

```python
def save_database(self, create_backup: bool = True) -> None:
    """データベースを保存"""
    if self._database is None:
        return
    
    # バックアップ作成
    if create_backup and self.db_file.exists():
        backup_file = self.backup_dir / f"unified_knowledge_db_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        shutil.copy2(self.db_file, backup_file)
        print(f"バックアップを作成しました: {backup_file}")
    
    # データベース保存
    try:
        self._database.last_updated = datetime.now()
        with open(self.db_file, 'w', encoding='utf-8') as f:
            json.dump(self._database.to_dict(), f, ensure_ascii=False, indent=2)
        print(f"統合データベースを保存しました: {self.db_file}")
    except Exception as e:
        print(f"データベース保存エラー: {e}")
        raise
```

**アトミック書き込みの改良版実装例**

```python
def save_database_atomic(self, create_backup: bool = True) -> None:
    """アトミック書き込みによる安全な保存"""
    if self._database is None:
        return
    
    # 一時ファイルを使用したアトミック書き込み
    temp_file = self.db_file.with_suffix('.tmp')
    
    try:
        # 一時ファイルに書き込み
        self._database.last_updated = datetime.now()
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(self._database.to_dict(), f, ensure_ascii=False, indent=2)
        
        # バックアップ作成（書き込み成功後）
        if create_backup and self.db_file.exists():
            backup_file = self.backup_dir / f"unified_knowledge_db_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            shutil.copy2(self.db_file, backup_file)
        
        # アトミックな置き換え（OSレベルで保証される）
        temp_file.replace(self.db_file)
        
    except Exception as e:
        # エラー時は一時ファイルを削除
        if temp_file.exists():
            temp_file.unlink()
        raise e
```

**初心者向け: アトミック操作とは**

```
アトミック操作 = 「全て成功」または「全て失敗」
（部分的な成功は存在しない）

例：銀行送金
❌ 非アトミック: A口座から引き落とし成功、B口座への入金失敗
✅ アトミック: 全工程成功 or 全工程ロールバック

ファイル書き込みでのアトミック性:
❌ 直接書き込み: 途中でクラッシュすると破損ファイル
✅ 一時ファイル経由: 完全書き込み後に置き換え
```

---

## **🔍 インデックス構築とデータ検索**

### **検索インデックスの設計思想**

#### **⚡ 高速検索の実現**

**線形検索 vs インデックス検索**

```python
# ❌ 非効率: 線形検索（全動画を順次確認）
def find_videos_by_creator_slow(creator_name: str):
    results = []
    for video_id, video in all_videos.items():  # O(n)
        if video.creative_insight:
            for creator in video.creative_insight.creators:
                if creator.name == creator_name:
                    results.append(video)
    return results

# ✅ 効率的: インデックス検索（事前計算済み）
def find_videos_by_creator_fast(creator_name: str):
    video_ids = creator_index.get(creator_name, [])  # O(1)
    return [videos[vid] for vid in video_ids]         # O(m) m=結果数
```

**計算量の比較**

```
データ量: 10,000動画の場合

線形検索: O(n) = 10,000回の比較処理
インデックス検索: O(1) + O(m) = 1回の辞書検索 + 結果数分の取得

速度向上: 約100-1000倍（結果数による）
```

#### **🗂️ インデックス構造の実装**

**実際のインデックス構造**

```python
# core/data_models.py の KnowledgeDatabase より
class KnowledgeDatabase:
    def __init__(self):
        self.videos: Dict[str, Video] = {}
        self.playlists: Dict[str, Playlist] = {}
        
        # 横断インデックス
        self.creator_index: Dict[str, List[str]] = {}  # creator_name -> video_ids
        self.tag_index: Dict[str, List[str]] = {}      # tag -> video_ids  
        self.theme_index: Dict[str, List[str]] = {}    # theme -> video_ids
```

**インデックス再構築システム**

```python
def rebuild_indexes(self):
    """インデックスを再構築"""
    self.creator_index = {}
    self.tag_index = {}
    self.theme_index = {}
    
    for video_id, video in self.videos.items():
        # クリエイターインデックス
        if video.creative_insight:
            for creator in video.creative_insight.creators:
                if creator.name not in self.creator_index:
                    self.creator_index[creator.name] = []
                self.creator_index[creator.name].append(video_id)
        
        # タグインデックス
        for tag in video.metadata.tags:
            if tag not in self.tag_index:
                self.tag_index[tag] = []
            self.tag_index[tag].append(video_id)
        
        # テーマインデックス
        if video.creative_insight:
            for theme in video.creative_insight.themes:
                if theme not in self.theme_index:
                    self.theme_index[theme] = []
                self.theme_index[theme].append(video_id)
    
    # 統計更新
    self.total_videos = len(self.videos)
    self.total_playlists = len(self.playlists)
    self.last_updated = datetime.now()
```

### **検索機能の実装**

#### **🎯 多様な検索オプション**

```python
def search_videos_by_creator(self, creator_name: str) -> List[Video]:
    """クリエイター名で動画検索"""
    db = self.load_database()
    return db.get_videos_by_creator(creator_name)

def search_videos_by_tag(self, tag: str) -> List[Video]:
    """タグで動画検索"""
    db = self.load_database()
    return db.get_videos_by_tag(tag)

def search_videos_by_theme(self, theme: str) -> List[Video]:
    """テーマで動画検索"""
    db = self.load_database()
    return db.get_videos_by_theme(theme)
```

**検索結果の統合機能例**

```python
def advanced_search(self, 
                   creator: Optional[str] = None,
                   tag: Optional[str] = None, 
                   theme: Optional[str] = None,
                   playlist_id: Optional[str] = None) -> List[Video]:
    """複合条件での高度検索"""
    
    db = self.load_database()
    result_sets = []
    
    # 各条件での検索結果を取得
    if creator:
        creator_videos = set(v.metadata.id for v in db.get_videos_by_creator(creator))
        result_sets.append(creator_videos)
    
    if tag:
        tag_videos = set(v.metadata.id for v in db.get_videos_by_tag(tag))
        result_sets.append(tag_videos)
    
    if theme:
        theme_videos = set(v.metadata.id for v in db.get_videos_by_theme(theme))
        result_sets.append(theme_videos)
    
    if playlist_id:
        playlist_videos = set(v.metadata.id for v in self.get_videos_by_playlist(playlist_id))
        result_sets.append(playlist_videos)
    
    # 積集合（AND検索）
    if result_sets:
        final_video_ids = result_sets[0]
        for video_set in result_sets[1:]:
            final_video_ids &= video_set
        
        return [db.videos[vid] for vid in final_video_ids if vid in db.videos]
    
    return []
```

#### **📊 検索結果の統計情報**

```python
def get_search_statistics(self) -> Dict[str, Any]:
    """検索関連の統計情報"""
    db = self.load_database()
    
    return {
        "total_creators": len(db.creator_index),
        "total_tags": len(db.tag_index), 
        "total_themes": len(db.theme_index),
        "top_creators": sorted(
            [(name, len(videos)) for name, videos in db.creator_index.items()],
            key=lambda x: x[1], reverse=True
        )[:10],
        "top_tags": sorted(
            [(tag, len(videos)) for tag, videos in db.tag_index.items()],
            key=lambda x: x[1], reverse=True
        )[:10],
        "index_efficiency": {
            "creator_index_size": sum(len(videos) for videos in db.creator_index.values()),
            "tag_index_size": sum(len(videos) for videos in db.tag_index.values()),
            "theme_index_size": sum(len(videos) for videos in db.theme_index.values())
        }
    }
```

---

## **🔄 自動バックアップと復旧システム**

### **バックアップ戦略の設計**

#### **💾 階層化バックアップシステム**

**バックアップのタイミング**

```python
def save_database(self, create_backup: bool = True) -> None:
    """保存時の自動バックアップ"""
    # 1. 毎回の保存時にバックアップ作成
    if create_backup and self.db_file.exists():
        backup_file = self.backup_dir / f"unified_knowledge_db_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        shutil.copy2(self.db_file, backup_file)
```

**バックアップファイルの命名規則**

```
パターン: unified_knowledge_db_YYYYMMDD_HHMMSS.json

例:
unified_knowledge_db_20250625_103045.json  # 2025年6月25日 10:30:45
unified_knowledge_db_20250625_143021.json  # 2025年6月25日 14:30:21
unified_knowledge_db_20250625_173315.json  # 2025年6月25日 17:33:15
```

**長期保存戦略**

```python
def cleanup_old_backups(self, keep_days: int = 30) -> None:
    """古いバックアップファイルを削除"""
    cutoff_time = datetime.now().timestamp() - (keep_days * 24 * 60 * 60)
    
    deleted_count = 0
    for backup_file in self.backup_dir.glob("unified_knowledge_db_*.json"):
        if backup_file.stat().st_mtime < cutoff_time:
            backup_file.unlink()
            deleted_count += 1
            print(f"古いバックアップを削除しました: {backup_file}")
    
    print(f"バックアップクリーンアップ完了: {deleted_count}ファイル削除")
```

#### **⚡ 差分バックアップの実装例**

```python
def create_incremental_backup(self) -> Optional[Path]:
    """差分バックアップ作成（実装例）"""
    current_db = self.load_database()
    
    # 最新のバックアップファイルを取得
    backup_files = sorted(self.backup_dir.glob("unified_knowledge_db_*.json"))
    if not backup_files:
        # 初回は完全バックアップ
        return self.create_full_backup()
    
    latest_backup = backup_files[-1]
    
    try:
        # 前回バックアップを読み込み
        with open(latest_backup, 'r', encoding='utf-8') as f:
            previous_data = json.load(f)
        previous_db = KnowledgeDatabase.from_dict(previous_data)
        
        # 差分を計算
        changes = self._calculate_changes(previous_db, current_db)
        
        if not changes['has_changes']:
            print("変更なし、差分バックアップはスキップ")
            return None
        
        # 差分バックアップファイル作成
        increment_file = self.backup_dir / f"increment_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(increment_file, 'w', encoding='utf-8') as f:
            json.dump(changes, f, ensure_ascii=False, indent=2)
        
        print(f"差分バックアップ作成: {increment_file}")
        return increment_file
        
    except Exception as e:
        print(f"差分バックアップ作成エラー: {e}")
        return self.create_full_backup()  # フォールバック

def _calculate_changes(self, old_db: KnowledgeDatabase, new_db: KnowledgeDatabase) -> Dict[str, Any]:
    """データベース間の差分を計算"""
    changes = {
        'timestamp': datetime.now().isoformat(),
        'has_changes': False,
        'added_videos': {},
        'modified_videos': {},
        'deleted_videos': [],
        'added_playlists': {},
        'modified_playlists': {},
        'deleted_playlists': []
    }
    
    # 動画の差分
    old_video_ids = set(old_db.videos.keys())
    new_video_ids = set(new_db.videos.keys())
    
    # 追加された動画
    for video_id in new_video_ids - old_video_ids:
        changes['added_videos'][video_id] = new_db.videos[video_id].to_dict()
        changes['has_changes'] = True
    
    # 削除された動画
    for video_id in old_video_ids - new_video_ids:
        changes['deleted_videos'].append(video_id)
        changes['has_changes'] = True
    
    # 変更された動画
    for video_id in old_video_ids & new_video_ids:
        old_video = old_db.videos[video_id]
        new_video = new_db.videos[video_id]
        if old_video.updated_at != new_video.updated_at:
            changes['modified_videos'][video_id] = new_video.to_dict()
            changes['has_changes'] = True
    
    return changes
```

### **データ復旧システム**

#### **🔧 自動復旧機能**

```python
def recover_from_backup(self, backup_file: Optional[Path] = None) -> bool:
    """バックアップからの復旧"""
    try:
        if backup_file is None:
            # 最新のバックアップを自動選択
            backup_files = sorted(self.backup_dir.glob("unified_knowledge_db_*.json"))
            if not backup_files:
                print("❌ 利用可能なバックアップファイルがありません")
                return False
            backup_file = backup_files[-1]
        
        print(f"🔄 バックアップからの復旧開始: {backup_file}")
        
        # バックアップファイルの整合性チェック
        with open(backup_file, 'r', encoding='utf-8') as f:
            backup_data = json.load(f)
        
        # データベースオブジェクトとして復元可能かテスト
        test_db = KnowledgeDatabase.from_dict(backup_data)
        print(f"   ✅ バックアップファイル検証成功")
        print(f"   📊 復旧データ: {test_db.total_videos}動画, {test_db.total_playlists}プレイリスト")
        
        # 現在のファイルをバックアップ（破損ファイルとして保存）
        if self.db_file.exists():
            corrupted_backup = self.backup_dir / f"corrupted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            shutil.move(str(self.db_file), str(corrupted_backup))
            print(f"   📁 破損ファイルを保存: {corrupted_backup}")
        
        # バックアップからメインファイルを復元
        shutil.copy2(backup_file, self.db_file)
        
        # メモリ上のデータベースを更新
        self._database = test_db
        
        print(f"✅ データベース復旧完了")
        return True
        
    except Exception as e:
        print(f"❌ 復旧処理エラー: {e}")
        return False

def verify_database_integrity(self) -> Dict[str, Any]:
    """データベース整合性チェック"""
    try:
        db = self.load_database()
        
        issues = []
        warnings = []
        
        # 基本構造チェック
        if not isinstance(db.videos, dict):
            issues.append("videos が辞書型ではありません")
        if not isinstance(db.playlists, dict):
            issues.append("playlists が辞書型ではありません")
        
        # 参照整合性チェック
        for playlist_id, playlist in db.playlists.items():
            for video_id in playlist.video_ids:
                if video_id not in db.videos:
                    issues.append(f"プレイリスト {playlist_id} に存在しない動画 {video_id} が含まれています")
        
        # インデックス整合性チェック
        for creator_name, video_ids in db.creator_index.items():
            for video_id in video_ids:
                if video_id not in db.videos:
                    warnings.append(f"creator_index に存在しない動画 {video_id} が含まれています")
        
        # 統計情報チェック
        actual_video_count = len(db.videos)
        if db.total_videos != actual_video_count:
            warnings.append(f"total_videos の不整合: 記録値={db.total_videos}, 実際={actual_video_count}")
        
        return {
            'is_valid': len(issues) == 0,
            'issues': issues,
            'warnings': warnings,
            'checked_at': datetime.now().isoformat(),
            'total_videos': len(db.videos),
            'total_playlists': len(db.playlists)
        }
        
    except Exception as e:
        return {
            'is_valid': False,
            'issues': [f"整合性チェック中にエラー: {e}"],
            'warnings': [],
            'checked_at': datetime.now().isoformat()
        }
```

---

## **📊 レガシーデータ移行機能**

### **段階的データ移行システム**

#### **🔄 既存データの自動検出**

```python
def _find_legacy_files(self) -> Dict[str, Path]:
    """既存データファイルを探索"""
    legacy_files = {}
    
    # プレイリストファイル
    playlist_files = list(self.data_dir.glob("playlists/playlist_*.json"))
    if playlist_files:
        legacy_files['playlists'] = playlist_files
        print(f"   📋 既存プレイリストファイル: {len(playlist_files)}件")
    
    # 分析結果ファイル
    analysis_files = list(self.data_dir.glob("analyzed_*.json"))
    if analysis_files:
        legacy_files['analysis'] = analysis_files  
        print(f"   🤖 既存分析結果ファイル: {len(analysis_files)}件")
    
    # 設定ファイル（古い形式）
    old_config_files = list(self.data_dir.glob("config_*.json"))
    if old_config_files:
        legacy_files['configs'] = old_config_files
        print(f"   ⚙️ 既存設定ファイル: {len(old_config_files)}件")
    
    return legacy_files
```

**移行処理の実装**

```python
def _migrate_legacy_data(self, legacy_files: Dict[str, Any]) -> KnowledgeDatabase:
    """既存データを移行"""
    print("🔄 レガシーデータ移行を開始します...")
    db = create_empty_database()
    migration_stats = {
        'migrated_videos': 0,
        'migrated_playlists': 0,
        'failed_files': [],
        'start_time': datetime.now()
    }
    
    # プレイリストファイルを処理
    if 'playlists' in legacy_files:
        for playlist_file in legacy_files['playlists']:
            try:
                print(f"   📋 プレイリストファイル移行中: {playlist_file.name}")
                
                # 旧形式のプレイリストデータを読み込み
                with open(playlist_file, 'r', encoding='utf-8') as f:
                    old_data = json.load(f)
                
                # 新形式に変換
                converted_db = self._convert_legacy_playlist(old_data)
                
                # データを統合
                for video_id, video in converted_db.videos.items():
                    db.add_video(video)
                    migration_stats['migrated_videos'] += 1
                
                for playlist_id, playlist in converted_db.playlists.items():
                    db.add_playlist(playlist)
                    migration_stats['migrated_playlists'] += 1
                
                # レガシーファイルを移動
                legacy_target = self.legacy_dir / playlist_file.name
                shutil.move(str(playlist_file), str(legacy_target))
                print(f"   ✅ 移行完了 → {legacy_target}")
                
            except Exception as e:
                print(f"   ❌ プレイリストファイル移行エラー {playlist_file}: {e}")
                migration_stats['failed_files'].append(str(playlist_file))
    
    # 分析結果を統合
    if 'analysis' in legacy_files:
        for analysis_file in legacy_files['analysis']:
            try:
                print(f"   🤖 分析結果ファイル移行中: {analysis_file.name}")
                
                with open(analysis_file, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                
                # 分析結果を既存動画に統合
                merged_count = self._merge_analysis_results(db, analysis_data)
                print(f"   ✅ {merged_count}件の分析結果を統合")
                
                # 分析ファイルを移動
                legacy_target = self.legacy_dir / analysis_file.name
                shutil.move(str(analysis_file), str(legacy_target))
                
            except Exception as e:
                print(f"   ❌ 分析ファイル移行エラー {analysis_file}: {e}")
                migration_stats['failed_files'].append(str(analysis_file))
    
    # 移行統計表示
    end_time = datetime.now()
    duration = end_time - migration_stats['start_time']
    
    print(f"\n📊 レガシーデータ移行完了")
    print(f"   動画: {migration_stats['migrated_videos']}件")
    print(f"   プレイリスト: {migration_stats['migrated_playlists']}件")
    print(f"   失敗ファイル: {len(migration_stats['failed_files'])}件")
    print(f"   処理時間: {duration.total_seconds():.1f}秒")
    
    if migration_stats['failed_files']:
        print(f"   ⚠️ 失敗ファイル: {migration_stats['failed_files']}")
    
    return db

def _convert_legacy_playlist(self, old_data: Dict[str, Any]) -> KnowledgeDatabase:
    """旧プレイリスト形式を新形式に変換"""
    from core.data_models import Video, Playlist, VideoMetadata, PlaylistMetadata, ContentSource, AnalysisStatus
    
    db = create_empty_database()
    
    # 旧形式の構造例:
    # {
    #   "playlist_info": {...},
    #   "videos": [...],
    #   "last_updated": "..."
    # }
    
    playlist_info = old_data.get('playlist_info', {})
    videos_data = old_data.get('videos', [])
    
    # プレイリストオブジェクト作成
    playlist = Playlist(
        source=ContentSource.YOUTUBE,
        metadata=PlaylistMetadata(
            id=playlist_info.get('id', ''),
            title=playlist_info.get('title', ''),
            description=playlist_info.get('description', ''),
            channel_title=playlist_info.get('channel_title', ''),
            channel_id=playlist_info.get('channel_id', ''),
            published_at=datetime.fromisoformat(playlist_info.get('published_at', datetime.now().isoformat())),
            item_count=len(videos_data),
            collected_at=datetime.now()
        ),
        video_ids=[],
        last_full_sync=datetime.now(),
        last_incremental_sync=None,
        sync_settings={},
        total_videos=len(videos_data),
        analyzed_videos=0,
        analysis_success_rate=0.0,
        created_at=datetime.now(),
        updated_at=datetime.now()
    )
    
    # 動画オブジェクト作成
    for video_data in videos_data:
        try:
            video = Video(
                source=ContentSource.YOUTUBE,
                metadata=VideoMetadata.from_youtube_api(video_data),
                playlists=[playlist.metadata.id],
                playlist_positions={playlist.metadata.id: video_data.get('position', 0)},
                analysis_status=AnalysisStatus.PENDING,
                creative_insight=None,
                analysis_error=None,
                created_at=datetime.now(),
                updated_at=datetime.now()
            )
            
            db.add_video(video)
            playlist.video_ids.append(video.metadata.id)
            
        except Exception as e:
            print(f"   ⚠️ 動画変換エラー {video_data.get('id', 'unknown')}: {e}")
    
    db.add_playlist(playlist)
    return db
```

### **エクスポート・統計機能**

#### **📈 詳細統計情報の提供**

```python
def get_statistics(self) -> Dict[str, Any]:
    """統計情報を取得"""
    db = self.load_database()
    
    analyzed_videos = sum(1 for v in db.videos.values() if v.creative_insight is not None)
    analysis_success_rate = analyzed_videos / len(db.videos) if db.videos else 0
    
    # プレイリスト別統計
    playlist_stats = {}
    for pid, playlist in db.playlists.items():
        playlist_videos = [db.videos[vid] for vid in playlist.video_ids if vid in db.videos]
        analyzed_in_playlist = sum(1 for v in playlist_videos if v.creative_insight is not None)
        
        playlist_stats[pid] = {
            'title': playlist.metadata.title,
            'total_videos': len(playlist_videos),
            'analyzed_videos': analyzed_in_playlist,
            'analysis_rate': analyzed_in_playlist / len(playlist_videos) if playlist_videos else 0,
            'last_sync': playlist.last_full_sync.isoformat(),
            'channel_title': playlist.metadata.channel_title
        }
    
    # 時系列統計（分析の進捗）
    analysis_timeline = self._calculate_analysis_timeline(db)
    
    return {
        'database_overview': {
            'total_videos': db.total_videos,
            'total_playlists': db.total_playlists,
            'analyzed_videos': analyzed_videos,
            'analysis_success_rate': analysis_success_rate,
            'last_updated': db.last_updated.isoformat(),
            'database_version': db.database_version
        },
        'content_statistics': {
            'total_creators': len(db.creator_index),
            'total_tags': len(db.tag_index),
            'total_themes': len(db.theme_index),
            'top_creators': sorted(
                [(name, len(videos)) for name, videos in db.creator_index.items()],
                key=lambda x: x[1], reverse=True
            )[:10],
            'popular_tags': sorted(
                [(tag, len(videos)) for tag, videos in db.tag_index.items()],
                key=lambda x: x[1], reverse=True
            )[:10]
        },
        'playlists': playlist_stats,
        'analysis_timeline': analysis_timeline,
        'storage_info': {
            'database_file_size': self.db_file.stat().st_size if self.db_file.exists() else 0,
            'backup_count': len(list(self.backup_dir.glob("unified_knowledge_db_*.json"))),
            'legacy_file_count': len(list(self.legacy_dir.glob("*")))
        }
    }

def _calculate_analysis_timeline(self, db: KnowledgeDatabase) -> Dict[str, Any]:
    """分析進捗のタイムライン作成"""
    timeline = {}
    
    for video in db.videos.values():
        if video.creative_insight and video.creative_insight.analysis_timestamp:
            date_key = video.creative_insight.analysis_timestamp.strftime('%Y-%m-%d')
            if date_key not in timeline:
                timeline[date_key] = 0
            timeline[date_key] += 1
    
    return {
        'daily_analysis_count': timeline,
        'peak_analysis_day': max(timeline.items(), key=lambda x: x[1]) if timeline else None,
        'analysis_span_days': len(timeline)
    }
```

この章では、ファイルベースデータベースの実践的な実装を通じて、データ永続化、バックアップ、検索最適化の技術を体系的に学びました。次章では、このストレージシステムと連携する設定管理システムについて詳しく解説します。